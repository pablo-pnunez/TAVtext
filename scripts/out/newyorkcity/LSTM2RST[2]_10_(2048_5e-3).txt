[93m[WARNING] Model folder already exists...[0m
[92m[INFO] Loading existing model...[0m
[92m[INFO] Model already trained![0m
[92m[INFO] Loading w2v...[0m
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding (Embedding)        (None, None, 300)         41334000  
_________________________________________________________________
lstm (LSTM)                  (None, 256)               570368    
_________________________________________________________________
dropout (Dropout)            (None, 256)               0         
_________________________________________________________________
dense (Dense)                (None, 1988)              510916    
=================================================================
Total params: 42,415,284
Trainable params: 1,081,284
Non-trainable params: 41,334,000
_________________________________________________________________
None
Epoch 1/1000
323/323 - 148s - loss: 6.9608 - accuracy: 0.0450 - top_5: 0.0871 - top_10: 0.1163 - val_loss: 6.6426 - val_accuracy: 0.0648 - val_top_5: 0.1139 - val_top_10: 0.1490
Epoch 2/1000
323/323 - 151s - loss: 6.6347 - accuracy: 0.0609 - top_5: 0.1141 - top_10: 0.1502 - val_loss: 6.1889 - val_accuracy: 0.0864 - val_top_5: 0.1540 - val_top_10: 0.1975
Epoch 3/1000
323/323 - 151s - loss: 6.3402 - accuracy: 0.0716 - top_5: 0.1378 - top_10: 0.1800 - val_loss: 5.8691 - val_accuracy: 0.0974 - val_top_5: 0.1756 - val_top_10: 0.2307
Epoch 4/1000
323/323 - 152s - loss: 6.1236 - accuracy: 0.0828 - top_5: 0.1579 - top_10: 0.2050 - val_loss: 5.6516 - val_accuracy: 0.1111 - val_top_5: 0.2008 - val_top_10: 0.2594
Epoch 5/1000
323/323 - 151s - loss: 6.0020 - accuracy: 0.0897 - top_5: 0.1687 - top_10: 0.2181 - val_loss: 5.5074 - val_accuracy: 0.1182 - val_top_5: 0.2165 - val_top_10: 0.2760
Epoch 6/1000
323/323 - 151s - loss: 5.9265 - accuracy: 0.0931 - top_5: 0.1761 - top_10: 0.2278 - val_loss: 5.4350 - val_accuracy: 0.1239 - val_top_5: 0.2232 - val_top_10: 0.2847
Epoch 7/1000
323/323 - 151s - loss: 5.8437 - accuracy: 0.0976 - top_5: 0.1839 - top_10: 0.2374 - val_loss: 5.3264 - val_accuracy: 0.1286 - val_top_5: 0.2350 - val_top_10: 0.3032
Epoch 8/1000
323/323 - 151s - loss: 5.7877 - accuracy: 0.1000 - top_5: 0.1907 - top_10: 0.2463 - val_loss: 5.3032 - val_accuracy: 0.1336 - val_top_5: 0.2420 - val_top_10: 0.3095
Epoch 9/1000
323/323 - 152s - loss: 5.8239 - accuracy: 0.0982 - top_5: 0.1873 - top_10: 0.2432 - val_loss: 5.2645 - val_accuracy: 0.1352 - val_top_5: 0.2486 - val_top_10: 0.3161
Epoch 10/1000
323/323 - 150s - loss: 5.7503 - accuracy: 0.1017 - top_5: 0.1938 - top_10: 0.2509 - val_loss: 5.2005 - val_accuracy: 0.1389 - val_top_5: 0.2582 - val_top_10: 0.3269
Epoch 11/1000
323/323 - 151s - loss: 5.7049 - accuracy: 0.1044 - top_5: 0.1994 - top_10: 0.2579 - val_loss: 5.3148 - val_accuracy: 0.1327 - val_top_5: 0.2416 - val_top_10: 0.3090
Epoch 12/1000
323/323 - 151s - loss: 5.7169 - accuracy: 0.1037 - top_5: 0.1981 - top_10: 0.2567 - val_loss: 5.1690 - val_accuracy: 0.1407 - val_top_5: 0.2582 - val_top_10: 0.3317
Epoch 13/1000
323/323 - 150s - loss: 5.6736 - accuracy: 0.1057 - top_5: 0.2016 - top_10: 0.2616 - val_loss: 5.2307 - val_accuracy: 0.1381 - val_top_5: 0.2524 - val_top_10: 0.3226
Epoch 14/1000
323/323 - 151s - loss: 5.7609 - accuracy: 0.1018 - top_5: 0.1943 - top_10: 0.2519 - val_loss: 5.2623 - val_accuracy: 0.1363 - val_top_5: 0.2477 - val_top_10: 0.3181
Epoch 15/1000
323/323 - 150s - loss: 5.7819 - accuracy: 0.1003 - top_5: 0.1928 - top_10: 0.2501 - val_loss: 5.2200 - val_accuracy: 0.1392 - val_top_5: 0.2537 - val_top_10: 0.3233
Epoch 16/1000
323/323 - 151s - loss: 5.7682 - accuracy: 0.1006 - top_5: 0.1928 - top_10: 0.2505 - val_loss: 5.2568 - val_accuracy: 0.1352 - val_top_5: 0.2485 - val_top_10: 0.3189
Epoch 17/1000
323/323 - 151s - loss: 5.7637 - accuracy: 0.1012 - top_5: 0.1937 - top_10: 0.2512 - val_loss: 5.2493 - val_accuracy: 0.1366 - val_top_5: 0.2507 - val_top_10: 0.3196
Epoch 18/1000
323/323 - 151s - loss: 5.8382 - accuracy: 0.0976 - top_5: 0.1874 - top_10: 0.2433 - val_loss: 5.3879 - val_accuracy: 0.1293 - val_top_5: 0.2378 - val_top_10: 0.3029
Epoch 19/1000
323/323 - 151s - loss: 5.8888 - accuracy: 0.0954 - top_5: 0.1837 - top_10: 0.2379 - val_loss: 5.3364 - val_accuracy: 0.1317 - val_top_5: 0.2435 - val_top_10: 0.3091
Epoch 20/1000
323/323 - 151s - loss: 5.8883 - accuracy: 0.0949 - top_5: 0.1819 - top_10: 0.2364 - val_loss: 5.3678 - val_accuracy: 0.1296 - val_top_5: 0.2368 - val_top_10: 0.3041
Epoch 21/1000
323/323 - 151s - loss: 5.8789 - accuracy: 0.0948 - top_5: 0.1829 - top_10: 0.2375 - val_loss: 5.3123 - val_accuracy: 0.1316 - val_top_5: 0.2433 - val_top_10: 0.3126
Epoch 22/1000
323/323 - 151s - loss: 5.8581 - accuracy: 0.0964 - top_5: 0.1850 - top_10: 0.2397 - val_loss: 5.3844 - val_accuracy: 0.1292 - val_top_5: 0.2353 - val_top_10: 0.3005
Epoch 23/1000
323/323 - 151s - loss: 5.8575 - accuracy: 0.0960 - top_5: 0.1847 - top_10: 0.2399 - val_loss: 5.3148 - val_accuracy: 0.1325 - val_top_5: 0.2427 - val_top_10: 0.3111
Epoch 24/1000
323/323 - 151s - loss: 5.8984 - accuracy: 0.0937 - top_5: 0.1814 - top_10: 0.2357 - val_loss: 5.4084 - val_accuracy: 0.1272 - val_top_5: 0.2335 - val_top_10: 0.2982
Epoch 25/1000
323/323 - 152s - loss: 5.9827 - accuracy: 0.0898 - top_5: 0.1730 - top_10: 0.2252 - val_loss: 5.4873 - val_accuracy: 0.1236 - val_top_5: 0.2246 - val_top_10: 0.2888
Epoch 26/1000
323/323 - 151s - loss: 6.0163 - accuracy: 0.0883 - top_5: 0.1697 - top_10: 0.2209 - val_loss: 5.4844 - val_accuracy: 0.1234 - val_top_5: 0.2250 - val_top_10: 0.2880
Epoch 27/1000
323/323 - 152s - loss: 5.9748 - accuracy: 0.0899 - top_5: 0.1732 - top_10: 0.2257 - val_loss: 5.4536 - val_accuracy: 0.1243 - val_top_5: 0.2271 - val_top_10: 0.2917
Epoch 28/1000
323/323 - 152s - loss: 5.9716 - accuracy: 0.0905 - top_5: 0.1737 - top_10: 0.2260 - val_loss: 5.4578 - val_accuracy: 0.1262 - val_top_5: 0.2293 - val_top_10: 0.2936
Epoch 29/1000
323/323 - 152s - loss: 5.9949 - accuracy: 0.0897 - top_5: 0.1722 - top_10: 0.2241 - val_loss: 5.5347 - val_accuracy: 0.1221 - val_top_5: 0.2211 - val_top_10: 0.2851
Epoch 30/1000
323/323 - 151s - loss: 6.0798 - accuracy: 0.0855 - top_5: 0.1656 - top_10: 0.2154 - val_loss: 5.6136 - val_accuracy: 0.1169 - val_top_5: 0.2145 - val_top_10: 0.2748
Epoch 31/1000
323/323 - 152s - loss: 6.1196 - accuracy: 0.0837 - top_5: 0.1610 - top_10: 0.2094 - val_loss: 5.5700 - val_accuracy: 0.1198 - val_top_5: 0.2155 - val_top_10: 0.2770
Epoch 32/1000
323/323 - 149s - loss: 6.0870 - accuracy: 0.0848 - top_5: 0.1633 - top_10: 0.2125 - val_loss: 5.5949 - val_accuracy: 0.1198 - val_top_5: 0.2163 - val_top_10: 0.2786
Epoch 00032: early stopping
[92m[INFO] Loading best model...[0m
[93m[WARNING] Model folder already exists...[0m
[92m[INFO] Loading existing model...[0m
[92m[INFO] Model already trained![0m
[93m[WARNING] Model folder already exists...[0m
[92m[INFO] Loading w2v...[0m
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding (Embedding)        (None, None, 300)         41334000  
_________________________________________________________________
lstm (LSTM)                  (None, 256)               570368    
_________________________________________________________________
dropout (Dropout)            (None, 256)               0         
_________________________________________________________________
dense (Dense)                (None, 1988)              510916    
=================================================================
Total params: 42,415,284
Trainable params: 1,081,284
Non-trainable params: 41,334,000
_________________________________________________________________
None
[92m[INFO] Model already trained. Loading weights...[0m
