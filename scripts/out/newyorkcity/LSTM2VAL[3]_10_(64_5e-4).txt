[93m[WARNING] Model folder already exists...[0m
[92m[INFO] Loading existing model...[0m
[92m[INFO] Model already trained![0m
[92m[INFO] Loading w2v...[0m
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding (Embedding)        (None, None, 300)         41334000  
_________________________________________________________________
lstm (LSTM)                  (None, 256)               570368    
_________________________________________________________________
dense (Dense)                (None, 128)               32896     
_________________________________________________________________
dense_1 (Dense)              (None, 64)                8256      
_________________________________________________________________
dense_2 (Dense)              (None, 32)                2080      
_________________________________________________________________
dense_3 (Dense)              (None, 16)                528       
_________________________________________________________________
dense_4 (Dense)              (None, 1)                 17        
=================================================================
Total params: 41,948,145
Trainable params: 614,145
Non-trainable params: 41,334,000
_________________________________________________________________
None
Epoch 1/1000
10354/10354 - 1456s - loss: 42.0875 - mean_absolute_error: 4.8044 - val_loss: 33.1213 - val_mean_absolute_error: 4.4100
Epoch 2/1000
10354/10354 - 1438s - loss: 32.0810 - mean_absolute_error: 4.3439 - val_loss: 31.8940 - val_mean_absolute_error: 4.1753
Epoch 3/1000
10354/10354 - 1458s - loss: 30.6160 - mean_absolute_error: 4.2450 - val_loss: 31.5507 - val_mean_absolute_error: 4.4727
Epoch 4/1000
10354/10354 - 1453s - loss: 29.6830 - mean_absolute_error: 4.1849 - val_loss: 32.8329 - val_mean_absolute_error: 4.0926
Epoch 5/1000
[93m[WARNING] Model folder already exists...[0m
[92m[INFO] Loading existing model...[0m
[92m[INFO] Model already trained![0m
[92m[INFO] Loading w2v...[0m
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding (Embedding)        (None, None, 300)         41334000  
_________________________________________________________________
lstm (LSTM)                  (None, 256)               570368    
_________________________________________________________________
dense (Dense)                (None, 128)               32896     
_________________________________________________________________
dense_1 (Dense)              (None, 64)                8256      
_________________________________________________________________
dense_2 (Dense)              (None, 32)                2080      
_________________________________________________________________
dense_3 (Dense)              (None, 16)                528       
_________________________________________________________________
dense_4 (Dense)              (None, 1)                 17        
=================================================================
Total params: 41,948,145
Trainable params: 614,145
Non-trainable params: 41,334,000
_________________________________________________________________
None
Epoch 1/1000
10354/10354 - 1605s - loss: 41.9963 - mean_absolute_error: 4.7951 - val_loss: 33.4696 - val_mean_absolute_error: 4.4467
Epoch 2/1000
10354/10354 - 1512s - loss: 31.9269 - mean_absolute_error: 4.3329 - val_loss: 32.0617 - val_mean_absolute_error: 4.1763
Epoch 3/1000
10354/10354 - 1506s - loss: 30.4555 - mean_absolute_error: 4.2327 - val_loss: 31.3195 - val_mean_absolute_error: 4.4694
Epoch 4/1000
10354/10354 - 1508s - loss: 29.4886 - mean_absolute_error: 4.1691 - val_loss: 32.4186 - val_mean_absolute_error: 4.1261
Epoch 5/1000
10354/10354 - 1506s - loss: 28.8438 - mean_absolute_error: 4.1254 - val_loss: 30.3437 - val_mean_absolute_error: 4.3449
Epoch 6/1000
10354/10354 - 1505s - loss: 28.2379 - mean_absolute_error: 4.0832 - val_loss: 30.2364 - val_mean_absolute_error: 4.0753
Epoch 7/1000
10354/10354 - 1510s - loss: 27.8294 - mean_absolute_error: 4.0561 - val_loss: 29.9178 - val_mean_absolute_error: 4.1902
Epoch 8/1000
10354/10354 - 1504s - loss: 27.3674 - mean_absolute_error: 4.0198 - val_loss: 30.0815 - val_mean_absolute_error: 4.1210
Epoch 9/1000
10354/10354 - 1505s - loss: 27.0663 - mean_absolute_error: 3.9996 - val_loss: 30.0119 - val_mean_absolute_error: 4.1299
Epoch 10/1000
10354/10354 - 1507s - loss: 26.6835 - mean_absolute_error: 3.9723 - val_loss: 30.4756 - val_mean_absolute_error: 4.3799
Epoch 11/1000
10354/10354 - 1504s - loss: 26.4153 - mean_absolute_error: 3.9525 - val_loss: 29.8545 - val_mean_absolute_error: 4.1668
Epoch 12/1000
10354/10354 - 1513s - loss: 26.0902 - mean_absolute_error: 3.9277 - val_loss: 30.3974 - val_mean_absolute_error: 4.0399
Epoch 13/1000
10354/10354 - 1518s - loss: 25.9441 - mean_absolute_error: 3.9201 - val_loss: 29.7710 - val_mean_absolute_error: 4.1009
Epoch 14/1000
10354/10354 - 1518s - loss: 25.6750 - mean_absolute_error: 3.8993 - val_loss: 30.0833 - val_mean_absolute_error: 4.2139
Epoch 15/1000
10354/10354 - 1513s - loss: 25.4300 - mean_absolute_error: 3.8795 - val_loss: 29.7564 - val_mean_absolute_error: 4.1924
Epoch 16/1000
10354/10354 - 1501s - loss: 25.1465 - mean_absolute_error: 3.8572 - val_loss: 30.1619 - val_mean_absolute_error: 4.2625
Epoch 17/1000
10354/10354 - 1508s - loss: 24.9356 - mean_absolute_error: 3.8431 - val_loss: 30.8149 - val_mean_absolute_error: 4.0294
Epoch 18/1000
10354/10354 - 1504s - loss: 24.6721 - mean_absolute_error: 3.8219 - val_loss: 29.9946 - val_mean_absolute_error: 4.1397
Epoch 19/1000
10354/10354 - 1512s - loss: 24.4658 - mean_absolute_error: 3.8057 - val_loss: 29.9852 - val_mean_absolute_error: 4.1131
Epoch 20/1000
10354/10354 - 1509s - loss: 24.3029 - mean_absolute_error: 3.7916 - val_loss: 30.5321 - val_mean_absolute_error: 4.2370
Epoch 21/1000
10354/10354 - 1505s - loss: 24.1520 - mean_absolute_error: 3.7790 - val_loss: 32.0720 - val_mean_absolute_error: 4.5535
Epoch 22/1000
10354/10354 - 1509s - loss: 23.9803 - mean_absolute_error: 3.7635 - val_loss: 30.1225 - val_mean_absolute_error: 4.2218
Epoch 23/1000
10354/10354 - 1511s - loss: 23.7741 - mean_absolute_error: 3.7487 - val_loss: 30.4493 - val_mean_absolute_error: 4.0270
Epoch 24/1000
10354/10354 - 1512s - loss: 23.6349 - mean_absolute_error: 3.7386 - val_loss: 30.3275 - val_mean_absolute_error: 4.1835
Epoch 25/1000
10354/10354 - 1512s - loss: 23.4913 - mean_absolute_error: 3.7279 - val_loss: 30.5214 - val_mean_absolute_error: 4.0663
Epoch 26/1000
10354/10354 - 1505s - loss: 23.3854 - mean_absolute_error: 3.7167 - val_loss: 30.3378 - val_mean_absolute_error: 4.0667
Epoch 27/1000
10354/10354 - 1507s - loss: 23.1899 - mean_absolute_error: 3.7005 - val_loss: 30.5798 - val_mean_absolute_error: 4.0283
Epoch 28/1000
10354/10354 - 1520s - loss: 23.0271 - mean_absolute_error: 3.6883 - val_loss: 30.1967 - val_mean_absolute_error: 4.1150
Epoch 29/1000
10354/10354 - 1519s - loss: 22.8756 - mean_absolute_error: 3.6748 - val_loss: 30.3504 - val_mean_absolute_error: 4.0484
Epoch 30/1000
10354/10354 - 1526s - loss: 22.7080 - mean_absolute_error: 3.6579 - val_loss: 30.5090 - val_mean_absolute_error: 4.0619
Epoch 31/1000
10354/10354 - 1498s - loss: 22.5700 - mean_absolute_error: 3.6475 - val_loss: 30.8675 - val_mean_absolute_error: 4.1663
Epoch 32/1000
10354/10354 - 1511s - loss: 22.4052 - mean_absolute_error: 3.6338 - val_loss: 30.3943 - val_mean_absolute_error: 4.1308
Epoch 33/1000
10354/10354 - 1511s - loss: 22.2443 - mean_absolute_error: 3.6206 - val_loss: 30.9921 - val_mean_absolute_error: 4.0384
Epoch 34/1000
10354/10354 - 1511s - loss: 22.0922 - mean_absolute_error: 3.6074 - val_loss: 30.8320 - val_mean_absolute_error: 4.0443
Epoch 35/1000
10354/10354 - 1510s - loss: 21.9457 - mean_absolute_error: 3.5945 - val_loss: 30.6636 - val_mean_absolute_error: 4.1063
Epoch 36/1000
10354/10354 - 1510s - loss: 21.7789 - mean_absolute_error: 3.5785 - val_loss: 30.6444 - val_mean_absolute_error: 4.1703
Epoch 37/1000
10354/10354 - 1506s - loss: 21.6307 - mean_absolute_error: 3.5687 - val_loss: 31.0374 - val_mean_absolute_error: 4.2829
Epoch 38/1000
10354/10354 - 1511s - loss: 21.5722 - mean_absolute_error: 3.5610 - val_loss: 30.5414 - val_mean_absolute_error: 4.1581
Epoch 39/1000
10354/10354 - 1508s - loss: 21.4524 - mean_absolute_error: 3.5503 - val_loss: 31.0187 - val_mean_absolute_error: 4.1594
Epoch 40/1000
10354/10354 - 1427s - loss: 21.3052 - mean_absolute_error: 3.5372 - val_loss: 31.1201 - val_mean_absolute_error: 4.2517
Epoch 41/1000
10354/10354 - 1428s - loss: 21.1960 - mean_absolute_error: 3.5271 - val_loss: 31.1128 - val_mean_absolute_error: 4.0939
Epoch 42/1000
10354/10354 - 1426s - loss: 21.0336 - mean_absolute_error: 3.5129 - val_loss: 31.0220 - val_mean_absolute_error: 4.1272
Epoch 43/1000
10354/10354 - 1426s - loss: 20.9310 - mean_absolute_error: 3.5023 - val_loss: 31.0548 - val_mean_absolute_error: 4.1193
Epoch 00043: early stopping
[92m[INFO] Loading best model...[0m
