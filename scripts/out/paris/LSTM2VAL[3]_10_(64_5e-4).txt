[93m[WARNING] Model folder already exists...[0m
[92m[INFO] Loading existing model...[0m
[92m[INFO] Model already trained![0m
[92m[INFO] Loading w2v...[0m
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding (Embedding)        (None, None, 300)         43245900  
_________________________________________________________________
lstm (LSTM)                  (None, 256)               570368    
_________________________________________________________________
dense (Dense)                (None, 128)               32896     
_________________________________________________________________
dense_1 (Dense)              (None, 64)                8256      
_________________________________________________________________
dense_2 (Dense)              (None, 32)                2080      
_________________________________________________________________
dense_3 (Dense)              (None, 16)                528       
_________________________________________________________________
dense_4 (Dense)              (None, 1)                 17        
=================================================================
Total params: 43,860,045
Trainable params: 614,145
Non-trainable params: 43,245,900
_________________________________________________________________
None
[92m[INFO] Not saving the model...[0m
Epoch 1/1000
10142/10142 - 1822s - loss: 39.8557 - mean_absolute_error: 4.7558 - val_loss: 31.1777 - val_mean_absolute_error: 4.3895
Epoch 2/1000
10142/10142 - 1817s - loss: 30.4024 - mean_absolute_error: 4.2913 - val_loss: 31.0740 - val_mean_absolute_error: 4.2521
Epoch 3/1000
10142/10142 - 1815s - loss: 28.8667 - mean_absolute_error: 4.1855 - val_loss: 29.5033 - val_mean_absolute_error: 4.2810
Epoch 4/1000
10142/10142 - 1815s - loss: 27.9136 - mean_absolute_error: 4.1229 - val_loss: 29.5373 - val_mean_absolute_error: 4.3595
Epoch 5/1000
10142/10142 - 1811s - loss: 27.1838 - mean_absolute_error: 4.0736 - val_loss: 28.7042 - val_mean_absolute_error: 4.2347
Epoch 6/1000
10142/10142 - 1807s - loss: 26.5461 - mean_absolute_error: 4.0264 - val_loss: 28.9714 - val_mean_absolute_error: 4.2655
Epoch 7/1000
10142/10142 - 1810s - loss: 25.9281 - mean_absolute_error: 3.9832 - val_loss: 28.6853 - val_mean_absolute_error: 4.1895
Epoch 8/1000
10142/10142 - 1809s - loss: 25.4768 - mean_absolute_error: 3.9495 - val_loss: 29.3068 - val_mean_absolute_error: 4.0731
Epoch 9/1000
10142/10142 - 1814s - loss: 25.0794 - mean_absolute_error: 3.9188 - val_loss: 28.6072 - val_mean_absolute_error: 4.1201
Epoch 10/1000
10142/10142 - 1803s - loss: 24.6384 - mean_absolute_error: 3.8841 - val_loss: 29.9000 - val_mean_absolute_error: 4.0741
Epoch 11/1000
10142/10142 - 1811s - loss: 24.2634 - mean_absolute_error: 3.8573 - val_loss: 28.8805 - val_mean_absolute_error: 4.1356
Epoch 12/1000
10142/10142 - 1804s - loss: 23.8552 - mean_absolute_error: 3.8231 - val_loss: 29.2097 - val_mean_absolute_error: 4.0647
Epoch 13/1000
10142/10142 - 1808s - loss: 23.5521 - mean_absolute_error: 3.7987 - val_loss: 28.7092 - val_mean_absolute_error: 4.1015
Epoch 14/1000
10142/10142 - 1806s - loss: 23.2347 - mean_absolute_error: 3.7717 - val_loss: 29.0275 - val_mean_absolute_error: 4.0741
Epoch 15/1000
10142/10142 - 1808s - loss: 22.8624 - mean_absolute_error: 3.7395 - val_loss: 29.0195 - val_mean_absolute_error: 4.1225
Epoch 16/1000
10142/10142 - 1806s - loss: 22.6276 - mean_absolute_error: 3.7168 - val_loss: 29.0855 - val_mean_absolute_error: 4.1761
Epoch 17/1000
10142/10142 - 1813s - loss: 22.3273 - mean_absolute_error: 3.6950 - val_loss: 29.3207 - val_mean_absolute_error: 4.1209
Epoch 18/1000
10142/10142 - 1801s - loss: 22.0437 - mean_absolute_error: 3.6687 - val_loss: 30.3020 - val_mean_absolute_error: 4.0545
Epoch 19/1000
10142/10142 - 1806s - loss: 21.7460 - mean_absolute_error: 3.6423 - val_loss: 29.4908 - val_mean_absolute_error: 4.1548
Epoch 20/1000
10142/10142 - 1803s - loss: 21.5307 - mean_absolute_error: 3.6211 - val_loss: 29.9799 - val_mean_absolute_error: 4.0372
Epoch 21/1000
10142/10142 - 1805s - loss: 21.2694 - mean_absolute_error: 3.5978 - val_loss: 29.8960 - val_mean_absolute_error: 4.1023
Epoch 22/1000
10142/10142 - 1802s - loss: 21.0378 - mean_absolute_error: 3.5777 - val_loss: 29.7766 - val_mean_absolute_error: 4.0517
Epoch 23/1000
10142/10142 - 1805s - loss: 20.8358 - mean_absolute_error: 3.5557 - val_loss: 29.8550 - val_mean_absolute_error: 4.0731
Epoch 24/1000
10142/10142 - 1802s - loss: 20.6001 - mean_absolute_error: 3.5341 - val_loss: 30.1928 - val_mean_absolute_error: 4.1019
Epoch 25/1000
10142/10142 - 1804s - loss: 20.3872 - mean_absolute_error: 3.5131 - val_loss: 30.2178 - val_mean_absolute_error: 4.1214
Epoch 26/1000
10142/10142 - 1800s - loss: 20.1703 - mean_absolute_error: 3.4942 - val_loss: 30.5054 - val_mean_absolute_error: 4.2375
Epoch 27/1000
10142/10142 - 1808s - loss: 19.8988 - mean_absolute_error: 3.4660 - val_loss: 30.5895 - val_mean_absolute_error: 4.2083
Epoch 28/1000
[93m[WARNING] Model folder already exists...[0m
[92m[INFO] Loading existing model...[0m
[92m[INFO] Model already trained![0m
[93m[WARNING] Model folder already exists...[0m
[92m[INFO] Loading w2v...[0m
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding (Embedding)        (None, None, 300)         43245900  
_________________________________________________________________
lstm (LSTM)                  (None, 256)               570368    
_________________________________________________________________
dense (Dense)                (None, 128)               32896     
_________________________________________________________________
dense_1 (Dense)              (None, 64)                8256      
_________________________________________________________________
dense_2 (Dense)              (None, 32)                2080      
_________________________________________________________________
dense_3 (Dense)              (None, 16)                528       
_________________________________________________________________
dense_4 (Dense)              (None, 1)                 17        
=================================================================
Total params: 43,860,045
Trainable params: 614,145
Non-trainable params: 43,245,900
_________________________________________________________________
None
Epoch 1/1000
10142/10142 - 1643s - loss: 39.5786 - mean_absolute_error: 4.7264 - val_loss: 31.0188 - val_mean_absolute_error: 4.3982
Epoch 2/1000
10142/10142 - 1631s - loss: 30.2068 - mean_absolute_error: 4.2792 - val_loss: 30.7379 - val_mean_absolute_error: 4.1969
Epoch 3/1000
10142/10142 - 1642s - loss: 28.8015 - mean_absolute_error: 4.1820 - val_loss: 29.3371 - val_mean_absolute_error: 4.2457
Epoch 4/1000
10142/10142 - 1641s - loss: 27.8512 - mean_absolute_error: 4.1180 - val_loss: 29.7835 - val_mean_absolute_error: 4.3932
Epoch 5/1000
10142/10142 - 1626s - loss: 27.1830 - mean_absolute_error: 4.0727 - val_loss: 28.9635 - val_mean_absolute_error: 4.2264
Epoch 6/1000
10142/10142 - 1628s - loss: 26.5697 - mean_absolute_error: 4.0306 - val_loss: 28.8374 - val_mean_absolute_error: 4.2273
Epoch 7/1000
10142/10142 - 1626s - loss: 26.0675 - mean_absolute_error: 3.9903 - val_loss: 28.5466 - val_mean_absolute_error: 4.1645
Epoch 8/1000
10142/10142 - 1628s - loss: 25.5508 - mean_absolute_error: 3.9564 - val_loss: 29.3465 - val_mean_absolute_error: 4.0851
Epoch 9/1000
10142/10142 - 1625s - loss: 25.1778 - mean_absolute_error: 3.9301 - val_loss: 28.6151 - val_mean_absolute_error: 4.0764
Epoch 10/1000
10142/10142 - 1626s - loss: 24.7350 - mean_absolute_error: 3.8966 - val_loss: 29.6737 - val_mean_absolute_error: 4.0814
Epoch 11/1000
10142/10142 - 1627s - loss: 24.3624 - mean_absolute_error: 3.8679 - val_loss: 28.6784 - val_mean_absolute_error: 4.1394
Epoch 12/1000
10142/10142 - 1622s - loss: 23.9932 - mean_absolute_error: 3.8374 - val_loss: 28.7602 - val_mean_absolute_error: 4.0765
Epoch 13/1000
10142/10142 - 1638s - loss: 23.7282 - mean_absolute_error: 3.8193 - val_loss: 28.6176 - val_mean_absolute_error: 4.1097
Epoch 14/1000
10142/10142 - 1635s - loss: 23.3787 - mean_absolute_error: 3.7897 - val_loss: 28.8173 - val_mean_absolute_error: 4.1024
Epoch 15/1000
10142/10142 - 1632s - loss: 23.0383 - mean_absolute_error: 3.7623 - val_loss: 29.0138 - val_mean_absolute_error: 4.1082
Epoch 16/1000
10142/10142 - 1612s - loss: 22.7335 - mean_absolute_error: 3.7378 - val_loss: 29.0148 - val_mean_absolute_error: 4.2543
Epoch 17/1000
10142/10142 - 1608s - loss: 22.4816 - mean_absolute_error: 3.7142 - val_loss: 29.0608 - val_mean_absolute_error: 4.0868
Epoch 18/1000
10142/10142 - 1606s - loss: 22.2247 - mean_absolute_error: 3.6917 - val_loss: 29.6254 - val_mean_absolute_error: 4.0677
Epoch 19/1000
10142/10142 - 1607s - loss: 21.9608 - mean_absolute_error: 3.6659 - val_loss: 29.4766 - val_mean_absolute_error: 4.1203
Epoch 20/1000
10142/10142 - 1606s - loss: 21.7121 - mean_absolute_error: 3.6445 - val_loss: 29.7384 - val_mean_absolute_error: 4.1011
Epoch 21/1000
10142/10142 - 1631s - loss: 21.4030 - mean_absolute_error: 3.6182 - val_loss: 29.9848 - val_mean_absolute_error: 4.0799
Epoch 22/1000
10142/10142 - 1608s - loss: 21.1554 - mean_absolute_error: 3.5933 - val_loss: 29.9602 - val_mean_absolute_error: 4.0489
Epoch 23/1000
10142/10142 - 1631s - loss: 20.9057 - mean_absolute_error: 3.5700 - val_loss: 30.3145 - val_mean_absolute_error: 4.0667
Epoch 24/1000
10142/10142 - 1782s - loss: 20.6392 - mean_absolute_error: 3.5437 - val_loss: 30.5855 - val_mean_absolute_error: 4.1064
Epoch 25/1000
10142/10142 - 1776s - loss: 20.4059 - mean_absolute_error: 3.5214 - val_loss: 30.2222 - val_mean_absolute_error: 4.1352
Epoch 26/1000
10142/10142 - 1781s - loss: 20.1907 - mean_absolute_error: 3.4999 - val_loss: 30.1720 - val_mean_absolute_error: 4.2269
Epoch 27/1000
10142/10142 - 1780s - loss: 19.9510 - mean_absolute_error: 3.4761 - val_loss: 30.2408 - val_mean_absolute_error: 4.1662
Epoch 28/1000
10142/10142 - 1782s - loss: 19.7754 - mean_absolute_error: 3.4563 - val_loss: 30.5617 - val_mean_absolute_error: 4.1440
Epoch 29/1000
10142/10142 - 1783s - loss: 19.5612 - mean_absolute_error: 3.4352 - val_loss: 31.3004 - val_mean_absolute_error: 4.0836
Epoch 30/1000
10142/10142 - 1784s - loss: 19.3501 - mean_absolute_error: 3.4145 - val_loss: 31.2199 - val_mean_absolute_error: 4.3231
Epoch 31/1000
10142/10142 - 1777s - loss: 19.2269 - mean_absolute_error: 3.4014 - val_loss: 30.8808 - val_mean_absolute_error: 4.1455
Epoch 32/1000
10142/10142 - 1783s - loss: 19.0515 - mean_absolute_error: 3.3836 - val_loss: 30.8274 - val_mean_absolute_error: 4.1408
Epoch 33/1000
10142/10142 - 1782s - loss: 18.9061 - mean_absolute_error: 3.3673 - val_loss: 30.8282 - val_mean_absolute_error: 4.2298
Epoch 34/1000
10142/10142 - 1779s - loss: 18.6970 - mean_absolute_error: 3.3455 - val_loss: 30.9614 - val_mean_absolute_error: 4.1493
Epoch 35/1000
10142/10142 - 1781s - loss: 18.5543 - mean_absolute_error: 3.3295 - val_loss: 31.0068 - val_mean_absolute_error: 4.1428
Epoch 36/1000
10142/10142 - 1786s - loss: 18.3704 - mean_absolute_error: 3.3096 - val_loss: 31.3030 - val_mean_absolute_error: 4.2850
Epoch 37/1000
10142/10142 - 1773s - loss: 18.1724 - mean_absolute_error: 3.2885 - val_loss: 31.2617 - val_mean_absolute_error: 4.1972
Epoch 38/1000
10142/10142 - 1782s - loss: 18.0366 - mean_absolute_error: 3.2726 - val_loss: 31.3356 - val_mean_absolute_error: 4.1567
Epoch 39/1000
10142/10142 - 1774s - loss: 17.8880 - mean_absolute_error: 3.2551 - val_loss: 31.6772 - val_mean_absolute_error: 4.3211
Epoch 40/1000
10142/10142 - 1789s - loss: 17.7995 - mean_absolute_error: 3.2443 - val_loss: 31.5232 - val_mean_absolute_error: 4.1457
Epoch 41/1000
10142/10142 - 1793s - loss: 17.6302 - mean_absolute_error: 3.2264 - val_loss: 31.4413 - val_mean_absolute_error: 4.1866
Epoch 42/1000
10142/10142 - 1743s - loss: 17.5063 - mean_absolute_error: 3.2127 - val_loss: 31.8299 - val_mean_absolute_error: 4.1821
Epoch 00042: early stopping
[92m[INFO] Loading best model...[0m
