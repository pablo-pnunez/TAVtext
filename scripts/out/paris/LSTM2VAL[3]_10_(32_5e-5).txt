[93m[WARNING] Model folder already exists...[0m
[92m[INFO] Loading existing model...[0m
[92m[INFO] Model already trained![0m
[92m[INFO] Loading w2v...[0m
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding (Embedding)        (None, None, 300)         43245900  
_________________________________________________________________
lstm (LSTM)                  (None, 256)               570368    
_________________________________________________________________
dense (Dense)                (None, 128)               32896     
_________________________________________________________________
dense_1 (Dense)              (None, 64)                8256      
_________________________________________________________________
dense_2 (Dense)              (None, 32)                2080      
_________________________________________________________________
dense_3 (Dense)              (None, 16)                528       
_________________________________________________________________
dense_4 (Dense)              (None, 1)                 17        
=================================================================
Total params: 43,860,045
Trainable params: 614,145
Non-trainable params: 43,245,900
_________________________________________________________________
None
[92m[INFO] Not saving the model...[0m
Epoch 1/1000
20284/20284 - 3638s - loss: 49.8942 - mean_absolute_error: 5.0602 - val_loss: 31.9483 - val_mean_absolute_error: 4.3927
Epoch 2/1000
20284/20284 - 3655s - loss: 30.7445 - mean_absolute_error: 4.3131 - val_loss: 31.4669 - val_mean_absolute_error: 4.1895
Epoch 3/1000
20284/20284 - 3659s - loss: 28.8360 - mean_absolute_error: 4.1819 - val_loss: 29.1941 - val_mean_absolute_error: 4.2090
Epoch 4/1000
20284/20284 - 3650s - loss: 27.7064 - mean_absolute_error: 4.1048 - val_loss: 28.8888 - val_mean_absolute_error: 4.2277
Epoch 5/1000
20284/20284 - 3638s - loss: 26.8159 - mean_absolute_error: 4.0403 - val_loss: 29.5659 - val_mean_absolute_error: 4.1239
Epoch 6/1000
20284/20284 - 3636s - loss: 26.0597 - mean_absolute_error: 3.9886 - val_loss: 28.7022 - val_mean_absolute_error: 4.2425
Epoch 7/1000
20284/20284 - 3616s - loss: 25.4114 - mean_absolute_error: 3.9419 - val_loss: 28.0377 - val_mean_absolute_error: 4.0803
Epoch 8/1000
20284/20284 - 3619s - loss: 24.8425 - mean_absolute_error: 3.9000 - val_loss: 27.9369 - val_mean_absolute_error: 4.0794
Epoch 9/1000
20284/20284 - 3631s - loss: 24.2691 - mean_absolute_error: 3.8570 - val_loss: 28.0140 - val_mean_absolute_error: 4.1054
Epoch 10/1000
20284/20284 - 3632s - loss: 23.7584 - mean_absolute_error: 3.8180 - val_loss: 28.4865 - val_mean_absolute_error: 4.1510
Epoch 11/1000
20284/20284 - 3629s - loss: 23.2607 - mean_absolute_error: 3.7799 - val_loss: 28.0747 - val_mean_absolute_error: 4.0201
Epoch 12/1000
20284/20284 - 3631s - loss: 22.8111 - mean_absolute_error: 3.7435 - val_loss: 28.3138 - val_mean_absolute_error: 4.0124
Epoch 13/1000
20284/20284 - 3630s - loss: 22.3728 - mean_absolute_error: 3.7066 - val_loss: 28.4664 - val_mean_absolute_error: 4.0545
Epoch 14/1000
[93m[WARNING] Model folder already exists...[0m
[92m[INFO] Loading existing model...[0m
[92m[INFO] Model already trained![0m
[93m[WARNING] Model folder already exists...[0m
[92m[INFO] Loading w2v...[0m
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding (Embedding)        (None, None, 300)         43245900  
_________________________________________________________________
lstm (LSTM)                  (None, 256)               570368    
_________________________________________________________________
dense (Dense)                (None, 128)               32896     
_________________________________________________________________
dense_1 (Dense)              (None, 64)                8256      
_________________________________________________________________
dense_2 (Dense)              (None, 32)                2080      
_________________________________________________________________
dense_3 (Dense)              (None, 16)                528       
_________________________________________________________________
dense_4 (Dense)              (None, 1)                 17        
=================================================================
Total params: 43,860,045
Trainable params: 614,145
Non-trainable params: 43,245,900
_________________________________________________________________
None
Epoch 1/1000
20284/20284 - 3645s - loss: 49.9381 - mean_absolute_error: 5.0564 - val_loss: 31.9900 - val_mean_absolute_error: 4.4016
Epoch 2/1000
20284/20284 - 3641s - loss: 30.8328 - mean_absolute_error: 4.3176 - val_loss: 31.5629 - val_mean_absolute_error: 4.1963
Epoch 3/1000
20284/20284 - 3660s - loss: 28.8853 - mean_absolute_error: 4.1838 - val_loss: 28.9181 - val_mean_absolute_error: 4.1872
Epoch 4/1000
20284/20284 - 3661s - loss: 27.7432 - mean_absolute_error: 4.1052 - val_loss: 28.7811 - val_mean_absolute_error: 4.2274
Epoch 5/1000
20284/20284 - 3661s - loss: 26.8863 - mean_absolute_error: 4.0458 - val_loss: 29.3236 - val_mean_absolute_error: 4.1462
Epoch 6/1000
20284/20284 - 3643s - loss: 26.1259 - mean_absolute_error: 3.9925 - val_loss: 28.8172 - val_mean_absolute_error: 4.2667
Epoch 7/1000
20284/20284 - 3627s - loss: 25.4873 - mean_absolute_error: 3.9475 - val_loss: 27.9642 - val_mean_absolute_error: 4.0664
Epoch 8/1000
20284/20284 - 3616s - loss: 24.9088 - mean_absolute_error: 3.9057 - val_loss: 27.7477 - val_mean_absolute_error: 4.0307
Epoch 9/1000
20284/20284 - 3610s - loss: 24.3648 - mean_absolute_error: 3.8656 - val_loss: 27.8671 - val_mean_absolute_error: 4.1067
Epoch 10/1000
20284/20284 - 3621s - loss: 23.8519 - mean_absolute_error: 3.8246 - val_loss: 28.3290 - val_mean_absolute_error: 4.1435
Epoch 11/1000
20284/20284 - 3312s - loss: 23.3923 - mean_absolute_error: 3.7892 - val_loss: 27.9285 - val_mean_absolute_error: 4.0466
Epoch 12/1000
20284/20284 - 3181s - loss: 22.9298 - mean_absolute_error: 3.7528 - val_loss: 28.3445 - val_mean_absolute_error: 4.0057
Epoch 13/1000
20284/20284 - 3170s - loss: 22.5058 - mean_absolute_error: 3.7158 - val_loss: 28.0533 - val_mean_absolute_error: 4.0444
Epoch 14/1000
20284/20284 - 3169s - loss: 22.0661 - mean_absolute_error: 3.6818 - val_loss: 28.2485 - val_mean_absolute_error: 4.0675
Epoch 15/1000
20284/20284 - 3175s - loss: 21.6845 - mean_absolute_error: 3.6468 - val_loss: 29.2324 - val_mean_absolute_error: 4.2317
Epoch 16/1000
20284/20284 - 3166s - loss: 21.2605 - mean_absolute_error: 3.6120 - val_loss: 28.7629 - val_mean_absolute_error: 4.0882
Epoch 17/1000
20284/20284 - 3163s - loss: 20.8665 - mean_absolute_error: 3.5750 - val_loss: 28.6464 - val_mean_absolute_error: 4.1014
Epoch 18/1000
20284/20284 - 3178s - loss: 20.4919 - mean_absolute_error: 3.5414 - val_loss: 28.8163 - val_mean_absolute_error: 4.1148
Epoch 19/1000
20284/20284 - 3169s - loss: 20.1503 - mean_absolute_error: 3.5082 - val_loss: 29.0610 - val_mean_absolute_error: 4.0883
Epoch 20/1000
20284/20284 - 3162s - loss: 19.7726 - mean_absolute_error: 3.4740 - val_loss: 29.5623 - val_mean_absolute_error: 4.1428
Epoch 21/1000
20284/20284 - 3138s - loss: 19.4110 - mean_absolute_error: 3.4386 - val_loss: 29.5351 - val_mean_absolute_error: 4.0924
Epoch 22/1000
20284/20284 - 3094s - loss: 19.1108 - mean_absolute_error: 3.4055 - val_loss: 30.0417 - val_mean_absolute_error: 4.1181
Epoch 23/1000
20284/20284 - 3034s - loss: 18.7537 - mean_absolute_error: 3.3710 - val_loss: 29.9337 - val_mean_absolute_error: 4.1409
Epoch 24/1000
20284/20284 - 3063s - loss: 18.4518 - mean_absolute_error: 3.3386 - val_loss: 30.7445 - val_mean_absolute_error: 4.0757
Epoch 25/1000
20284/20284 - 3044s - loss: 18.1341 - mean_absolute_error: 3.3041 - val_loss: 30.5580 - val_mean_absolute_error: 4.1295
Epoch 26/1000
20284/20284 - 3033s - loss: 17.8543 - mean_absolute_error: 3.2737 - val_loss: 30.8436 - val_mean_absolute_error: 4.1504
Epoch 27/1000
20284/20284 - 3081s - loss: 17.5519 - mean_absolute_error: 3.2394 - val_loss: 30.7637 - val_mean_absolute_error: 4.2272
Epoch 28/1000
20284/20284 - 3071s - loss: 17.2747 - mean_absolute_error: 3.2081 - val_loss: 31.3056 - val_mean_absolute_error: 4.0946
Epoch 29/1000
20284/20284 - 3054s - loss: 17.0032 - mean_absolute_error: 3.1761 - val_loss: 31.1827 - val_mean_absolute_error: 4.1832
Epoch 30/1000
20284/20284 - 3035s - loss: 16.7471 - mean_absolute_error: 3.1459 - val_loss: 31.3888 - val_mean_absolute_error: 4.1759
Epoch 31/1000
20284/20284 - 3012s - loss: 16.4972 - mean_absolute_error: 3.1171 - val_loss: 31.4655 - val_mean_absolute_error: 4.1388
Epoch 32/1000
20284/20284 - 3019s - loss: 16.2493 - mean_absolute_error: 3.0863 - val_loss: 31.7422 - val_mean_absolute_error: 4.1624
Epoch 00032: early stopping
[92m[INFO] Loading best model...[0m
