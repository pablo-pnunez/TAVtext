[93m[WARNING] Model folder already exists...[0m
[92m[INFO] Loading existing model...[0m
[92m[INFO] Model already trained![0m
[92m[INFO] Loading w2v...[0m
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding (Embedding)        (None, None, 300)         43245900  
_________________________________________________________________
lstm (LSTM)                  (None, 256)               570368    
_________________________________________________________________
dense (Dense)                (None, 128)               32896     
_________________________________________________________________
dense_1 (Dense)              (None, 64)                8256      
_________________________________________________________________
dense_2 (Dense)              (None, 32)                2080      
_________________________________________________________________
dense_3 (Dense)              (None, 16)                528       
_________________________________________________________________
dense_4 (Dense)              (None, 1)                 17        
=================================================================
Total params: 43,860,045
Trainable params: 614,145
Non-trainable params: 43,245,900
_________________________________________________________________
None
[92m[INFO] Not saving the model...[0m
Epoch 1/1000
10142/10142 - 1811s - loss: 50.2066 - mean_absolute_error: 5.0307 - val_loss: 31.3861 - val_mean_absolute_error: 4.3840
Epoch 2/1000
10142/10142 - 1812s - loss: 30.2050 - mean_absolute_error: 4.2699 - val_loss: 30.3142 - val_mean_absolute_error: 4.2560
Epoch 3/1000
10142/10142 - 1815s - loss: 28.4306 - mean_absolute_error: 4.1489 - val_loss: 28.7986 - val_mean_absolute_error: 4.2046
Epoch 4/1000
10142/10142 - 1812s - loss: 27.3062 - mean_absolute_error: 4.0726 - val_loss: 28.3905 - val_mean_absolute_error: 4.1661
Epoch 5/1000
10142/10142 - 1814s - loss: 26.4446 - mean_absolute_error: 4.0148 - val_loss: 28.5558 - val_mean_absolute_error: 4.2259
Epoch 6/1000
10142/10142 - 1815s - loss: 25.6927 - mean_absolute_error: 3.9623 - val_loss: 28.2290 - val_mean_absolute_error: 4.1432
Epoch 7/1000
10142/10142 - 1810s - loss: 24.9944 - mean_absolute_error: 3.9116 - val_loss: 27.8381 - val_mean_absolute_error: 4.0978
Epoch 8/1000
10142/10142 - 1814s - loss: 24.3518 - mean_absolute_error: 3.8649 - val_loss: 27.9602 - val_mean_absolute_error: 4.1505
Epoch 9/1000
10142/10142 - 1808s - loss: 23.7919 - mean_absolute_error: 3.8211 - val_loss: 28.4375 - val_mean_absolute_error: 4.0927
Epoch 10/1000
10142/10142 - 1806s - loss: 23.2250 - mean_absolute_error: 3.7771 - val_loss: 28.2442 - val_mean_absolute_error: 4.0200
Epoch 11/1000
10142/10142 - 1801s - loss: 22.7048 - mean_absolute_error: 3.7379 - val_loss: 28.2238 - val_mean_absolute_error: 4.1013
Epoch 12/1000
10142/10142 - 1801s - loss: 22.2232 - mean_absolute_error: 3.6960 - val_loss: 28.8579 - val_mean_absolute_error: 4.0563
Epoch 13/1000
10142/10142 - 1798s - loss: 21.7744 - mean_absolute_error: 3.6573 - val_loss: 28.5097 - val_mean_absolute_error: 4.0703
Epoch 14/1000
10142/10142 - 1798s - loss: 21.3159 - mean_absolute_error: 3.6166 - val_loss: 28.5563 - val_mean_absolute_error: 4.0243
Epoch 15/1000
10142/10142 - 1799s - loss: 20.9097 - mean_absolute_error: 3.5791 - val_loss: 28.7819 - val_mean_absolute_error: 4.0711
Epoch 16/1000
10142/10142 - 1802s - loss: 20.4111 - mean_absolute_error: 3.5352 - val_loss: 29.1204 - val_mean_absolute_error: 4.1528
Epoch 17/1000
10142/10142 - 1801s - loss: 20.0433 - mean_absolute_error: 3.4993 - val_loss: 29.3631 - val_mean_absolute_error: 4.0908
Epoch 18/1000
10142/10142 - 1801s - loss: 19.6401 - mean_absolute_error: 3.4597 - val_loss: 30.5070 - val_mean_absolute_error: 4.1051
Epoch 19/1000
10142/10142 - 1801s - loss: 19.2400 - mean_absolute_error: 3.4204 - val_loss: 29.8358 - val_mean_absolute_error: 4.1522
Epoch 20/1000
10142/10142 - 1800s - loss: 18.8721 - mean_absolute_error: 3.3824 - val_loss: 30.3085 - val_mean_absolute_error: 4.0613
Epoch 21/1000
10142/10142 - 1801s - loss: 18.5087 - mean_absolute_error: 3.3452 - val_loss: 30.7037 - val_mean_absolute_error: 4.0815
Epoch 22/1000
10142/10142 - 1801s - loss: 18.1664 - mean_absolute_error: 3.3078 - val_loss: 30.8504 - val_mean_absolute_error: 4.0489
Epoch 23/1000
10142/10142 - 1803s - loss: 17.8367 - mean_absolute_error: 3.2706 - val_loss: 31.3989 - val_mean_absolute_error: 4.0999
Epoch 24/1000
10142/10142 - 1803s - loss: 17.4967 - mean_absolute_error: 3.2309 - val_loss: 31.0903 - val_mean_absolute_error: 4.1072
Epoch 25/1000
10142/10142 - 1807s - loss: 17.1800 - mean_absolute_error: 3.1953 - val_loss: 31.2319 - val_mean_absolute_error: 4.1671
Epoch 26/1000
10142/10142 - 1805s - loss: 16.8826 - mean_absolute_error: 3.1607 - val_loss: 31.6480 - val_mean_absolute_error: 4.2014
Epoch 27/1000
10142/10142 - 1801s - loss: 16.5718 - mean_absolute_error: 3.1237 - val_loss: 31.6308 - val_mean_absolute_error: 4.1903
Epoch 28/1000
[93m[WARNING] Model folder already exists...[0m
[92m[INFO] Loading existing model...[0m
[92m[INFO] Model already trained![0m
[93m[WARNING] Model folder already exists...[0m
[92m[INFO] Loading w2v...[0m
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding (Embedding)        (None, None, 300)         43245900  
_________________________________________________________________
lstm (LSTM)                  (None, 256)               570368    
_________________________________________________________________
dense (Dense)                (None, 128)               32896     
_________________________________________________________________
dense_1 (Dense)              (None, 64)                8256      
_________________________________________________________________
dense_2 (Dense)              (None, 32)                2080      
_________________________________________________________________
dense_3 (Dense)              (None, 16)                528       
_________________________________________________________________
dense_4 (Dense)              (None, 1)                 17        
=================================================================
Total params: 43,860,045
Trainable params: 614,145
Non-trainable params: 43,245,900
_________________________________________________________________
None
Epoch 1/1000
10142/10142 - 1789s - loss: 50.2704 - mean_absolute_error: 5.0350 - val_loss: 31.6306 - val_mean_absolute_error: 4.3816
Epoch 2/1000
10142/10142 - 1805s - loss: 30.2365 - mean_absolute_error: 4.2745 - val_loss: 30.1727 - val_mean_absolute_error: 4.2462
Epoch 3/1000
10142/10142 - 1798s - loss: 28.4227 - mean_absolute_error: 4.1461 - val_loss: 28.9062 - val_mean_absolute_error: 4.1826
Epoch 4/1000
10142/10142 - 1801s - loss: 27.2956 - mean_absolute_error: 4.0680 - val_loss: 28.4000 - val_mean_absolute_error: 4.1952
Epoch 5/1000
10142/10142 - 1806s - loss: 26.4014 - mean_absolute_error: 4.0084 - val_loss: 28.3007 - val_mean_absolute_error: 4.1895
Epoch 6/1000
10142/10142 - 1809s - loss: 25.6451 - mean_absolute_error: 3.9552 - val_loss: 28.1595 - val_mean_absolute_error: 4.1438
Epoch 7/1000
10142/10142 - 1804s - loss: 24.9755 - mean_absolute_error: 3.9067 - val_loss: 27.7039 - val_mean_absolute_error: 4.0865
Epoch 8/1000
10142/10142 - 1806s - loss: 24.3414 - mean_absolute_error: 3.8600 - val_loss: 27.9049 - val_mean_absolute_error: 4.1598
Epoch 9/1000
10142/10142 - 1802s - loss: 23.8105 - mean_absolute_error: 3.8204 - val_loss: 28.2264 - val_mean_absolute_error: 4.0772
Epoch 10/1000
10142/10142 - 1804s - loss: 23.2866 - mean_absolute_error: 3.7798 - val_loss: 28.0858 - val_mean_absolute_error: 4.0424
Epoch 11/1000
10142/10142 - 1803s - loss: 22.7487 - mean_absolute_error: 3.7376 - val_loss: 28.1948 - val_mean_absolute_error: 4.1164
Epoch 12/1000
10142/10142 - 1794s - loss: 22.2640 - mean_absolute_error: 3.6977 - val_loss: 28.7100 - val_mean_absolute_error: 4.0432
Epoch 13/1000
10142/10142 - 1787s - loss: 21.8076 - mean_absolute_error: 3.6602 - val_loss: 28.6614 - val_mean_absolute_error: 4.0837
Epoch 14/1000
10142/10142 - 1795s - loss: 21.3423 - mean_absolute_error: 3.6176 - val_loss: 28.7702 - val_mean_absolute_error: 4.0282
Epoch 15/1000
10142/10142 - 1783s - loss: 20.9376 - mean_absolute_error: 3.5830 - val_loss: 28.7718 - val_mean_absolute_error: 4.0629
Epoch 16/1000
10142/10142 - 1787s - loss: 20.4632 - mean_absolute_error: 3.5406 - val_loss: 28.8999 - val_mean_absolute_error: 4.1533
Epoch 17/1000
10142/10142 - 1788s - loss: 20.0580 - mean_absolute_error: 3.5016 - val_loss: 29.2754 - val_mean_absolute_error: 4.0439
Epoch 18/1000
10142/10142 - 1813s - loss: 19.6433 - mean_absolute_error: 3.4614 - val_loss: 29.8214 - val_mean_absolute_error: 4.0509
Epoch 19/1000
10142/10142 - 1780s - loss: 19.2930 - mean_absolute_error: 3.4259 - val_loss: 29.6713 - val_mean_absolute_error: 4.1010
Epoch 20/1000
10142/10142 - 1783s - loss: 18.8794 - mean_absolute_error: 3.3865 - val_loss: 30.2371 - val_mean_absolute_error: 4.0536
Epoch 21/1000
10142/10142 - 1708s - loss: 18.5362 - mean_absolute_error: 3.3501 - val_loss: 30.5826 - val_mean_absolute_error: 4.0623
Epoch 22/1000
10142/10142 - 1595s - loss: 18.1936 - mean_absolute_error: 3.3118 - val_loss: 30.5544 - val_mean_absolute_error: 4.0475
Epoch 23/1000
10142/10142 - 1588s - loss: 17.8587 - mean_absolute_error: 3.2752 - val_loss: 31.2128 - val_mean_absolute_error: 4.0987
Epoch 24/1000
10142/10142 - 1601s - loss: 17.5078 - mean_absolute_error: 3.2351 - val_loss: 31.2059 - val_mean_absolute_error: 4.0836
Epoch 25/1000
10142/10142 - 1590s - loss: 17.2022 - mean_absolute_error: 3.1977 - val_loss: 30.8587 - val_mean_absolute_error: 4.1226
Epoch 26/1000
10142/10142 - 1591s - loss: 16.8953 - mean_absolute_error: 3.1623 - val_loss: 32.1507 - val_mean_absolute_error: 4.2661
Epoch 27/1000
10142/10142 - 1588s - loss: 16.6127 - mean_absolute_error: 3.1258 - val_loss: 31.8951 - val_mean_absolute_error: 4.1357
Epoch 28/1000
10142/10142 - 1589s - loss: 16.3258 - mean_absolute_error: 3.0921 - val_loss: 31.9796 - val_mean_absolute_error: 4.1478
Epoch 29/1000
10142/10142 - 1589s - loss: 16.0618 - mean_absolute_error: 3.0557 - val_loss: 32.5448 - val_mean_absolute_error: 4.1284
Epoch 30/1000
10142/10142 - 1596s - loss: 15.7699 - mean_absolute_error: 3.0201 - val_loss: 32.4227 - val_mean_absolute_error: 4.2811
Epoch 31/1000
10142/10142 - 1586s - loss: 15.5127 - mean_absolute_error: 2.9850 - val_loss: 32.6672 - val_mean_absolute_error: 4.1260
Epoch 32/1000
10142/10142 - 1589s - loss: 15.2663 - mean_absolute_error: 2.9516 - val_loss: 32.5967 - val_mean_absolute_error: 4.1237
Epoch 33/1000
10142/10142 - 1592s - loss: 15.0131 - mean_absolute_error: 2.9172 - val_loss: 33.2085 - val_mean_absolute_error: 4.2817
Epoch 34/1000
10142/10142 - 1592s - loss: 14.7570 - mean_absolute_error: 2.8813 - val_loss: 33.0325 - val_mean_absolute_error: 4.1755
Epoch 00034: early stopping
[92m[INFO] Loading best model...[0m
