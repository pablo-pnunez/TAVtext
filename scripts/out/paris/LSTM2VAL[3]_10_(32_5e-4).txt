[93m[WARNING] Model folder already exists...[0m
[92m[INFO] Loading existing model...[0m
[92m[INFO] Model already trained![0m
[92m[INFO] Loading w2v...[0m
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding (Embedding)        (None, None, 300)         43245900  
_________________________________________________________________
lstm (LSTM)                  (None, 256)               570368    
_________________________________________________________________
dense (Dense)                (None, 128)               32896     
_________________________________________________________________
dense_1 (Dense)              (None, 64)                8256      
_________________________________________________________________
dense_2 (Dense)              (None, 32)                2080      
_________________________________________________________________
dense_3 (Dense)              (None, 16)                528       
_________________________________________________________________
dense_4 (Dense)              (None, 1)                 17        
=================================================================
Total params: 43,860,045
Trainable params: 614,145
Non-trainable params: 43,245,900
_________________________________________________________________
None
[92m[INFO] Not saving the model...[0m
Epoch 1/1000
20284/20284 - 3615s - loss: 37.4579 - mean_absolute_error: 4.6665 - val_loss: 31.4878 - val_mean_absolute_error: 4.4828
Epoch 2/1000
20284/20284 - 3612s - loss: 30.6425 - mean_absolute_error: 4.3047 - val_loss: 30.3939 - val_mean_absolute_error: 4.2146
Epoch 3/1000
20284/20284 - 3609s - loss: 29.4738 - mean_absolute_error: 4.2250 - val_loss: 29.6446 - val_mean_absolute_error: 4.2705
Epoch 4/1000
20284/20284 - 3606s - loss: 28.7145 - mean_absolute_error: 4.1779 - val_loss: 30.0999 - val_mean_absolute_error: 4.3826
Epoch 5/1000
20284/20284 - 3607s - loss: 28.1186 - mean_absolute_error: 4.1328 - val_loss: 29.3644 - val_mean_absolute_error: 4.1768
Epoch 6/1000
20284/20284 - 3598s - loss: 27.6672 - mean_absolute_error: 4.1048 - val_loss: 29.6815 - val_mean_absolute_error: 4.2753
Epoch 7/1000
20284/20284 - 3593s - loss: 27.3216 - mean_absolute_error: 4.0795 - val_loss: 29.2156 - val_mean_absolute_error: 4.1817
Epoch 8/1000
20284/20284 - 3609s - loss: 26.9966 - mean_absolute_error: 4.0563 - val_loss: 29.2860 - val_mean_absolute_error: 4.2290
Epoch 9/1000
20284/20284 - 3591s - loss: 26.6767 - mean_absolute_error: 4.0357 - val_loss: 29.6009 - val_mean_absolute_error: 4.1964
Epoch 10/1000
20284/20284 - 3593s - loss: 26.4368 - mean_absolute_error: 4.0178 - val_loss: 30.0459 - val_mean_absolute_error: 4.3190
Epoch 11/1000
20284/20284 - 3594s - loss: 26.1961 - mean_absolute_error: 4.0009 - val_loss: 29.8427 - val_mean_absolute_error: 4.1192
Epoch 12/1000
20284/20284 - 3594s - loss: 25.9396 - mean_absolute_error: 3.9868 - val_loss: 29.7712 - val_mean_absolute_error: 4.1294
Epoch 13/1000
20284/20284 - 3591s - loss: 25.7829 - mean_absolute_error: 3.9700 - val_loss: 29.1958 - val_mean_absolute_error: 4.1633
Epoch 14/1000
[93m[WARNING] Model folder already exists...[0m
[92m[INFO] Loading existing model...[0m
[92m[INFO] Model already trained![0m
[93m[WARNING] Model folder already exists...[0m
[92m[INFO] Loading w2v...[0m
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding (Embedding)        (None, None, 300)         43245900  
_________________________________________________________________
lstm (LSTM)                  (None, 256)               570368    
_________________________________________________________________
dense (Dense)                (None, 128)               32896     
_________________________________________________________________
dense_1 (Dense)              (None, 64)                8256      
_________________________________________________________________
dense_2 (Dense)              (None, 32)                2080      
_________________________________________________________________
dense_3 (Dense)              (None, 16)                528       
_________________________________________________________________
dense_4 (Dense)              (None, 1)                 17        
=================================================================
Total params: 43,860,045
Trainable params: 614,145
Non-trainable params: 43,245,900
_________________________________________________________________
None
Epoch 1/1000
20284/20284 - 3190s - loss: 37.4128 - mean_absolute_error: 4.6669 - val_loss: 31.4029 - val_mean_absolute_error: 4.4729
Epoch 2/1000
20284/20284 - 3179s - loss: 30.5828 - mean_absolute_error: 4.3088 - val_loss: 30.5126 - val_mean_absolute_error: 4.2002
Epoch 3/1000
20284/20284 - 3171s - loss: 29.4824 - mean_absolute_error: 4.2298 - val_loss: 29.7505 - val_mean_absolute_error: 4.2665
Epoch 4/1000
20284/20284 - 3150s - loss: 28.6914 - mean_absolute_error: 4.1786 - val_loss: 30.1276 - val_mean_absolute_error: 4.3994
Epoch 5/1000
20284/20284 - 2938s - loss: 28.0544 - mean_absolute_error: 4.1309 - val_loss: 29.3303 - val_mean_absolute_error: 4.1362
Epoch 6/1000
20284/20284 - 2937s - loss: 27.6244 - mean_absolute_error: 4.1021 - val_loss: 29.3830 - val_mean_absolute_error: 4.2504
Epoch 7/1000
20284/20284 - 2918s - loss: 27.2276 - mean_absolute_error: 4.0763 - val_loss: 29.0649 - val_mean_absolute_error: 4.1737
Epoch 8/1000
20284/20284 - 2946s - loss: 26.9559 - mean_absolute_error: 4.0535 - val_loss: 28.9352 - val_mean_absolute_error: 4.1952
Epoch 9/1000
20284/20284 - 2948s - loss: 26.6384 - mean_absolute_error: 4.0321 - val_loss: 29.2614 - val_mean_absolute_error: 4.1094
Epoch 10/1000
20284/20284 - 2939s - loss: 26.3842 - mean_absolute_error: 4.0143 - val_loss: 30.2047 - val_mean_absolute_error: 4.3159
Epoch 11/1000
20284/20284 - 2945s - loss: 26.1376 - mean_absolute_error: 3.9920 - val_loss: 29.1091 - val_mean_absolute_error: 4.0843
Epoch 12/1000
20284/20284 - 2927s - loss: 25.9121 - mean_absolute_error: 3.9779 - val_loss: 29.6431 - val_mean_absolute_error: 4.0720
Epoch 13/1000
20284/20284 - 2962s - loss: 25.7310 - mean_absolute_error: 3.9618 - val_loss: 29.1718 - val_mean_absolute_error: 4.1320
Epoch 14/1000
20284/20284 - 2949s - loss: 25.5222 - mean_absolute_error: 3.9513 - val_loss: 29.1135 - val_mean_absolute_error: 4.2053
Epoch 15/1000
20284/20284 - 2976s - loss: 25.3730 - mean_absolute_error: 3.9383 - val_loss: 29.8478 - val_mean_absolute_error: 4.3533
Epoch 16/1000
20284/20284 - 2689s - loss: 25.0894 - mean_absolute_error: 3.9194 - val_loss: 29.2829 - val_mean_absolute_error: 4.1127
Epoch 17/1000
20284/20284 - 2467s - loss: 25.0073 - mean_absolute_error: 3.9129 - val_loss: 29.8738 - val_mean_absolute_error: 4.2692
Epoch 18/1000
20284/20284 - 2495s - loss: 24.8864 - mean_absolute_error: 3.9027 - val_loss: 29.1654 - val_mean_absolute_error: 4.2203
Epoch 19/1000
20284/20284 - 2424s - loss: 24.7671 - mean_absolute_error: 3.8904 - val_loss: 29.3287 - val_mean_absolute_error: 4.1984
Epoch 20/1000
20284/20284 - 2482s - loss: 24.6313 - mean_absolute_error: 3.8807 - val_loss: 29.3224 - val_mean_absolute_error: 4.1734
Epoch 21/1000
20284/20284 - 2467s - loss: 24.4625 - mean_absolute_error: 3.8689 - val_loss: 29.3754 - val_mean_absolute_error: 4.1112
Epoch 22/1000
20284/20284 - 2439s - loss: 24.3230 - mean_absolute_error: 3.8594 - val_loss: 29.5302 - val_mean_absolute_error: 4.2111
Epoch 23/1000
20284/20284 - 2452s - loss: 24.1617 - mean_absolute_error: 3.8461 - val_loss: 29.8496 - val_mean_absolute_error: 4.2500
Epoch 24/1000
20284/20284 - 2459s - loss: 24.0867 - mean_absolute_error: 3.8390 - val_loss: 30.0226 - val_mean_absolute_error: 4.0848
Epoch 25/1000
20284/20284 - 2556s - loss: 23.9677 - mean_absolute_error: 3.8269 - val_loss: 29.7839 - val_mean_absolute_error: 4.1087
Epoch 26/1000
20284/20284 - 2554s - loss: 23.9168 - mean_absolute_error: 3.8258 - val_loss: 29.5176 - val_mean_absolute_error: 4.0968
Epoch 27/1000
20284/20284 - 2554s - loss: 23.8450 - mean_absolute_error: 3.8201 - val_loss: 30.0241 - val_mean_absolute_error: 4.3202
Epoch 28/1000
20284/20284 - 2557s - loss: 23.7552 - mean_absolute_error: 3.8096 - val_loss: 29.7606 - val_mean_absolute_error: 4.0955
Epoch 29/1000
20284/20284 - 2553s - loss: 23.6149 - mean_absolute_error: 3.8005 - val_loss: 29.6098 - val_mean_absolute_error: 4.1891
Epoch 30/1000
20284/20284 - 2555s - loss: 23.5107 - mean_absolute_error: 3.7926 - val_loss: 29.7268 - val_mean_absolute_error: 4.2036
Epoch 31/1000
20284/20284 - 2554s - loss: 23.4379 - mean_absolute_error: 3.7861 - val_loss: 29.7079 - val_mean_absolute_error: 4.1763
Epoch 32/1000
20284/20284 - 2554s - loss: 23.4244 - mean_absolute_error: 3.7869 - val_loss: 29.7834 - val_mean_absolute_error: 4.1763
Epoch 00032: early stopping
[92m[INFO] Loading best model...[0m
