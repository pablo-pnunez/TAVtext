[93m[WARNING] Model folder already exists...[0m
[92m[INFO] Loading existing model...[0m
[92m[INFO] Model already trained![0m
[92m[INFO] Loading w2v...[0m
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding (Embedding)        (None, None, 300)         43245900  
_________________________________________________________________
lstm (LSTM)                  (None, 256)               570368    
_________________________________________________________________
dense (Dense)                (None, 128)               32896     
_________________________________________________________________
dense_1 (Dense)              (None, 64)                8256      
_________________________________________________________________
dense_2 (Dense)              (None, 32)                2080      
_________________________________________________________________
dense_3 (Dense)              (None, 16)                528       
_________________________________________________________________
dense_4 (Dense)              (None, 1)                 17        
=================================================================
Total params: 43,860,045
Trainable params: 614,145
Non-trainable params: 43,245,900
_________________________________________________________________
None
[92m[INFO] Not saving the model...[0m
Epoch 1/1000
10142/10142 - 1819s - loss: 62.1315 - mean_absolute_error: 5.4214 - val_loss: 33.3708 - val_mean_absolute_error: 4.5048
Epoch 2/1000
10142/10142 - 1816s - loss: 31.9810 - mean_absolute_error: 4.3914 - val_loss: 31.6656 - val_mean_absolute_error: 4.3244
Epoch 3/1000
10142/10142 - 1812s - loss: 29.8338 - mean_absolute_error: 4.2501 - val_loss: 29.9533 - val_mean_absolute_error: 4.2843
Epoch 4/1000
10142/10142 - 1814s - loss: 28.5395 - mean_absolute_error: 4.1591 - val_loss: 29.1455 - val_mean_absolute_error: 4.1907
Epoch 5/1000
10142/10142 - 1811s - loss: 27.6199 - mean_absolute_error: 4.0974 - val_loss: 29.0279 - val_mean_absolute_error: 4.2554
Epoch 6/1000
10142/10142 - 1806s - loss: 26.8781 - mean_absolute_error: 4.0449 - val_loss: 28.4345 - val_mean_absolute_error: 4.1151
Epoch 7/1000
10142/10142 - 1809s - loss: 26.2511 - mean_absolute_error: 3.9999 - val_loss: 28.2372 - val_mean_absolute_error: 4.1022
Epoch 8/1000
10142/10142 - 1807s - loss: 25.6658 - mean_absolute_error: 3.9579 - val_loss: 28.6529 - val_mean_absolute_error: 4.2268
Epoch 9/1000
10142/10142 - 1815s - loss: 25.1803 - mean_absolute_error: 3.9223 - val_loss: 27.9770 - val_mean_absolute_error: 4.0799
Epoch 10/1000
10142/10142 - 1803s - loss: 24.6795 - mean_absolute_error: 3.8883 - val_loss: 28.2790 - val_mean_absolute_error: 4.1109
Epoch 11/1000
10142/10142 - 1812s - loss: 24.2365 - mean_absolute_error: 3.8550 - val_loss: 28.2019 - val_mean_absolute_error: 4.1350
Epoch 12/1000
10142/10142 - 1802s - loss: 23.8153 - mean_absolute_error: 3.8226 - val_loss: 28.4386 - val_mean_absolute_error: 4.1057
Epoch 13/1000
10142/10142 - 1809s - loss: 23.4222 - mean_absolute_error: 3.7910 - val_loss: 28.3918 - val_mean_absolute_error: 4.1331
Epoch 14/1000
10142/10142 - 1808s - loss: 23.0482 - mean_absolute_error: 3.7625 - val_loss: 28.7943 - val_mean_absolute_error: 4.0545
Epoch 15/1000
10142/10142 - 1813s - loss: 22.6815 - mean_absolute_error: 3.7322 - val_loss: 28.3899 - val_mean_absolute_error: 4.0532
Epoch 16/1000
10142/10142 - 1806s - loss: 22.3157 - mean_absolute_error: 3.7015 - val_loss: 28.5562 - val_mean_absolute_error: 4.1523
Epoch 17/1000
10142/10142 - 1801s - loss: 22.0037 - mean_absolute_error: 3.6756 - val_loss: 28.9171 - val_mean_absolute_error: 4.0818
Epoch 18/1000
10142/10142 - 1799s - loss: 21.6710 - mean_absolute_error: 3.6470 - val_loss: 29.2427 - val_mean_absolute_error: 4.0662
Epoch 19/1000
10142/10142 - 1802s - loss: 21.3144 - mean_absolute_error: 3.6149 - val_loss: 28.9071 - val_mean_absolute_error: 4.1033
Epoch 20/1000
10142/10142 - 1797s - loss: 21.0109 - mean_absolute_error: 3.5882 - val_loss: 29.4329 - val_mean_absolute_error: 4.0598
Epoch 21/1000
10142/10142 - 1802s - loss: 20.6623 - mean_absolute_error: 3.5567 - val_loss: 29.9543 - val_mean_absolute_error: 4.0852
Epoch 22/1000
10142/10142 - 1797s - loss: 20.3894 - mean_absolute_error: 3.5309 - val_loss: 29.7764 - val_mean_absolute_error: 4.0290
Epoch 23/1000
10142/10142 - 1799s - loss: 20.1056 - mean_absolute_error: 3.5043 - val_loss: 30.0740 - val_mean_absolute_error: 4.1114
Epoch 24/1000
10142/10142 - 1797s - loss: 19.8171 - mean_absolute_error: 3.4775 - val_loss: 29.8384 - val_mean_absolute_error: 4.0770
Epoch 25/1000
10142/10142 - 1798s - loss: 19.5402 - mean_absolute_error: 3.4486 - val_loss: 30.5240 - val_mean_absolute_error: 4.1633
Epoch 26/1000
10142/10142 - 1796s - loss: 19.2669 - mean_absolute_error: 3.4232 - val_loss: 30.3734 - val_mean_absolute_error: 4.1462
Epoch 27/1000
10142/10142 - 1806s - loss: 18.9825 - mean_absolute_error: 3.3943 - val_loss: 30.7176 - val_mean_absolute_error: 4.1781
Epoch 28/1000
[93m[WARNING] Model folder already exists...[0m
[92m[INFO] Loading existing model...[0m
[92m[INFO] Model already trained![0m
[93m[WARNING] Model folder already exists...[0m
[92m[INFO] Loading w2v...[0m
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding (Embedding)        (None, None, 300)         43245900  
_________________________________________________________________
lstm (LSTM)                  (None, 256)               570368    
_________________________________________________________________
dense (Dense)                (None, 128)               32896     
_________________________________________________________________
dense_1 (Dense)              (None, 64)                8256      
_________________________________________________________________
dense_2 (Dense)              (None, 32)                2080      
_________________________________________________________________
dense_3 (Dense)              (None, 16)                528       
_________________________________________________________________
dense_4 (Dense)              (None, 1)                 17        
=================================================================
Total params: 43,860,045
Trainable params: 614,145
Non-trainable params: 43,245,900
_________________________________________________________________
None
Epoch 1/1000
10142/10142 - 1621s - loss: 62.1229 - mean_absolute_error: 5.4238 - val_loss: 33.5955 - val_mean_absolute_error: 4.4859
Epoch 2/1000
10142/10142 - 1615s - loss: 31.9004 - mean_absolute_error: 4.3889 - val_loss: 31.5017 - val_mean_absolute_error: 4.2950
Epoch 3/1000
10142/10142 - 1622s - loss: 29.8012 - mean_absolute_error: 4.2481 - val_loss: 30.3493 - val_mean_absolute_error: 4.3095
Epoch 4/1000
10142/10142 - 1622s - loss: 28.5563 - mean_absolute_error: 4.1608 - val_loss: 29.3414 - val_mean_absolute_error: 4.2073
Epoch 5/1000
10142/10142 - 1612s - loss: 27.6162 - mean_absolute_error: 4.0974 - val_loss: 29.1655 - val_mean_absolute_error: 4.2617
Epoch 6/1000
10142/10142 - 1613s - loss: 26.8877 - mean_absolute_error: 4.0455 - val_loss: 28.5368 - val_mean_absolute_error: 4.1145
Epoch 7/1000
10142/10142 - 1611s - loss: 26.2211 - mean_absolute_error: 3.9996 - val_loss: 28.1776 - val_mean_absolute_error: 4.1106
Epoch 8/1000
10142/10142 - 1613s - loss: 25.6534 - mean_absolute_error: 3.9586 - val_loss: 28.5663 - val_mean_absolute_error: 4.1987
Epoch 9/1000
10142/10142 - 1613s - loss: 25.1707 - mean_absolute_error: 3.9245 - val_loss: 27.9997 - val_mean_absolute_error: 4.0955
Epoch 10/1000
10142/10142 - 1611s - loss: 24.6994 - mean_absolute_error: 3.8917 - val_loss: 28.4261 - val_mean_absolute_error: 4.1052
Epoch 11/1000
10142/10142 - 1614s - loss: 24.2619 - mean_absolute_error: 3.8602 - val_loss: 28.0593 - val_mean_absolute_error: 4.1168
Epoch 12/1000
10142/10142 - 1610s - loss: 23.8416 - mean_absolute_error: 3.8267 - val_loss: 28.3712 - val_mean_absolute_error: 4.0605
Epoch 13/1000
10142/10142 - 1619s - loss: 23.4590 - mean_absolute_error: 3.7967 - val_loss: 28.2347 - val_mean_absolute_error: 4.1365
Epoch 14/1000
10142/10142 - 1617s - loss: 23.0695 - mean_absolute_error: 3.7657 - val_loss: 28.2427 - val_mean_absolute_error: 4.0472
Epoch 15/1000
10142/10142 - 1616s - loss: 22.7069 - mean_absolute_error: 3.7361 - val_loss: 28.4386 - val_mean_absolute_error: 4.1203
Epoch 16/1000
10142/10142 - 1599s - loss: 22.3388 - mean_absolute_error: 3.7076 - val_loss: 28.4921 - val_mean_absolute_error: 4.1664
Epoch 17/1000
10142/10142 - 1593s - loss: 22.0149 - mean_absolute_error: 3.6802 - val_loss: 28.7219 - val_mean_absolute_error: 4.0558
Epoch 18/1000
10142/10142 - 1599s - loss: 21.6543 - mean_absolute_error: 3.6504 - val_loss: 28.9982 - val_mean_absolute_error: 4.0649
Epoch 19/1000
10142/10142 - 1589s - loss: 21.3114 - mean_absolute_error: 3.6197 - val_loss: 28.8713 - val_mean_absolute_error: 4.0910
Epoch 20/1000
10142/10142 - 1589s - loss: 20.9880 - mean_absolute_error: 3.5919 - val_loss: 29.2907 - val_mean_absolute_error: 4.0524
Epoch 21/1000
10142/10142 - 1590s - loss: 20.6515 - mean_absolute_error: 3.5619 - val_loss: 30.0181 - val_mean_absolute_error: 4.0556
Epoch 22/1000
10142/10142 - 1591s - loss: 20.3349 - mean_absolute_error: 3.5335 - val_loss: 29.8217 - val_mean_absolute_error: 4.0428
Epoch 23/1000
10142/10142 - 1590s - loss: 20.0615 - mean_absolute_error: 3.5080 - val_loss: 29.7625 - val_mean_absolute_error: 4.0978
Epoch 24/1000
10142/10142 - 1769s - loss: 19.7358 - mean_absolute_error: 3.4769 - val_loss: 29.9519 - val_mean_absolute_error: 4.1061
Epoch 25/1000
10142/10142 - 1784s - loss: 19.4889 - mean_absolute_error: 3.4514 - val_loss: 30.2032 - val_mean_absolute_error: 4.0982
Epoch 26/1000
10142/10142 - 1779s - loss: 19.1738 - mean_absolute_error: 3.4218 - val_loss: 30.5012 - val_mean_absolute_error: 4.1739
Epoch 27/1000
10142/10142 - 1783s - loss: 18.9255 - mean_absolute_error: 3.3958 - val_loss: 30.9243 - val_mean_absolute_error: 4.2178
Epoch 28/1000
10142/10142 - 1787s - loss: 18.6524 - mean_absolute_error: 3.3685 - val_loss: 31.4152 - val_mean_absolute_error: 4.1534
Epoch 29/1000
10142/10142 - 1784s - loss: 18.4354 - mean_absolute_error: 3.3440 - val_loss: 31.4090 - val_mean_absolute_error: 4.1149
Epoch 30/1000
10142/10142 - 1777s - loss: 18.1886 - mean_absolute_error: 3.3184 - val_loss: 32.1750 - val_mean_absolute_error: 4.3305
Epoch 31/1000
10142/10142 - 1786s - loss: 17.9531 - mean_absolute_error: 3.2954 - val_loss: 31.2805 - val_mean_absolute_error: 4.1297
Epoch 32/1000
10142/10142 - 1779s - loss: 17.7252 - mean_absolute_error: 3.2692 - val_loss: 31.3060 - val_mean_absolute_error: 4.1673
Epoch 33/1000
10142/10142 - 1788s - loss: 17.4898 - mean_absolute_error: 3.2432 - val_loss: 32.1777 - val_mean_absolute_error: 4.2391
Epoch 34/1000
10142/10142 - 1779s - loss: 17.2664 - mean_absolute_error: 3.2188 - val_loss: 32.0967 - val_mean_absolute_error: 4.1791
Epoch 35/1000
10142/10142 - 1786s - loss: 17.0409 - mean_absolute_error: 3.1923 - val_loss: 31.9403 - val_mean_absolute_error: 4.1639
Epoch 36/1000
10142/10142 - 1774s - loss: 16.8445 - mean_absolute_error: 3.1699 - val_loss: 32.2056 - val_mean_absolute_error: 4.2551
Epoch 37/1000
10142/10142 - 1784s - loss: 16.6422 - mean_absolute_error: 3.1452 - val_loss: 32.3400 - val_mean_absolute_error: 4.2396
Epoch 38/1000
10142/10142 - 1780s - loss: 16.4565 - mean_absolute_error: 3.1232 - val_loss: 32.9068 - val_mean_absolute_error: 4.1677
Epoch 39/1000
10142/10142 - 1785s - loss: 16.2769 - mean_absolute_error: 3.1025 - val_loss: 32.9177 - val_mean_absolute_error: 4.2798
Epoch 40/1000
10142/10142 - 1815s - loss: 16.0712 - mean_absolute_error: 3.0778 - val_loss: 33.3615 - val_mean_absolute_error: 4.2000
Epoch 41/1000
10142/10142 - 1783s - loss: 15.8804 - mean_absolute_error: 3.0540 - val_loss: 32.7177 - val_mean_absolute_error: 4.2392
Epoch 42/1000
10142/10142 - 1788s - loss: 15.7092 - mean_absolute_error: 3.0329 - val_loss: 33.1703 - val_mean_absolute_error: 4.2215
Epoch 00042: early stopping
[92m[INFO] Loading best model...[0m
