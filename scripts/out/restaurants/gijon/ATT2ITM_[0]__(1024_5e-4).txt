Model: "ATT2ITM_0"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 162)]        0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 149)]        0           []                               
                                                                                                  
 embedding (Embedding)          (None, 162, 384)     926976      ['input_1[0][0]']                
                                                                                                  
 in_rsts (Embedding)            (None, 149, 384)     57216       ['input_2[0][0]']                
                                                                                                  
 dense (Dense)                  (None, 162, 256)     98560       ['embedding[0][0]']              
                                                                                                  
 dense_2 (Dense)                (None, 149, 256)     98560       ['in_rsts[0][0]']                
                                                                                                  
 tf.math.not_equal (TFOpLambda)  (None, 162)         0           ['input_1[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 162, 128)     32896       ['dense[0][0]']                  
                                                                                                  
 dense_3 (Dense)                (None, 149, 128)     32896       ['dense_2[0][0]']                
                                                                                                  
 tf.cast (TFOpLambda)           (None, 162)          0           ['tf.math.not_equal[0][0]']      
                                                                                                  
 word_emb (Lambda)              (None, 162, 128)     0           ['dense_1[0][0]']                
                                                                                                  
 rest_emb (Lambda)              (None, 149, 128)     0           ['dense_3[0][0]']                
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 162, 1)       0           ['tf.cast[0][0]']                
                                                                                                  
 lambda (Lambda)                (None, 162, 149)     0           ['word_emb[0][0]',               
                                                                  'rest_emb[0][0]']               
                                                                                                  
 tf.tile (TFOpLambda)           (None, 162, 149)     0           ['tf.expand_dims[0][0]']         
                                                                                                  
 lambda_1 (Lambda)              (None, 162, 149)     0           ['lambda[0][0]',                 
                                                                  'tf.tile[0][0]']                
                                                                                                  
 dotprod (Activation)           (None, 162, 149)     0           ['lambda_1[0][0]']               
                                                                                                  
 dropout (Dropout)              (None, 162, 149)     0           ['dotprod[0][0]']                
                                                                                                  
 sum (Lambda)                   (None, 149)          0           ['dropout[0][0]']                
                                                                                                  
 out (Activation)               (None, 149)          0           ['sum[0][0]']                    
                                                                                                  
==================================================================================================
Total params: 1,247,104
Trainable params: 1,247,104
Non-trainable params: 0
__________________________________________________________________________________________________
None
Epoch 1/1000
32/32 - 5s - loss: 4.6912 - r1: 0.0783 - r5: 0.2084 - r10: 0.2888 - p5: 0.0417 - p10: 0.0289 - val_loss: 4.3696 - val_r1: 0.1385 - val_r5: 0.2902 - val_r10: 0.3804 - val_p5: 0.0580 - val_p10: 0.0380 - lr: 4.9951e-04 - 5s/epoch - 150ms/step
Epoch 2/1000
32/32 - 2s - loss: 4.0438 - r1: 0.1595 - r5: 0.3490 - r10: 0.4562 - p5: 0.0698 - p10: 0.0456 - val_loss: 3.6851 - val_r1: 0.2511 - val_r5: 0.4752 - val_r10: 0.5848 - val_p5: 0.0951 - val_p10: 0.0585 - lr: 4.9901e-04 - 2s/epoch - 51ms/step
Epoch 3/1000
32/32 - 2s - loss: 3.5764 - r1: 0.2276 - r5: 0.4524 - r10: 0.5710 - p5: 0.0905 - p10: 0.0571 - val_loss: 3.3509 - val_r1: 0.3070 - val_r5: 0.5428 - val_r10: 0.6572 - val_p5: 0.1086 - val_p10: 0.0657 - lr: 4.9852e-04 - 2s/epoch - 56ms/step
Epoch 4/1000
32/32 - 2s - loss: 3.3021 - r1: 0.2691 - r5: 0.5089 - r10: 0.6313 - p5: 0.1018 - p10: 0.0631 - val_loss: 3.1439 - val_r1: 0.3316 - val_r5: 0.5731 - val_r10: 0.6854 - val_p5: 0.1147 - val_p10: 0.0685 - lr: 4.9802e-04 - 2s/epoch - 55ms/step
Epoch 5/1000
32/32 - 2s - loss: 3.0896 - r1: 0.3055 - r5: 0.5562 - r10: 0.6701 - p5: 0.1112 - p10: 0.0670 - val_loss: 2.9925 - val_r1: 0.3545 - val_r5: 0.5959 - val_r10: 0.7034 - val_p5: 0.1192 - val_p10: 0.0703 - lr: 4.9753e-04 - 2s/epoch - 56ms/step
Epoch 6/1000
32/32 - 2s - loss: 2.9473 - r1: 0.3268 - r5: 0.5820 - r10: 0.6986 - p5: 0.1164 - p10: 0.0699 - val_loss: 2.9210 - val_r1: 0.3649 - val_r5: 0.6064 - val_r10: 0.7128 - val_p5: 0.1213 - val_p10: 0.0713 - lr: 4.9703e-04 - 2s/epoch - 55ms/step
Epoch 7/1000
32/32 - 2s - loss: 2.8476 - r1: 0.3481 - r5: 0.6013 - r10: 0.7128 - p5: 0.1203 - p10: 0.0713 - val_loss: 2.8868 - val_r1: 0.3713 - val_r5: 0.6132 - val_r10: 0.7174 - val_p5: 0.1226 - val_p10: 0.0717 - lr: 4.9654e-04 - 2s/epoch - 56ms/step
Epoch 8/1000
32/32 - 2s - loss: 2.7729 - r1: 0.3613 - r5: 0.6147 - r10: 0.7240 - p5: 0.1229 - p10: 0.0724 - val_loss: 2.8504 - val_r1: 0.3753 - val_r5: 0.6168 - val_r10: 0.7238 - val_p5: 0.1234 - val_p10: 0.0724 - lr: 4.9604e-04 - 2s/epoch - 56ms/step
Epoch 9/1000
32/32 - 2s - loss: 2.6873 - r1: 0.3735 - r5: 0.6367 - r10: 0.7436 - p5: 0.1273 - p10: 0.0744 - val_loss: 2.8191 - val_r1: 0.3799 - val_r5: 0.6180 - val_r10: 0.7304 - val_p5: 0.1236 - val_p10: 0.0730 - lr: 4.9555e-04 - 2s/epoch - 56ms/step
Epoch 10/1000
32/32 - 2s - loss: 2.6270 - r1: 0.3838 - r5: 0.6445 - r10: 0.7502 - p5: 0.1289 - p10: 0.0750 - val_loss: 2.8001 - val_r1: 0.3853 - val_r5: 0.6198 - val_r10: 0.7273 - val_p5: 0.1240 - val_p10: 0.0727 - lr: 4.9505e-04 - 2s/epoch - 56ms/step
Epoch 11/1000
32/32 - 2s - loss: 2.5730 - r1: 0.3933 - r5: 0.6592 - r10: 0.7603 - p5: 0.1318 - p10: 0.0760 - val_loss: 2.7952 - val_r1: 0.3863 - val_r5: 0.6267 - val_r10: 0.7301 - val_p5: 0.1253 - val_p10: 0.0730 - lr: 4.9456e-04 - 2s/epoch - 55ms/step
Epoch 12/1000
32/32 - 2s - loss: 2.5186 - r1: 0.4031 - r5: 0.6689 - r10: 0.7723 - p5: 0.1338 - p10: 0.0772 - val_loss: 2.7798 - val_r1: 0.3865 - val_r5: 0.6249 - val_r10: 0.7339 - val_p5: 0.1250 - val_p10: 0.0734 - lr: 4.9406e-04 - 2s/epoch - 56ms/step
Epoch 13/1000
32/32 - 2s - loss: 2.4896 - r1: 0.4089 - r5: 0.6718 - r10: 0.7758 - p5: 0.1344 - p10: 0.0776 - val_loss: 2.7781 - val_r1: 0.3878 - val_r5: 0.6221 - val_r10: 0.7304 - val_p5: 0.1244 - val_p10: 0.0730 - lr: 4.9357e-04 - 2s/epoch - 56ms/step
Epoch 14/1000
32/32 - 2s - loss: 2.4337 - r1: 0.4198 - r5: 0.6835 - r10: 0.7853 - p5: 0.1367 - p10: 0.0785 - val_loss: 2.7808 - val_r1: 0.3848 - val_r5: 0.6236 - val_r10: 0.7286 - val_p5: 0.1247 - val_p10: 0.0729 - lr: 4.9307e-04 - 2s/epoch - 50ms/step
Epoch 15/1000
32/32 - 2s - loss: 2.4044 - r1: 0.4255 - r5: 0.6913 - r10: 0.7877 - p5: 0.1383 - p10: 0.0788 - val_loss: 2.7774 - val_r1: 0.3863 - val_r5: 0.6221 - val_r10: 0.7273 - val_p5: 0.1245 - val_p10: 0.0728 - lr: 4.9258e-04 - 2s/epoch - 56ms/step
Epoch 16/1000
32/32 - 2s - loss: 2.3514 - r1: 0.4387 - r5: 0.7001 - r10: 0.7986 - p5: 0.1400 - p10: 0.0799 - val_loss: 2.7742 - val_r1: 0.3896 - val_r5: 0.6206 - val_r10: 0.7288 - val_p5: 0.1241 - val_p10: 0.0729 - lr: 4.9208e-04 - 2s/epoch - 56ms/step
Epoch 17/1000
32/32 - 2s - loss: 2.3167 - r1: 0.4417 - r5: 0.7070 - r10: 0.8039 - p5: 0.1414 - p10: 0.0804 - val_loss: 2.7652 - val_r1: 0.3944 - val_r5: 0.6254 - val_r10: 0.7304 - val_p5: 0.1251 - val_p10: 0.0730 - lr: 4.9159e-04 - 2s/epoch - 56ms/step
Epoch 18/1000
32/32 - 2s - loss: 2.2884 - r1: 0.4446 - r5: 0.7159 - r10: 0.8098 - p5: 0.1432 - p10: 0.0810 - val_loss: 2.7733 - val_r1: 0.3850 - val_r5: 0.6226 - val_r10: 0.7273 - val_p5: 0.1245 - val_p10: 0.0727 - lr: 4.9109e-04 - 2s/epoch - 50ms/step
Epoch 19/1000
32/32 - 2s - loss: 2.2584 - r1: 0.4550 - r5: 0.7165 - r10: 0.8122 - p5: 0.1433 - p10: 0.0812 - val_loss: 2.7920 - val_r1: 0.3827 - val_r5: 0.6147 - val_r10: 0.7291 - val_p5: 0.1229 - val_p10: 0.0729 - lr: 4.9060e-04 - 2s/epoch - 50ms/step
Epoch 20/1000
32/32 - 2s - loss: 2.2325 - r1: 0.4572 - r5: 0.7203 - r10: 0.8162 - p5: 0.1440 - p10: 0.0816 - val_loss: 2.7812 - val_r1: 0.3898 - val_r5: 0.6226 - val_r10: 0.7243 - val_p5: 0.1245 - val_p10: 0.0724 - lr: 4.9010e-04 - 2s/epoch - 51ms/step
Epoch 21/1000
32/32 - 2s - loss: 2.2075 - r1: 0.4632 - r5: 0.7284 - r10: 0.8208 - p5: 0.1457 - p10: 0.0821 - val_loss: 2.7973 - val_r1: 0.3809 - val_r5: 0.6252 - val_r10: 0.7184 - val_p5: 0.1250 - val_p10: 0.0718 - lr: 4.8961e-04 - 2s/epoch - 51ms/step
Epoch 22/1000
32/32 - 2s - loss: 2.1877 - r1: 0.4644 - r5: 0.7334 - r10: 0.8265 - p5: 0.1467 - p10: 0.0826 - val_loss: 2.7894 - val_r1: 0.3850 - val_r5: 0.6254 - val_r10: 0.7240 - val_p5: 0.1251 - val_p10: 0.0724 - lr: 4.8911e-04 - 2s/epoch - 50ms/step
Epoch 23/1000
32/32 - 2s - loss: 2.1707 - r1: 0.4712 - r5: 0.7362 - r10: 0.8262 - p5: 0.1472 - p10: 0.0826 - val_loss: 2.7868 - val_r1: 0.3809 - val_r5: 0.6224 - val_r10: 0.7253 - val_p5: 0.1245 - val_p10: 0.0725 - lr: 4.8862e-04 - 2s/epoch - 51ms/step
Epoch 24/1000
32/32 - 2s - loss: 2.1379 - r1: 0.4770 - r5: 0.7403 - r10: 0.8309 - p5: 0.1481 - p10: 0.0831 - val_loss: 2.7870 - val_r1: 0.3888 - val_r5: 0.6216 - val_r10: 0.7212 - val_p5: 0.1244 - val_p10: 0.0721 - lr: 4.8812e-04 - 2s/epoch - 51ms/step
Epoch 25/1000
32/32 - 2s - loss: 2.1044 - r1: 0.4857 - r5: 0.7449 - r10: 0.8364 - p5: 0.1490 - p10: 0.0836 - val_loss: 2.8025 - val_r1: 0.3868 - val_r5: 0.6163 - val_r10: 0.7222 - val_p5: 0.1233 - val_p10: 0.0722 - lr: 4.8763e-04 - 2s/epoch - 50ms/step
Epoch 26/1000
32/32 - 2s - loss: 2.1029 - r1: 0.4834 - r5: 0.7464 - r10: 0.8396 - p5: 0.1493 - p10: 0.0840 - val_loss: 2.8162 - val_r1: 0.3848 - val_r5: 0.6112 - val_r10: 0.7225 - val_p5: 0.1222 - val_p10: 0.0723 - lr: 4.8713e-04 - 2s/epoch - 50ms/step
Epoch 27/1000
32/32 - 2s - loss: 2.0697 - r1: 0.4888 - r5: 0.7535 - r10: 0.8429 - p5: 0.1507 - p10: 0.0843 - val_loss: 2.8189 - val_r1: 0.3837 - val_r5: 0.6109 - val_r10: 0.7189 - val_p5: 0.1222 - val_p10: 0.0719 - lr: 4.8664e-04 - 2s/epoch - 50ms/step
Epoch 28/1000
32/32 - 2s - loss: 2.0592 - r1: 0.4869 - r5: 0.7562 - r10: 0.8436 - p5: 0.1512 - p10: 0.0844 - val_loss: 2.8224 - val_r1: 0.3853 - val_r5: 0.6158 - val_r10: 0.7169 - val_p5: 0.1232 - val_p10: 0.0717 - lr: 4.8614e-04 - 2s/epoch - 50ms/step
Epoch 29/1000
32/32 - 2s - loss: 2.0342 - r1: 0.4947 - r5: 0.7597 - r10: 0.8479 - p5: 0.1519 - p10: 0.0848 - val_loss: 2.8234 - val_r1: 0.3883 - val_r5: 0.6125 - val_r10: 0.7146 - val_p5: 0.1225 - val_p10: 0.0715 - lr: 4.8565e-04 - 2s/epoch - 51ms/step
Epoch 30/1000
32/32 - 2s - loss: 2.0182 - r1: 0.5011 - r5: 0.7647 - r10: 0.8491 - p5: 0.1529 - p10: 0.0849 - val_loss: 2.8288 - val_r1: 0.3853 - val_r5: 0.6183 - val_r10: 0.7126 - val_p5: 0.1237 - val_p10: 0.0713 - lr: 4.8515e-04 - 2s/epoch - 50ms/step
Epoch 31/1000
32/32 - 2s - loss: 2.0083 - r1: 0.4991 - r5: 0.7662 - r10: 0.8516 - p5: 0.1532 - p10: 0.0852 - val_loss: 2.8373 - val_r1: 0.3865 - val_r5: 0.6140 - val_r10: 0.7172 - val_p5: 0.1228 - val_p10: 0.0717 - lr: 4.8466e-04 - 2s/epoch - 51ms/step
Epoch 32/1000
32/32 - 2s - loss: 1.9946 - r1: 0.5022 - r5: 0.7682 - r10: 0.8552 - p5: 0.1536 - p10: 0.0855 - val_loss: 2.8435 - val_r1: 0.3837 - val_r5: 0.6168 - val_r10: 0.7088 - val_p5: 0.1234 - val_p10: 0.0709 - lr: 4.8416e-04 - 2s/epoch - 51ms/step
Epoch 33/1000
32/32 - 2s - loss: 1.9807 - r1: 0.5057 - r5: 0.7703 - r10: 0.8557 - p5: 0.1540 - p10: 0.0856 - val_loss: 2.8320 - val_r1: 0.3812 - val_r5: 0.6178 - val_r10: 0.7139 - val_p5: 0.1236 - val_p10: 0.0714 - lr: 4.8367e-04 - 2s/epoch - 51ms/step
Epoch 34/1000
32/32 - 2s - loss: 1.9540 - r1: 0.5117 - r5: 0.7724 - r10: 0.8584 - p5: 0.1545 - p10: 0.0858 - val_loss: 2.8350 - val_r1: 0.3835 - val_r5: 0.6231 - val_r10: 0.7179 - val_p5: 0.1246 - val_p10: 0.0718 - lr: 4.8317e-04 - 2s/epoch - 51ms/step
Epoch 35/1000
32/32 - 2s - loss: 1.9563 - r1: 0.5084 - r5: 0.7752 - r10: 0.8589 - p5: 0.1550 - p10: 0.0859 - val_loss: 2.8532 - val_r1: 0.3812 - val_r5: 0.6155 - val_r10: 0.7172 - val_p5: 0.1231 - val_p10: 0.0717 - lr: 4.8268e-04 - 2s/epoch - 51ms/step
Epoch 36/1000
32/32 - 2s - loss: 1.9426 - r1: 0.5131 - r5: 0.7754 - r10: 0.8594 - p5: 0.1551 - p10: 0.0859 - val_loss: 2.8460 - val_r1: 0.3804 - val_r5: 0.6231 - val_r10: 0.7205 - val_p5: 0.1246 - val_p10: 0.0720 - lr: 4.8218e-04 - 2s/epoch - 51ms/step
Epoch 37/1000
32/32 - 2s - loss: 1.9191 - r1: 0.5167 - r5: 0.7833 - r10: 0.8658 - p5: 0.1566 - p10: 0.0866 - val_loss: 2.8333 - val_r1: 0.3842 - val_r5: 0.6155 - val_r10: 0.7184 - val_p5: 0.1231 - val_p10: 0.0718 - lr: 4.8169e-04 - 2s/epoch - 50ms/step
Epoch 38/1000
32/32 - 2s - loss: 1.9099 - r1: 0.5174 - r5: 0.7820 - r10: 0.8658 - p5: 0.1564 - p10: 0.0866 - val_loss: 2.8615 - val_r1: 0.3802 - val_r5: 0.6137 - val_r10: 0.7199 - val_p5: 0.1227 - val_p10: 0.0720 - lr: 4.8119e-04 - 2s/epoch - 51ms/step
Epoch 39/1000
32/32 - 2s - loss: 1.9081 - r1: 0.5206 - r5: 0.7834 - r10: 0.8642 - p5: 0.1567 - p10: 0.0864 - val_loss: 2.8579 - val_r1: 0.3835 - val_r5: 0.6089 - val_r10: 0.7123 - val_p5: 0.1218 - val_p10: 0.0712 - lr: 4.8070e-04 - 2s/epoch - 51ms/step
Epoch 40/1000
32/32 - 2s - loss: 1.8718 - r1: 0.5272 - r5: 0.7890 - r10: 0.8715 - p5: 0.1578 - p10: 0.0872 - val_loss: 2.8617 - val_r1: 0.3832 - val_r5: 0.6142 - val_r10: 0.7164 - val_p5: 0.1228 - val_p10: 0.0716 - lr: 4.8020e-04 - 2s/epoch - 50ms/step
Epoch 41/1000
32/32 - 2s - loss: 1.8829 - r1: 0.5209 - r5: 0.7882 - r10: 0.8685 - p5: 0.1576 - p10: 0.0869 - val_loss: 2.8757 - val_r1: 0.3761 - val_r5: 0.6114 - val_r10: 0.7177 - val_p5: 0.1223 - val_p10: 0.0718 - lr: 4.7971e-04 - 2s/epoch - 51ms/step
Epoch 42/1000
32/32 - 2s - loss: 1.8644 - r1: 0.5276 - r5: 0.7933 - r10: 0.8713 - p5: 0.1587 - p10: 0.0871 - val_loss: 2.8657 - val_r1: 0.3774 - val_r5: 0.6158 - val_r10: 0.7189 - val_p5: 0.1232 - val_p10: 0.0719 - lr: 4.7921e-04 - 2s/epoch - 50ms/step
Epoch 43/1000
32/32 - 2s - loss: 1.8560 - r1: 0.5281 - r5: 0.7931 - r10: 0.8714 - p5: 0.1586 - p10: 0.0871 - val_loss: 2.8704 - val_r1: 0.3774 - val_r5: 0.6147 - val_r10: 0.7133 - val_p5: 0.1229 - val_p10: 0.0713 - lr: 4.7872e-04 - 2s/epoch - 50ms/step
Epoch 44/1000
32/32 - 2s - loss: 1.8456 - r1: 0.5329 - r5: 0.7973 - r10: 0.8745 - p5: 0.1594 - p10: 0.0874 - val_loss: 2.8698 - val_r1: 0.3794 - val_r5: 0.6107 - val_r10: 0.7177 - val_p5: 0.1221 - val_p10: 0.0718 - lr: 4.7822e-04 - 2s/epoch - 51ms/step
Epoch 45/1000
32/32 - 2s - loss: 1.8436 - r1: 0.5313 - r5: 0.7960 - r10: 0.8753 - p5: 0.1592 - p10: 0.0875 - val_loss: 2.8730 - val_r1: 0.3802 - val_r5: 0.6155 - val_r10: 0.7133 - val_p5: 0.1231 - val_p10: 0.0713 - lr: 4.7773e-04 - 2s/epoch - 51ms/step
Epoch 46/1000
32/32 - 2s - loss: 1.8214 - r1: 0.5360 - r5: 0.8002 - r10: 0.8771 - p5: 0.1600 - p10: 0.0877 - val_loss: 2.8865 - val_r1: 0.3820 - val_r5: 0.6099 - val_r10: 0.7118 - val_p5: 0.1220 - val_p10: 0.0712 - lr: 4.7723e-04 - 2s/epoch - 50ms/step
Epoch 47/1000
32/32 - 2s - loss: 1.8147 - r1: 0.5378 - r5: 0.8007 - r10: 0.8777 - p5: 0.1601 - p10: 0.0878 - val_loss: 2.9031 - val_r1: 0.3776 - val_r5: 0.6061 - val_r10: 0.7075 - val_p5: 0.1212 - val_p10: 0.0707 - lr: 4.7674e-04 - 2s/epoch - 50ms/step
Epoch 48/1000
32/32 - 2s - loss: 1.8038 - r1: 0.5400 - r5: 0.8009 - r10: 0.8779 - p5: 0.1602 - p10: 0.0878 - val_loss: 2.9023 - val_r1: 0.3802 - val_r5: 0.6109 - val_r10: 0.7105 - val_p5: 0.1222 - val_p10: 0.0711 - lr: 4.7624e-04 - 2s/epoch - 51ms/step
Epoch 49/1000
32/32 - 1s - loss: 1.8086 - r1: 0.5390 - r5: 0.7997 - r10: 0.8785 - p5: 0.1599 - p10: 0.0879 - val_loss: 2.9145 - val_r1: 0.3753 - val_r5: 0.6086 - val_r10: 0.7108 - val_p5: 0.1217 - val_p10: 0.0711 - lr: 4.7575e-04 - 1s/epoch - 37ms/step
Epoch 50/1000
32/32 - 1s - loss: 1.8026 - r1: 0.5398 - r5: 0.8050 - r10: 0.8816 - p5: 0.1610 - p10: 0.0882 - val_loss: 2.9046 - val_r1: 0.3708 - val_r5: 0.6132 - val_r10: 0.7105 - val_p5: 0.1226 - val_p10: 0.0711 - lr: 4.7525e-04 - 801ms/epoch - 25ms/step
Epoch 51/1000
32/32 - 1s - loss: 1.7928 - r1: 0.5440 - r5: 0.8053 - r10: 0.8820 - p5: 0.1611 - p10: 0.0882 - val_loss: 2.9032 - val_r1: 0.3761 - val_r5: 0.6158 - val_r10: 0.7088 - val_p5: 0.1232 - val_p10: 0.0709 - lr: 4.7476e-04 - 806ms/epoch - 25ms/step
Epoch 52/1000
32/32 - 1s - loss: 1.7787 - r1: 0.5445 - r5: 0.8035 - r10: 0.8822 - p5: 0.1607 - p10: 0.0882 - val_loss: 2.8969 - val_r1: 0.3787 - val_r5: 0.6125 - val_r10: 0.7116 - val_p5: 0.1225 - val_p10: 0.0712 - lr: 4.7426e-04 - 809ms/epoch - 25ms/step
Epoch 53/1000
32/32 - 1s - loss: 1.7791 - r1: 0.5422 - r5: 0.8068 - r10: 0.8830 - p5: 0.1614 - p10: 0.0883 - val_loss: 2.9178 - val_r1: 0.3781 - val_r5: 0.6069 - val_r10: 0.7093 - val_p5: 0.1213 - val_p10: 0.0709 - lr: 4.7377e-04 - 809ms/epoch - 25ms/step
Epoch 54/1000
32/32 - 1s - loss: 1.7658 - r1: 0.5474 - r5: 0.8094 - r10: 0.8850 - p5: 0.1619 - p10: 0.0885 - val_loss: 2.9246 - val_r1: 0.3781 - val_r5: 0.6140 - val_r10: 0.7103 - val_p5: 0.1228 - val_p10: 0.0710 - lr: 4.7327e-04 - 808ms/epoch - 25ms/step
Epoch 55/1000
32/32 - 1s - loss: 1.7637 - r1: 0.5449 - r5: 0.8072 - r10: 0.8845 - p5: 0.1614 - p10: 0.0885 - val_loss: 2.9202 - val_r1: 0.3746 - val_r5: 0.6122 - val_r10: 0.7095 - val_p5: 0.1224 - val_p10: 0.0710 - lr: 4.7278e-04 - 810ms/epoch - 25ms/step
Epoch 56/1000
32/32 - 1s - loss: 1.7540 - r1: 0.5506 - r5: 0.8101 - r10: 0.8855 - p5: 0.1620 - p10: 0.0886 - val_loss: 2.9437 - val_r1: 0.3687 - val_r5: 0.6102 - val_r10: 0.7098 - val_p5: 0.1220 - val_p10: 0.0710 - lr: 4.7228e-04 - 806ms/epoch - 25ms/step
Epoch 57/1000
32/32 - 1s - loss: 1.7433 - r1: 0.5530 - r5: 0.8148 - r10: 0.8888 - p5: 0.1630 - p10: 0.0889 - val_loss: 2.9262 - val_r1: 0.3703 - val_r5: 0.6175 - val_r10: 0.7144 - val_p5: 0.1235 - val_p10: 0.0714 - lr: 4.7179e-04 - 807ms/epoch - 25ms/step
Epoch 58/1000
32/32 - 1s - loss: 1.7386 - r1: 0.5539 - r5: 0.8147 - r10: 0.8874 - p5: 0.1630 - p10: 0.0887 - val_loss: 2.9144 - val_r1: 0.3741 - val_r5: 0.6091 - val_r10: 0.7144 - val_p5: 0.1218 - val_p10: 0.0714 - lr: 4.7129e-04 - 807ms/epoch - 25ms/step
Epoch 59/1000
32/32 - 1s - loss: 1.7355 - r1: 0.5519 - r5: 0.8153 - r10: 0.8899 - p5: 0.1631 - p10: 0.0890 - val_loss: 2.9261 - val_r1: 0.3779 - val_r5: 0.6079 - val_r10: 0.7100 - val_p5: 0.1216 - val_p10: 0.0710 - lr: 4.7080e-04 - 807ms/epoch - 25ms/step
Epoch 60/1000
32/32 - 1s - loss: 1.7335 - r1: 0.5529 - r5: 0.8129 - r10: 0.8904 - p5: 0.1626 - p10: 0.0890 - val_loss: 2.9448 - val_r1: 0.3764 - val_r5: 0.6097 - val_r10: 0.7062 - val_p5: 0.1219 - val_p10: 0.0706 - lr: 4.7030e-04 - 809ms/epoch - 25ms/step
Epoch 61/1000
32/32 - 1s - loss: 1.7183 - r1: 0.5572 - r5: 0.8162 - r10: 0.8900 - p5: 0.1632 - p10: 0.0890 - val_loss: 2.9340 - val_r1: 0.3784 - val_r5: 0.6084 - val_r10: 0.7065 - val_p5: 0.1217 - val_p10: 0.0707 - lr: 4.6981e-04 - 803ms/epoch - 25ms/step
Epoch 62/1000
32/32 - 1s - loss: 1.7180 - r1: 0.5582 - r5: 0.8177 - r10: 0.8939 - p5: 0.1635 - p10: 0.0894 - val_loss: 2.9437 - val_r1: 0.3759 - val_r5: 0.6053 - val_r10: 0.7083 - val_p5: 0.1211 - val_p10: 0.0708 - lr: 4.6931e-04 - 803ms/epoch - 25ms/step
Epoch 63/1000
32/32 - 1s - loss: 1.7174 - r1: 0.5555 - r5: 0.8191 - r10: 0.8942 - p5: 0.1638 - p10: 0.0894 - val_loss: 2.9243 - val_r1: 0.3753 - val_r5: 0.6163 - val_r10: 0.7139 - val_p5: 0.1233 - val_p10: 0.0714 - lr: 4.6882e-04 - 806ms/epoch - 25ms/step
Epoch 64/1000
32/32 - 1s - loss: 1.7104 - r1: 0.5607 - r5: 0.8191 - r10: 0.8911 - p5: 0.1638 - p10: 0.0891 - val_loss: 2.9253 - val_r1: 0.3746 - val_r5: 0.6150 - val_r10: 0.7111 - val_p5: 0.1230 - val_p10: 0.0711 - lr: 4.6832e-04 - 807ms/epoch - 25ms/step
Epoch 65/1000
32/32 - 1s - loss: 1.7006 - r1: 0.5625 - r5: 0.8208 - r10: 0.8929 - p5: 0.1642 - p10: 0.0893 - val_loss: 2.9371 - val_r1: 0.3776 - val_r5: 0.6079 - val_r10: 0.7093 - val_p5: 0.1216 - val_p10: 0.0709 - lr: 4.6783e-04 - 804ms/epoch - 25ms/step
Epoch 66/1000
32/32 - 1s - loss: 1.6850 - r1: 0.5631 - r5: 0.8237 - r10: 0.8969 - p5: 0.1647 - p10: 0.0897 - val_loss: 2.9622 - val_r1: 0.3703 - val_r5: 0.6074 - val_r10: 0.7100 - val_p5: 0.1215 - val_p10: 0.0710 - lr: 4.6733e-04 - 806ms/epoch - 25ms/step
Epoch 67/1000
32/32 - 1s - loss: 1.6740 - r1: 0.5679 - r5: 0.8249 - r10: 0.8971 - p5: 0.1650 - p10: 0.0897 - val_loss: 2.9638 - val_r1: 0.3751 - val_r5: 0.6102 - val_r10: 0.7093 - val_p5: 0.1220 - val_p10: 0.0709 - lr: 4.6684e-04 - 801ms/epoch - 25ms/step
Epoch 67: early stopping
[92m[INFO] Loading best model...[0m
[93m[WARNING] Model folder already exists...[0m
Model: "ATT2ITM_0"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 162)]        0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 149)]        0           []                               
                                                                                                  
 embedding (Embedding)          (None, 162, 384)     926976      ['input_1[0][0]']                
                                                                                                  
 in_rsts (Embedding)            (None, 149, 384)     57216       ['input_2[0][0]']                
                                                                                                  
 dense (Dense)                  (None, 162, 256)     98560       ['embedding[0][0]']              
                                                                                                  
 dense_2 (Dense)                (None, 149, 256)     98560       ['in_rsts[0][0]']                
                                                                                                  
 tf.math.not_equal (TFOpLambda)  (None, 162)         0           ['input_1[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 162, 128)     32896       ['dense[0][0]']                  
                                                                                                  
 dense_3 (Dense)                (None, 149, 128)     32896       ['dense_2[0][0]']                
                                                                                                  
 tf.cast (TFOpLambda)           (None, 162)          0           ['tf.math.not_equal[0][0]']      
                                                                                                  
 word_emb (Lambda)              (None, 162, 128)     0           ['dense_1[0][0]']                
                                                                                                  
 rest_emb (Lambda)              (None, 149, 128)     0           ['dense_3[0][0]']                
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 162, 1)       0           ['tf.cast[0][0]']                
                                                                                                  
 lambda (Lambda)                (None, 162, 149)     0           ['word_emb[0][0]',               
                                                                  'rest_emb[0][0]']               
                                                                                                  
 tf.tile (TFOpLambda)           (None, 162, 149)     0           ['tf.expand_dims[0][0]']         
                                                                                                  
 lambda_1 (Lambda)              (None, 162, 149)     0           ['lambda[0][0]',                 
                                                                  'tf.tile[0][0]']                
                                                                                                  
 dotprod (Activation)           (None, 162, 149)     0           ['lambda_1[0][0]']               
                                                                                                  
 dropout (Dropout)              (None, 162, 149)     0           ['dotprod[0][0]']                
                                                                                                  
 sum (Lambda)                   (None, 149)          0           ['dropout[0][0]']                
                                                                                                  
 out (Activation)               (None, 149)          0           ['sum[0][0]']                    
                                                                                                  
==================================================================================================
Total params: 1,247,104
Trainable params: 1,247,104
Non-trainable params: 0
__________________________________________________________________________________________________
None
[92m[INFO] Model already trained. Loading weights...[0m
[93m[WARNING] Model folder already exists...[0m
Model: "ATT2ITM_0"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 162)]        0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 149)]        0           []                               
                                                                                                  
 embedding (Embedding)          (None, 162, 384)     926976      ['input_1[0][0]']                
                                                                                                  
 in_rsts (Embedding)            (None, 149, 384)     57216       ['input_2[0][0]']                
                                                                                                  
 dense (Dense)                  (None, 162, 256)     98560       ['embedding[0][0]']              
                                                                                                  
 dense_2 (Dense)                (None, 149, 256)     98560       ['in_rsts[0][0]']                
                                                                                                  
 tf.math.not_equal (TFOpLambda)  (None, 162)         0           ['input_1[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 162, 128)     32896       ['dense[0][0]']                  
                                                                                                  
 dense_3 (Dense)                (None, 149, 128)     32896       ['dense_2[0][0]']                
                                                                                                  
 tf.cast (TFOpLambda)           (None, 162)          0           ['tf.math.not_equal[0][0]']      
                                                                                                  
 word_emb (Lambda)              (None, 162, 128)     0           ['dense_1[0][0]']                
                                                                                                  
 rest_emb (Lambda)              (None, 149, 128)     0           ['dense_3[0][0]']                
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 162, 1)       0           ['tf.cast[0][0]']                
                                                                                                  
 lambda (Lambda)                (None, 162, 149)     0           ['word_emb[0][0]',               
                                                                  'rest_emb[0][0]']               
                                                                                                  
 tf.tile (TFOpLambda)           (None, 162, 149)     0           ['tf.expand_dims[0][0]']         
                                                                                                  
 lambda_1 (Lambda)              (None, 162, 149)     0           ['lambda[0][0]',                 
                                                                  'tf.tile[0][0]']                
                                                                                                  
 dotprod (Activation)           (None, 162, 149)     0           ['lambda_1[0][0]']               
                                                                                                  
 dropout (Dropout)              (None, 162, 149)     0           ['dotprod[0][0]']                
                                                                                                  
 sum (Lambda)                   (None, 149)          0           ['dropout[0][0]']                
                                                                                                  
 out (Activation)               (None, 149)          0           ['sum[0][0]']                    
                                                                                                  
==================================================================================================
Total params: 1,247,104
Trainable params: 1,247,104
Non-trainable params: 0
__________________________________________________________________________________________________
None
[92m[INFO] Model already trained. Loading weights...[0m
[93m[WARNING] Model folder already exists...[0m
Model: "ATT2ITM_0"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 162)]        0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 149)]        0           []                               
                                                                                                  
 embedding (Embedding)          (None, 162, 384)     926976      ['input_1[0][0]']                
                                                                                                  
 in_rsts (Embedding)            (None, 149, 384)     57216       ['input_2[0][0]']                
                                                                                                  
 dense (Dense)                  (None, 162, 256)     98560       ['embedding[0][0]']              
                                                                                                  
 dense_2 (Dense)                (None, 149, 256)     98560       ['in_rsts[0][0]']                
                                                                                                  
 tf.math.not_equal (TFOpLambda)  (None, 162)         0           ['input_1[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 162, 128)     32896       ['dense[0][0]']                  
                                                                                                  
 dense_3 (Dense)                (None, 149, 128)     32896       ['dense_2[0][0]']                
                                                                                                  
 tf.cast (TFOpLambda)           (None, 162)          0           ['tf.math.not_equal[0][0]']      
                                                                                                  
 word_emb (Lambda)              (None, 162, 128)     0           ['dense_1[0][0]']                
                                                                                                  
 rest_emb (Lambda)              (None, 149, 128)     0           ['dense_3[0][0]']                
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 162, 1)       0           ['tf.cast[0][0]']                
                                                                                                  
 lambda (Lambda)                (None, 162, 149)     0           ['word_emb[0][0]',               
                                                                  'rest_emb[0][0]']               
                                                                                                  
 tf.tile (TFOpLambda)           (None, 162, 149)     0           ['tf.expand_dims[0][0]']         
                                                                                                  
 lambda_1 (Lambda)              (None, 162, 149)     0           ['lambda[0][0]',                 
                                                                  'tf.tile[0][0]']                
                                                                                                  
 dotprod (Activation)           (None, 162, 149)     0           ['lambda_1[0][0]']               
                                                                                                  
 dropout (Dropout)              (None, 162, 149)     0           ['dotprod[0][0]']                
                                                                                                  
 sum (Lambda)                   (None, 149)          0           ['dropout[0][0]']                
                                                                                                  
 out (Activation)               (None, 149)          0           ['sum[0][0]']                    
                                                                                                  
==================================================================================================
Total params: 1,247,104
Trainable params: 1,247,104
Non-trainable params: 0
__________________________________________________________________________________________________
None
[92m[INFO] Model already trained. Loading weights...[0m
