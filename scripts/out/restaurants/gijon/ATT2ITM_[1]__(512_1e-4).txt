Model: "ATT2ITM_1"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 162)]        0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 149)]        0           []                               
                                                                                                  
 embedding (Embedding)          (None, 162, 384)     926976      ['input_1[0][0]']                
                                                                                                  
 in_rsts (Embedding)            (None, 149, 384)     57216       ['input_2[0][0]']                
                                                                                                  
 dense (Dense)                  (None, 162, 256)     98560       ['embedding[0][0]']              
                                                                                                  
 dense_2 (Dense)                (None, 149, 256)     98560       ['in_rsts[0][0]']                
                                                                                                  
 tf.math.not_equal (TFOpLambda)  (None, 162)         0           ['input_1[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 162, 128)     32896       ['dense[0][0]']                  
                                                                                                  
 dense_3 (Dense)                (None, 149, 128)     32896       ['dense_2[0][0]']                
                                                                                                  
 tf.cast (TFOpLambda)           (None, 162)          0           ['tf.math.not_equal[0][0]']      
                                                                                                  
 word_emb (Lambda)              (None, 162, 128)     0           ['dense_1[0][0]']                
                                                                                                  
 rest_emb (Lambda)              (None, 149, 128)     0           ['dense_3[0][0]']                
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 162, 1)       0           ['tf.cast[0][0]']                
                                                                                                  
 lambda (Lambda)                (None, 162, 149)     0           ['word_emb[0][0]',               
                                                                  'rest_emb[0][0]']               
                                                                                                  
 tf.tile (TFOpLambda)           (None, 162, 149)     0           ['tf.expand_dims[0][0]']         
                                                                                                  
 lambda_1 (Lambda)              (None, 162, 149)     0           ['lambda[0][0]',                 
                                                                  'tf.tile[0][0]']                
                                                                                                  
 dotprod (Activation)           (None, 162, 149)     0           ['lambda_1[0][0]']               
                                                                                                  
 dropout (Dropout)              (None, 162, 149)     0           ['dotprod[0][0]']                
                                                                                                  
 sum (Lambda)                   (None, 149)          0           ['dropout[0][0]']                
                                                                                                  
 out (Activation)               (None, 149)          0           ['sum[0][0]']                    
                                                                                                  
==================================================================================================
Total params: 1,247,104
Trainable params: 1,247,104
Non-trainable params: 0
__________________________________________________________________________________________________
None
Epoch 1/1000
63/63 - 4s - loss: 0.0502 - r1: 0.0304 - r5: 0.0885 - r10: 0.1343 - p5: 0.0177 - p10: 0.0134 - val_loss: 0.0218 - val_r1: 0.0638 - val_r5: 0.1738 - val_r10: 0.2518 - val_p5: 0.0348 - val_p10: 0.0252 - lr: 9.9901e-05 - 4s/epoch - 60ms/step
Epoch 2/1000
63/63 - 1s - loss: 0.0215 - r1: 0.0569 - r5: 0.1576 - r10: 0.2334 - p5: 0.0315 - p10: 0.0233 - val_loss: 0.0196 - val_r1: 0.0689 - val_r5: 0.1916 - val_r10: 0.2625 - val_p5: 0.0383 - val_p10: 0.0263 - lr: 9.9802e-05 - 1s/epoch - 17ms/step
Epoch 3/1000
63/63 - 1s - loss: 0.0197 - r1: 0.0571 - r5: 0.1624 - r10: 0.2366 - p5: 0.0325 - p10: 0.0237 - val_loss: 0.0183 - val_r1: 0.0701 - val_r5: 0.2069 - val_r10: 0.2775 - val_p5: 0.0414 - val_p10: 0.0277 - lr: 9.9703e-05 - 1s/epoch - 17ms/step
Epoch 4/1000
63/63 - 1s - loss: 0.0188 - r1: 0.0612 - r5: 0.1695 - r10: 0.2462 - p5: 0.0339 - p10: 0.0246 - val_loss: 0.0176 - val_r1: 0.0709 - val_r5: 0.2186 - val_r10: 0.2978 - val_p5: 0.0437 - val_p10: 0.0297 - lr: 9.9604e-05 - 1s/epoch - 17ms/step
Epoch 5/1000
63/63 - 1s - loss: 0.0183 - r1: 0.0712 - r5: 0.1832 - r10: 0.2588 - p5: 0.0366 - p10: 0.0259 - val_loss: 0.0172 - val_r1: 0.0808 - val_r5: 0.2371 - val_r10: 0.3131 - val_p5: 0.0474 - val_p10: 0.0313 - lr: 9.9505e-05 - 1s/epoch - 17ms/step
Epoch 6/1000
63/63 - 1s - loss: 0.0179 - r1: 0.0817 - r5: 0.2008 - r10: 0.2770 - p5: 0.0402 - p10: 0.0277 - val_loss: 0.0168 - val_r1: 0.0976 - val_r5: 0.2551 - val_r10: 0.3278 - val_p5: 0.0510 - val_p10: 0.0328 - lr: 9.9406e-05 - 1s/epoch - 17ms/step
Epoch 7/1000
63/63 - 1s - loss: 0.0175 - r1: 0.0973 - r5: 0.2200 - r10: 0.2947 - p5: 0.0440 - p10: 0.0295 - val_loss: 0.0164 - val_r1: 0.1212 - val_r5: 0.2783 - val_r10: 0.3555 - val_p5: 0.0557 - val_p10: 0.0356 - lr: 9.9307e-05 - 1s/epoch - 17ms/step
Epoch 8/1000
63/63 - 1s - loss: 0.0171 - r1: 0.1153 - r5: 0.2404 - r10: 0.3187 - p5: 0.0481 - p10: 0.0319 - val_loss: 0.0160 - val_r1: 0.1443 - val_r5: 0.3047 - val_r10: 0.3936 - val_p5: 0.0610 - val_p10: 0.0394 - lr: 9.9208e-05 - 1s/epoch - 17ms/step
Epoch 9/1000
63/63 - 1s - loss: 0.0166 - r1: 0.1320 - r5: 0.2665 - r10: 0.3487 - p5: 0.0533 - p10: 0.0349 - val_loss: 0.0156 - val_r1: 0.1667 - val_r5: 0.3357 - val_r10: 0.4320 - val_p5: 0.0671 - val_p10: 0.0432 - lr: 9.9109e-05 - 1s/epoch - 17ms/step
Epoch 10/1000
63/63 - 1s - loss: 0.0162 - r1: 0.1454 - r5: 0.2919 - r10: 0.3767 - p5: 0.0584 - p10: 0.0377 - val_loss: 0.0151 - val_r1: 0.1832 - val_r5: 0.3695 - val_r10: 0.4701 - val_p5: 0.0739 - val_p10: 0.0470 - lr: 9.9010e-05 - 1s/epoch - 17ms/step
Epoch 11/1000
63/63 - 1s - loss: 0.0157 - r1: 0.1596 - r5: 0.3145 - r10: 0.4019 - p5: 0.0629 - p10: 0.0402 - val_loss: 0.0147 - val_r1: 0.2025 - val_r5: 0.3995 - val_r10: 0.4983 - val_p5: 0.0798 - val_p10: 0.0498 - lr: 9.8911e-05 - 1s/epoch - 17ms/step
Epoch 12/1000
63/63 - 1s - loss: 0.0153 - r1: 0.1747 - r5: 0.3377 - r10: 0.4306 - p5: 0.0676 - p10: 0.0431 - val_loss: 0.0143 - val_r1: 0.2130 - val_r5: 0.4269 - val_r10: 0.5286 - val_p5: 0.0854 - val_p10: 0.0529 - lr: 9.8812e-05 - 1s/epoch - 17ms/step
Epoch 13/1000
63/63 - 1s - loss: 0.0149 - r1: 0.1883 - r5: 0.3569 - r10: 0.4563 - p5: 0.0714 - p10: 0.0456 - val_loss: 0.0139 - val_r1: 0.2307 - val_r5: 0.4503 - val_r10: 0.5558 - val_p5: 0.0902 - val_p10: 0.0556 - lr: 9.8713e-05 - 1s/epoch - 17ms/step
Epoch 14/1000
63/63 - 1s - loss: 0.0145 - r1: 0.1980 - r5: 0.3800 - r10: 0.4809 - p5: 0.0760 - p10: 0.0481 - val_loss: 0.0136 - val_r1: 0.2508 - val_r5: 0.4722 - val_r10: 0.5771 - val_p5: 0.0945 - val_p10: 0.0577 - lr: 9.8614e-05 - 1s/epoch - 17ms/step
Epoch 15/1000
63/63 - 1s - loss: 0.0142 - r1: 0.2135 - r5: 0.3969 - r10: 0.4990 - p5: 0.0794 - p10: 0.0499 - val_loss: 0.0133 - val_r1: 0.2618 - val_r5: 0.4882 - val_r10: 0.5936 - val_p5: 0.0977 - val_p10: 0.0593 - lr: 9.8515e-05 - 1s/epoch - 17ms/step
Epoch 16/1000
63/63 - 1s - loss: 0.0139 - r1: 0.2210 - r5: 0.4123 - r10: 0.5184 - p5: 0.0825 - p10: 0.0518 - val_loss: 0.0131 - val_r1: 0.2760 - val_r5: 0.5017 - val_r10: 0.6091 - val_p5: 0.1003 - val_p10: 0.0609 - lr: 9.8416e-05 - 1s/epoch - 17ms/step
Epoch 17/1000
63/63 - 1s - loss: 0.0137 - r1: 0.2337 - r5: 0.4283 - r10: 0.5358 - p5: 0.0857 - p10: 0.0536 - val_loss: 0.0129 - val_r1: 0.2887 - val_r5: 0.5174 - val_r10: 0.6241 - val_p5: 0.1035 - val_p10: 0.0624 - lr: 9.8317e-05 - 1s/epoch - 17ms/step
Epoch 18/1000
63/63 - 1s - loss: 0.0134 - r1: 0.2408 - r5: 0.4433 - r10: 0.5514 - p5: 0.0887 - p10: 0.0551 - val_loss: 0.0127 - val_r1: 0.2971 - val_r5: 0.5255 - val_r10: 0.6399 - val_p5: 0.1051 - val_p10: 0.0640 - lr: 9.8218e-05 - 1s/epoch - 17ms/step
Epoch 19/1000
63/63 - 1s - loss: 0.0132 - r1: 0.2532 - r5: 0.4567 - r10: 0.5668 - p5: 0.0913 - p10: 0.0567 - val_loss: 0.0125 - val_r1: 0.3067 - val_r5: 0.5344 - val_r10: 0.6468 - val_p5: 0.1068 - val_p10: 0.0647 - lr: 9.8119e-05 - 1s/epoch - 17ms/step
Epoch 20/1000
63/63 - 1s - loss: 0.0130 - r1: 0.2582 - r5: 0.4710 - r10: 0.5785 - p5: 0.0942 - p10: 0.0579 - val_loss: 0.0124 - val_r1: 0.3131 - val_r5: 0.5413 - val_r10: 0.6559 - val_p5: 0.1083 - val_p10: 0.0657 - lr: 9.8020e-05 - 1s/epoch - 17ms/step
Epoch 21/1000
63/63 - 1s - loss: 0.0129 - r1: 0.2680 - r5: 0.4780 - r10: 0.5874 - p5: 0.0956 - p10: 0.0587 - val_loss: 0.0122 - val_r1: 0.3139 - val_r5: 0.5535 - val_r10: 0.6615 - val_p5: 0.1107 - val_p10: 0.0661 - lr: 9.7921e-05 - 1s/epoch - 17ms/step
Epoch 22/1000
63/63 - 1s - loss: 0.0127 - r1: 0.2755 - r5: 0.4895 - r10: 0.5978 - p5: 0.0979 - p10: 0.0598 - val_loss: 0.0121 - val_r1: 0.3205 - val_r5: 0.5573 - val_r10: 0.6668 - val_p5: 0.1115 - val_p10: 0.0667 - lr: 9.7822e-05 - 1s/epoch - 17ms/step
Epoch 23/1000
63/63 - 1s - loss: 0.0126 - r1: 0.2785 - r5: 0.4983 - r10: 0.6076 - p5: 0.0997 - p10: 0.0608 - val_loss: 0.0120 - val_r1: 0.3222 - val_r5: 0.5665 - val_r10: 0.6773 - val_p5: 0.1134 - val_p10: 0.0677 - lr: 9.7723e-05 - 1s/epoch - 17ms/step
Epoch 24/1000
63/63 - 1s - loss: 0.0124 - r1: 0.2874 - r5: 0.5095 - r10: 0.6156 - p5: 0.1019 - p10: 0.0616 - val_loss: 0.0120 - val_r1: 0.3283 - val_r5: 0.5690 - val_r10: 0.6828 - val_p5: 0.1139 - val_p10: 0.0683 - lr: 9.7624e-05 - 1s/epoch - 17ms/step
Epoch 25/1000
63/63 - 1s - loss: 0.0124 - r1: 0.2878 - r5: 0.5084 - r10: 0.6185 - p5: 0.1016 - p10: 0.0618 - val_loss: 0.0119 - val_r1: 0.3418 - val_r5: 0.5784 - val_r10: 0.6897 - val_p5: 0.1156 - val_p10: 0.0689 - lr: 9.7525e-05 - 1s/epoch - 17ms/step
Epoch 26/1000
63/63 - 1s - loss: 0.0122 - r1: 0.2956 - r5: 0.5181 - r10: 0.6273 - p5: 0.1036 - p10: 0.0627 - val_loss: 0.0118 - val_r1: 0.3456 - val_r5: 0.5802 - val_r10: 0.6915 - val_p5: 0.1160 - val_p10: 0.0692 - lr: 9.7426e-05 - 1s/epoch - 17ms/step
Epoch 27/1000
63/63 - 1s - loss: 0.0121 - r1: 0.2991 - r5: 0.5244 - r10: 0.6355 - p5: 0.1049 - p10: 0.0635 - val_loss: 0.0117 - val_r1: 0.3428 - val_r5: 0.5807 - val_r10: 0.6935 - val_p5: 0.1161 - val_p10: 0.0694 - lr: 9.7327e-05 - 1s/epoch - 17ms/step
Epoch 28/1000
63/63 - 1s - loss: 0.0120 - r1: 0.3093 - r5: 0.5326 - r10: 0.6409 - p5: 0.1065 - p10: 0.0641 - val_loss: 0.0117 - val_r1: 0.3502 - val_r5: 0.5896 - val_r10: 0.7001 - val_p5: 0.1179 - val_p10: 0.0700 - lr: 9.7228e-05 - 1s/epoch - 17ms/step
Epoch 29/1000
63/63 - 1s - loss: 0.0119 - r1: 0.3097 - r5: 0.5371 - r10: 0.6467 - p5: 0.1074 - p10: 0.0647 - val_loss: 0.0116 - val_r1: 0.3583 - val_r5: 0.5911 - val_r10: 0.6996 - val_p5: 0.1181 - val_p10: 0.0700 - lr: 9.7129e-05 - 1s/epoch - 17ms/step
Epoch 30/1000
63/63 - 1s - loss: 0.0118 - r1: 0.3154 - r5: 0.5460 - r10: 0.6549 - p5: 0.1092 - p10: 0.0655 - val_loss: 0.0116 - val_r1: 0.3586 - val_r5: 0.5936 - val_r10: 0.7039 - val_p5: 0.1185 - val_p10: 0.0704 - lr: 9.7030e-05 - 1s/epoch - 17ms/step
Epoch 31/1000
63/63 - 1s - loss: 0.0117 - r1: 0.3165 - r5: 0.5476 - r10: 0.6591 - p5: 0.1095 - p10: 0.0659 - val_loss: 0.0115 - val_r1: 0.3548 - val_r5: 0.5975 - val_r10: 0.7052 - val_p5: 0.1195 - val_p10: 0.0705 - lr: 9.6931e-05 - 1s/epoch - 17ms/step
Epoch 32/1000
63/63 - 1s - loss: 0.0116 - r1: 0.3262 - r5: 0.5526 - r10: 0.6633 - p5: 0.1105 - p10: 0.0663 - val_loss: 0.0115 - val_r1: 0.3578 - val_r5: 0.5992 - val_r10: 0.7118 - val_p5: 0.1198 - val_p10: 0.0712 - lr: 9.6832e-05 - 893ms/epoch - 14ms/step
Epoch 33/1000
63/63 - 1s - loss: 0.0115 - r1: 0.3254 - r5: 0.5611 - r10: 0.6674 - p5: 0.1122 - p10: 0.0667 - val_loss: 0.0114 - val_r1: 0.3677 - val_r5: 0.6038 - val_r10: 0.7169 - val_p5: 0.1208 - val_p10: 0.0717 - lr: 9.6733e-05 - 1s/epoch - 17ms/step
Epoch 34/1000
63/63 - 1s - loss: 0.0115 - r1: 0.3288 - r5: 0.5632 - r10: 0.6729 - p5: 0.1126 - p10: 0.0673 - val_loss: 0.0114 - val_r1: 0.3644 - val_r5: 0.6051 - val_r10: 0.7121 - val_p5: 0.1210 - val_p10: 0.0712 - lr: 9.6634e-05 - 1s/epoch - 17ms/step
Epoch 35/1000
63/63 - 1s - loss: 0.0114 - r1: 0.3323 - r5: 0.5672 - r10: 0.6738 - p5: 0.1134 - p10: 0.0674 - val_loss: 0.0114 - val_r1: 0.3698 - val_r5: 0.6094 - val_r10: 0.7159 - val_p5: 0.1219 - val_p10: 0.0716 - lr: 9.6535e-05 - 893ms/epoch - 14ms/step
Epoch 36/1000
63/63 - 1s - loss: 0.0113 - r1: 0.3394 - r5: 0.5714 - r10: 0.6789 - p5: 0.1143 - p10: 0.0679 - val_loss: 0.0113 - val_r1: 0.3718 - val_r5: 0.6074 - val_r10: 0.7166 - val_p5: 0.1215 - val_p10: 0.0717 - lr: 9.6436e-05 - 1s/epoch - 19ms/step
Epoch 37/1000
63/63 - 1s - loss: 0.0112 - r1: 0.3412 - r5: 0.5770 - r10: 0.6835 - p5: 0.1154 - p10: 0.0683 - val_loss: 0.0113 - val_r1: 0.3738 - val_r5: 0.6079 - val_r10: 0.7182 - val_p5: 0.1215 - val_p10: 0.0718 - lr: 9.6337e-05 - 1s/epoch - 19ms/step
Epoch 38/1000
63/63 - 1s - loss: 0.0112 - r1: 0.3419 - r5: 0.5783 - r10: 0.6864 - p5: 0.1157 - p10: 0.0686 - val_loss: 0.0113 - val_r1: 0.3728 - val_r5: 0.6066 - val_r10: 0.7184 - val_p5: 0.1213 - val_p10: 0.0719 - lr: 9.6238e-05 - 892ms/epoch - 14ms/step
Epoch 39/1000
63/63 - 1s - loss: 0.0111 - r1: 0.3450 - r5: 0.5817 - r10: 0.6909 - p5: 0.1163 - p10: 0.0691 - val_loss: 0.0113 - val_r1: 0.3794 - val_r5: 0.6109 - val_r10: 0.7194 - val_p5: 0.1222 - val_p10: 0.0719 - lr: 9.6139e-05 - 1s/epoch - 17ms/step
Epoch 40/1000
63/63 - 1s - loss: 0.0111 - r1: 0.3499 - r5: 0.5886 - r10: 0.6946 - p5: 0.1177 - p10: 0.0695 - val_loss: 0.0113 - val_r1: 0.3756 - val_r5: 0.6119 - val_r10: 0.7192 - val_p5: 0.1224 - val_p10: 0.0719 - lr: 9.6040e-05 - 896ms/epoch - 14ms/step
Epoch 41/1000
63/63 - 1s - loss: 0.0110 - r1: 0.3502 - r5: 0.5905 - r10: 0.6976 - p5: 0.1181 - p10: 0.0698 - val_loss: 0.0113 - val_r1: 0.3759 - val_r5: 0.6132 - val_r10: 0.7243 - val_p5: 0.1227 - val_p10: 0.0725 - lr: 9.5941e-05 - 891ms/epoch - 14ms/step
Epoch 42/1000
63/63 - 1s - loss: 0.0109 - r1: 0.3526 - r5: 0.5934 - r10: 0.7012 - p5: 0.1187 - p10: 0.0701 - val_loss: 0.0113 - val_r1: 0.3748 - val_r5: 0.6168 - val_r10: 0.7258 - val_p5: 0.1234 - val_p10: 0.0726 - lr: 9.5842e-05 - 1s/epoch - 17ms/step
Epoch 43/1000
63/63 - 1s - loss: 0.0109 - r1: 0.3546 - r5: 0.5972 - r10: 0.7030 - p5: 0.1194 - p10: 0.0703 - val_loss: 0.0112 - val_r1: 0.3820 - val_r5: 0.6165 - val_r10: 0.7248 - val_p5: 0.1233 - val_p10: 0.0725 - lr: 9.5743e-05 - 1s/epoch - 17ms/step
Epoch 44/1000
63/63 - 1s - loss: 0.0108 - r1: 0.3609 - r5: 0.5980 - r10: 0.7048 - p5: 0.1196 - p10: 0.0705 - val_loss: 0.0113 - val_r1: 0.3830 - val_r5: 0.6183 - val_r10: 0.7288 - val_p5: 0.1236 - val_p10: 0.0729 - lr: 9.5644e-05 - 895ms/epoch - 14ms/step
Epoch 45/1000
63/63 - 1s - loss: 0.0108 - r1: 0.3608 - r5: 0.6012 - r10: 0.7080 - p5: 0.1202 - p10: 0.0708 - val_loss: 0.0112 - val_r1: 0.3820 - val_r5: 0.6175 - val_r10: 0.7260 - val_p5: 0.1235 - val_p10: 0.0726 - lr: 9.5545e-05 - 900ms/epoch - 14ms/step
Epoch 46/1000
63/63 - 1s - loss: 0.0107 - r1: 0.3626 - r5: 0.6058 - r10: 0.7127 - p5: 0.1212 - p10: 0.0713 - val_loss: 0.0112 - val_r1: 0.3837 - val_r5: 0.6183 - val_r10: 0.7283 - val_p5: 0.1236 - val_p10: 0.0729 - lr: 9.5446e-05 - 1s/epoch - 17ms/step
Epoch 47/1000
63/63 - 1s - loss: 0.0107 - r1: 0.3656 - r5: 0.6057 - r10: 0.7123 - p5: 0.1211 - p10: 0.0712 - val_loss: 0.0112 - val_r1: 0.3835 - val_r5: 0.6196 - val_r10: 0.7299 - val_p5: 0.1239 - val_p10: 0.0730 - lr: 9.5347e-05 - 1s/epoch - 17ms/step
Epoch 48/1000
63/63 - 1s - loss: 0.0106 - r1: 0.3711 - r5: 0.6121 - r10: 0.7155 - p5: 0.1224 - p10: 0.0716 - val_loss: 0.0112 - val_r1: 0.3840 - val_r5: 0.6244 - val_r10: 0.7296 - val_p5: 0.1250 - val_p10: 0.0730 - lr: 9.5248e-05 - 1s/epoch - 19ms/step
Epoch 49/1000
63/63 - 1s - loss: 0.0105 - r1: 0.3734 - r5: 0.6157 - r10: 0.7206 - p5: 0.1231 - p10: 0.0721 - val_loss: 0.0112 - val_r1: 0.3814 - val_r5: 0.6252 - val_r10: 0.7306 - val_p5: 0.1251 - val_p10: 0.0731 - lr: 9.5149e-05 - 901ms/epoch - 14ms/step
Epoch 50/1000
63/63 - 1s - loss: 0.0105 - r1: 0.3749 - r5: 0.6158 - r10: 0.7202 - p5: 0.1231 - p10: 0.0720 - val_loss: 0.0112 - val_r1: 0.3845 - val_r5: 0.6206 - val_r10: 0.7276 - val_p5: 0.1241 - val_p10: 0.0727 - lr: 9.5050e-05 - 900ms/epoch - 14ms/step
Epoch 51/1000
63/63 - 1s - loss: 0.0105 - r1: 0.3775 - r5: 0.6148 - r10: 0.7220 - p5: 0.1230 - p10: 0.0722 - val_loss: 0.0112 - val_r1: 0.3845 - val_r5: 0.6224 - val_r10: 0.7329 - val_p5: 0.1246 - val_p10: 0.0733 - lr: 9.4951e-05 - 893ms/epoch - 14ms/step
Epoch 52/1000
63/63 - 1s - loss: 0.0104 - r1: 0.3823 - r5: 0.6250 - r10: 0.7283 - p5: 0.1250 - p10: 0.0728 - val_loss: 0.0112 - val_r1: 0.3878 - val_r5: 0.6221 - val_r10: 0.7321 - val_p5: 0.1244 - val_p10: 0.0732 - lr: 9.4852e-05 - 897ms/epoch - 14ms/step
Epoch 53/1000
63/63 - 1s - loss: 0.0104 - r1: 0.3801 - r5: 0.6230 - r10: 0.7275 - p5: 0.1246 - p10: 0.0728 - val_loss: 0.0112 - val_r1: 0.3863 - val_r5: 0.6259 - val_r10: 0.7306 - val_p5: 0.1252 - val_p10: 0.0730 - lr: 9.4753e-05 - 893ms/epoch - 14ms/step
Epoch 54/1000
63/63 - 1s - loss: 0.0103 - r1: 0.3859 - r5: 0.6271 - r10: 0.7298 - p5: 0.1254 - p10: 0.0730 - val_loss: 0.0112 - val_r1: 0.3840 - val_r5: 0.6244 - val_r10: 0.7314 - val_p5: 0.1248 - val_p10: 0.0732 - lr: 9.4654e-05 - 896ms/epoch - 14ms/step
Epoch 55/1000
63/63 - 1s - loss: 0.0103 - r1: 0.3853 - r5: 0.6304 - r10: 0.7337 - p5: 0.1261 - p10: 0.0734 - val_loss: 0.0112 - val_r1: 0.3906 - val_r5: 0.6241 - val_r10: 0.7306 - val_p5: 0.1247 - val_p10: 0.0731 - lr: 9.4555e-05 - 1s/epoch - 17ms/step
Epoch 56/1000
63/63 - 1s - loss: 0.0103 - r1: 0.3823 - r5: 0.6282 - r10: 0.7323 - p5: 0.1257 - p10: 0.0732 - val_loss: 0.0113 - val_r1: 0.3873 - val_r5: 0.6290 - val_r10: 0.7286 - val_p5: 0.1258 - val_p10: 0.0729 - lr: 9.4456e-05 - 897ms/epoch - 14ms/step
Epoch 57/1000
63/63 - 1s - loss: 0.0102 - r1: 0.3895 - r5: 0.6300 - r10: 0.7340 - p5: 0.1260 - p10: 0.0734 - val_loss: 0.0112 - val_r1: 0.3850 - val_r5: 0.6272 - val_r10: 0.7309 - val_p5: 0.1255 - val_p10: 0.0731 - lr: 9.4357e-05 - 892ms/epoch - 14ms/step
Epoch 58/1000
63/63 - 1s - loss: 0.0102 - r1: 0.3932 - r5: 0.6353 - r10: 0.7364 - p5: 0.1271 - p10: 0.0736 - val_loss: 0.0112 - val_r1: 0.3875 - val_r5: 0.6264 - val_r10: 0.7337 - val_p5: 0.1252 - val_p10: 0.0734 - lr: 9.4258e-05 - 893ms/epoch - 14ms/step
Epoch 59/1000
63/63 - 1s - loss: 0.0101 - r1: 0.3955 - r5: 0.6344 - r10: 0.7392 - p5: 0.1269 - p10: 0.0739 - val_loss: 0.0112 - val_r1: 0.3845 - val_r5: 0.6244 - val_r10: 0.7327 - val_p5: 0.1249 - val_p10: 0.0732 - lr: 9.4159e-05 - 896ms/epoch - 14ms/step
Epoch 60/1000
63/63 - 1s - loss: 0.0101 - r1: 0.3925 - r5: 0.6380 - r10: 0.7412 - p5: 0.1276 - p10: 0.0741 - val_loss: 0.0112 - val_r1: 0.3952 - val_r5: 0.6252 - val_r10: 0.7339 - val_p5: 0.1250 - val_p10: 0.0734 - lr: 9.4060e-05 - 897ms/epoch - 14ms/step
Epoch 61/1000
63/63 - 1s - loss: 0.0101 - r1: 0.3954 - r5: 0.6448 - r10: 0.7454 - p5: 0.1290 - p10: 0.0745 - val_loss: 0.0113 - val_r1: 0.3919 - val_r5: 0.6269 - val_r10: 0.7314 - val_p5: 0.1254 - val_p10: 0.0731 - lr: 9.3961e-05 - 894ms/epoch - 14ms/step
Epoch 62/1000
63/63 - 1s - loss: 0.0100 - r1: 0.4019 - r5: 0.6427 - r10: 0.7439 - p5: 0.1285 - p10: 0.0744 - val_loss: 0.0113 - val_r1: 0.3875 - val_r5: 0.6254 - val_r10: 0.7299 - val_p5: 0.1250 - val_p10: 0.0730 - lr: 9.3862e-05 - 897ms/epoch - 14ms/step
Epoch 63/1000
63/63 - 1s - loss: 0.0100 - r1: 0.3952 - r5: 0.6436 - r10: 0.7442 - p5: 0.1287 - p10: 0.0744 - val_loss: 0.0113 - val_r1: 0.3906 - val_r5: 0.6254 - val_r10: 0.7334 - val_p5: 0.1251 - val_p10: 0.0733 - lr: 9.3763e-05 - 894ms/epoch - 14ms/step
Epoch 64/1000
63/63 - 1s - loss: 0.0100 - r1: 0.4026 - r5: 0.6445 - r10: 0.7444 - p5: 0.1289 - p10: 0.0744 - val_loss: 0.0113 - val_r1: 0.3896 - val_r5: 0.6287 - val_r10: 0.7311 - val_p5: 0.1257 - val_p10: 0.0731 - lr: 9.3664e-05 - 896ms/epoch - 14ms/step
Epoch 65/1000
63/63 - 1s - loss: 0.0099 - r1: 0.4032 - r5: 0.6503 - r10: 0.7506 - p5: 0.1301 - p10: 0.0750 - val_loss: 0.0113 - val_r1: 0.3921 - val_r5: 0.6244 - val_r10: 0.7306 - val_p5: 0.1248 - val_p10: 0.0730 - lr: 9.3565e-05 - 895ms/epoch - 14ms/step
Epoch 66/1000
63/63 - 1s - loss: 0.0099 - r1: 0.4059 - r5: 0.6519 - r10: 0.7516 - p5: 0.1304 - p10: 0.0752 - val_loss: 0.0113 - val_r1: 0.3916 - val_r5: 0.6292 - val_r10: 0.7296 - val_p5: 0.1258 - val_p10: 0.0730 - lr: 9.3466e-05 - 892ms/epoch - 14ms/step
Epoch 67/1000
63/63 - 1s - loss: 0.0099 - r1: 0.4086 - r5: 0.6533 - r10: 0.7529 - p5: 0.1307 - p10: 0.0753 - val_loss: 0.0114 - val_r1: 0.3924 - val_r5: 0.6297 - val_r10: 0.7294 - val_p5: 0.1259 - val_p10: 0.0729 - lr: 9.3367e-05 - 898ms/epoch - 14ms/step
Epoch 68/1000
63/63 - 1s - loss: 0.0098 - r1: 0.4108 - r5: 0.6558 - r10: 0.7570 - p5: 0.1312 - p10: 0.0757 - val_loss: 0.0114 - val_r1: 0.3906 - val_r5: 0.6302 - val_r10: 0.7314 - val_p5: 0.1261 - val_p10: 0.0731 - lr: 9.3268e-05 - 899ms/epoch - 14ms/step
Epoch 69/1000
63/63 - 1s - loss: 0.0098 - r1: 0.4097 - r5: 0.6556 - r10: 0.7550 - p5: 0.1311 - p10: 0.0755 - val_loss: 0.0113 - val_r1: 0.3901 - val_r5: 0.6257 - val_r10: 0.7329 - val_p5: 0.1251 - val_p10: 0.0733 - lr: 9.3169e-05 - 901ms/epoch - 14ms/step
Epoch 70/1000
63/63 - 1s - loss: 0.0097 - r1: 0.4134 - r5: 0.6595 - r10: 0.7618 - p5: 0.1319 - p10: 0.0762 - val_loss: 0.0114 - val_r1: 0.3878 - val_r5: 0.6254 - val_r10: 0.7288 - val_p5: 0.1251 - val_p10: 0.0729 - lr: 9.3070e-05 - 894ms/epoch - 14ms/step
Epoch 71/1000
63/63 - 1s - loss: 0.0097 - r1: 0.4127 - r5: 0.6595 - r10: 0.7600 - p5: 0.1319 - p10: 0.0760 - val_loss: 0.0114 - val_r1: 0.3929 - val_r5: 0.6295 - val_r10: 0.7334 - val_p5: 0.1259 - val_p10: 0.0733 - lr: 9.2971e-05 - 891ms/epoch - 14ms/step
Epoch 72/1000
63/63 - 1s - loss: 0.0097 - r1: 0.4147 - r5: 0.6626 - r10: 0.7618 - p5: 0.1325 - p10: 0.0762 - val_loss: 0.0113 - val_r1: 0.3952 - val_r5: 0.6295 - val_r10: 0.7316 - val_p5: 0.1258 - val_p10: 0.0732 - lr: 9.2872e-05 - 895ms/epoch - 14ms/step
Epoch 73/1000
63/63 - 1s - loss: 0.0096 - r1: 0.4157 - r5: 0.6648 - r10: 0.7653 - p5: 0.1330 - p10: 0.0765 - val_loss: 0.0113 - val_r1: 0.3947 - val_r5: 0.6335 - val_r10: 0.7314 - val_p5: 0.1268 - val_p10: 0.0732 - lr: 9.2773e-05 - 901ms/epoch - 14ms/step
Epoch 74/1000
63/63 - 1s - loss: 0.0097 - r1: 0.4170 - r5: 0.6597 - r10: 0.7615 - p5: 0.1320 - p10: 0.0762 - val_loss: 0.0114 - val_r1: 0.3975 - val_r5: 0.6292 - val_r10: 0.7314 - val_p5: 0.1258 - val_p10: 0.0731 - lr: 9.2674e-05 - 895ms/epoch - 14ms/step
Epoch 75/1000
63/63 - 1s - loss: 0.0096 - r1: 0.4189 - r5: 0.6694 - r10: 0.7655 - p5: 0.1339 - p10: 0.0766 - val_loss: 0.0114 - val_r1: 0.3990 - val_r5: 0.6338 - val_r10: 0.7324 - val_p5: 0.1268 - val_p10: 0.0732 - lr: 9.2575e-05 - 894ms/epoch - 14ms/step
Epoch 76/1000
63/63 - 1s - loss: 0.0096 - r1: 0.4177 - r5: 0.6660 - r10: 0.7660 - p5: 0.1332 - p10: 0.0766 - val_loss: 0.0114 - val_r1: 0.4013 - val_r5: 0.6315 - val_r10: 0.7319 - val_p5: 0.1263 - val_p10: 0.0732 - lr: 9.2476e-05 - 895ms/epoch - 14ms/step
Epoch 77/1000
63/63 - 1s - loss: 0.0095 - r1: 0.4225 - r5: 0.6680 - r10: 0.7675 - p5: 0.1336 - p10: 0.0767 - val_loss: 0.0114 - val_r1: 0.3939 - val_r5: 0.6307 - val_r10: 0.7327 - val_p5: 0.1261 - val_p10: 0.0732 - lr: 9.2377e-05 - 900ms/epoch - 14ms/step
Epoch 78/1000
63/63 - 1s - loss: 0.0095 - r1: 0.4237 - r5: 0.6730 - r10: 0.7711 - p5: 0.1346 - p10: 0.0771 - val_loss: 0.0115 - val_r1: 0.3939 - val_r5: 0.6290 - val_r10: 0.7342 - val_p5: 0.1258 - val_p10: 0.0734 - lr: 9.2278e-05 - 893ms/epoch - 14ms/step
Epoch 79/1000
63/63 - 1s - loss: 0.0095 - r1: 0.4219 - r5: 0.6727 - r10: 0.7714 - p5: 0.1345 - p10: 0.0771 - val_loss: 0.0115 - val_r1: 0.3914 - val_r5: 0.6302 - val_r10: 0.7283 - val_p5: 0.1260 - val_p10: 0.0729 - lr: 9.2179e-05 - 894ms/epoch - 14ms/step
Epoch 80/1000
63/63 - 1s - loss: 0.0095 - r1: 0.4245 - r5: 0.6728 - r10: 0.7716 - p5: 0.1346 - p10: 0.0771 - val_loss: 0.0114 - val_r1: 0.3980 - val_r5: 0.6285 - val_r10: 0.7291 - val_p5: 0.1257 - val_p10: 0.0729 - lr: 9.2080e-05 - 893ms/epoch - 14ms/step
Epoch 81/1000
63/63 - 1s - loss: 0.0094 - r1: 0.4260 - r5: 0.6742 - r10: 0.7740 - p5: 0.1349 - p10: 0.0774 - val_loss: 0.0114 - val_r1: 0.3919 - val_r5: 0.6295 - val_r10: 0.7306 - val_p5: 0.1259 - val_p10: 0.0731 - lr: 9.1981e-05 - 898ms/epoch - 14ms/step
Epoch 82/1000
63/63 - 1s - loss: 0.0094 - r1: 0.4267 - r5: 0.6767 - r10: 0.7721 - p5: 0.1353 - p10: 0.0772 - val_loss: 0.0114 - val_r1: 0.3942 - val_r5: 0.6302 - val_r10: 0.7319 - val_p5: 0.1260 - val_p10: 0.0732 - lr: 9.1882e-05 - 897ms/epoch - 14ms/step
Epoch 83/1000
63/63 - 1s - loss: 0.0094 - r1: 0.4302 - r5: 0.6809 - r10: 0.7754 - p5: 0.1362 - p10: 0.0775 - val_loss: 0.0115 - val_r1: 0.3952 - val_r5: 0.6290 - val_r10: 0.7301 - val_p5: 0.1258 - val_p10: 0.0730 - lr: 9.1783e-05 - 895ms/epoch - 14ms/step
Epoch 84/1000
63/63 - 1s - loss: 0.0094 - r1: 0.4325 - r5: 0.6783 - r10: 0.7745 - p5: 0.1357 - p10: 0.0775 - val_loss: 0.0114 - val_r1: 0.3924 - val_r5: 0.6262 - val_r10: 0.7283 - val_p5: 0.1252 - val_p10: 0.0728 - lr: 9.1684e-05 - 892ms/epoch - 14ms/step
Epoch 85/1000
63/63 - 1s - loss: 0.0093 - r1: 0.4306 - r5: 0.6847 - r10: 0.7781 - p5: 0.1369 - p10: 0.0778 - val_loss: 0.0115 - val_r1: 0.3985 - val_r5: 0.6282 - val_r10: 0.7296 - val_p5: 0.1256 - val_p10: 0.0729 - lr: 9.1585e-05 - 898ms/epoch - 14ms/step
Epoch 86/1000
63/63 - 1s - loss: 0.0093 - r1: 0.4308 - r5: 0.6845 - r10: 0.7788 - p5: 0.1369 - p10: 0.0779 - val_loss: 0.0116 - val_r1: 0.3911 - val_r5: 0.6280 - val_r10: 0.7263 - val_p5: 0.1256 - val_p10: 0.0726 - lr: 9.1486e-05 - 894ms/epoch - 14ms/step
Epoch 87/1000
63/63 - 1s - loss: 0.0093 - r1: 0.4353 - r5: 0.6851 - r10: 0.7814 - p5: 0.1370 - p10: 0.0782 - val_loss: 0.0115 - val_r1: 0.3914 - val_r5: 0.6290 - val_r10: 0.7273 - val_p5: 0.1257 - val_p10: 0.0727 - lr: 9.1387e-05 - 895ms/epoch - 14ms/step
Epoch 88/1000
63/63 - 1s - loss: 0.0092 - r1: 0.4353 - r5: 0.6856 - r10: 0.7839 - p5: 0.1371 - p10: 0.0784 - val_loss: 0.0116 - val_r1: 0.3947 - val_r5: 0.6315 - val_r10: 0.7309 - val_p5: 0.1263 - val_p10: 0.0731 - lr: 9.1288e-05 - 903ms/epoch - 14ms/step
Epoch 89/1000
63/63 - 1s - loss: 0.0092 - r1: 0.4379 - r5: 0.6867 - r10: 0.7815 - p5: 0.1373 - p10: 0.0781 - val_loss: 0.0115 - val_r1: 0.3903 - val_r5: 0.6277 - val_r10: 0.7273 - val_p5: 0.1256 - val_p10: 0.0727 - lr: 9.1189e-05 - 896ms/epoch - 14ms/step
Epoch 90/1000
63/63 - 1s - loss: 0.0092 - r1: 0.4368 - r5: 0.6875 - r10: 0.7828 - p5: 0.1375 - p10: 0.0783 - val_loss: 0.0115 - val_r1: 0.3980 - val_r5: 0.6290 - val_r10: 0.7296 - val_p5: 0.1258 - val_p10: 0.0730 - lr: 9.1090e-05 - 896ms/epoch - 14ms/step
Epoch 91/1000
63/63 - 1s - loss: 0.0092 - r1: 0.4409 - r5: 0.6871 - r10: 0.7832 - p5: 0.1374 - p10: 0.0783 - val_loss: 0.0115 - val_r1: 0.3936 - val_r5: 0.6277 - val_r10: 0.7299 - val_p5: 0.1255 - val_p10: 0.0730 - lr: 9.0991e-05 - 897ms/epoch - 14ms/step
Epoch 92/1000
63/63 - 1s - loss: 0.0091 - r1: 0.4405 - r5: 0.6897 - r10: 0.7858 - p5: 0.1380 - p10: 0.0786 - val_loss: 0.0115 - val_r1: 0.3924 - val_r5: 0.6274 - val_r10: 0.7266 - val_p5: 0.1255 - val_p10: 0.0726 - lr: 9.0892e-05 - 892ms/epoch - 14ms/step
Epoch 93/1000
63/63 - 1s - loss: 0.0091 - r1: 0.4391 - r5: 0.6911 - r10: 0.7891 - p5: 0.1382 - p10: 0.0789 - val_loss: 0.0117 - val_r1: 0.3934 - val_r5: 0.6208 - val_r10: 0.7286 - val_p5: 0.1241 - val_p10: 0.0728 - lr: 9.0793e-05 - 894ms/epoch - 14ms/step
Epoch 94/1000
63/63 - 1s - loss: 0.0091 - r1: 0.4442 - r5: 0.6949 - r10: 0.7878 - p5: 0.1390 - p10: 0.0788 - val_loss: 0.0117 - val_r1: 0.3914 - val_r5: 0.6264 - val_r10: 0.7296 - val_p5: 0.1252 - val_p10: 0.0730 - lr: 9.0694e-05 - 895ms/epoch - 14ms/step
Epoch 95/1000
63/63 - 1s - loss: 0.0091 - r1: 0.4463 - r5: 0.6967 - r10: 0.7899 - p5: 0.1393 - p10: 0.0790 - val_loss: 0.0116 - val_r1: 0.3936 - val_r5: 0.6257 - val_r10: 0.7288 - val_p5: 0.1251 - val_p10: 0.0729 - lr: 9.0595e-05 - 895ms/epoch - 14ms/step
Epoch 96/1000
63/63 - 1s - loss: 0.0091 - r1: 0.4458 - r5: 0.6943 - r10: 0.7898 - p5: 0.1388 - p10: 0.0790 - val_loss: 0.0115 - val_r1: 0.3962 - val_r5: 0.6221 - val_r10: 0.7296 - val_p5: 0.1244 - val_p10: 0.0729 - lr: 9.0496e-05 - 894ms/epoch - 14ms/step
Epoch 97/1000
63/63 - 1s - loss: 0.0090 - r1: 0.4457 - r5: 0.6938 - r10: 0.7895 - p5: 0.1388 - p10: 0.0790 - val_loss: 0.0116 - val_r1: 0.3893 - val_r5: 0.6213 - val_r10: 0.7294 - val_p5: 0.1243 - val_p10: 0.0729 - lr: 9.0397e-05 - 896ms/epoch - 14ms/step
Epoch 98/1000
63/63 - 1s - loss: 0.0090 - r1: 0.4455 - r5: 0.6954 - r10: 0.7915 - p5: 0.1391 - p10: 0.0791 - val_loss: 0.0116 - val_r1: 0.3990 - val_r5: 0.6219 - val_r10: 0.7286 - val_p5: 0.1244 - val_p10: 0.0729 - lr: 9.0298e-05 - 897ms/epoch - 14ms/step
Epoch 99/1000
63/63 - 1s - loss: 0.0090 - r1: 0.4499 - r5: 0.7001 - r10: 0.7931 - p5: 0.1400 - p10: 0.0793 - val_loss: 0.0116 - val_r1: 0.3939 - val_r5: 0.6249 - val_r10: 0.7263 - val_p5: 0.1250 - val_p10: 0.0726 - lr: 9.0199e-05 - 894ms/epoch - 14ms/step
Epoch 100/1000
63/63 - 1s - loss: 0.0090 - r1: 0.4476 - r5: 0.6981 - r10: 0.7920 - p5: 0.1396 - p10: 0.0792 - val_loss: 0.0116 - val_r1: 0.3919 - val_r5: 0.6247 - val_r10: 0.7268 - val_p5: 0.1249 - val_p10: 0.0727 - lr: 9.0100e-05 - 893ms/epoch - 14ms/step
Epoch 101/1000
63/63 - 1s - loss: 0.0090 - r1: 0.4509 - r5: 0.7025 - r10: 0.7959 - p5: 0.1405 - p10: 0.0796 - val_loss: 0.0116 - val_r1: 0.3949 - val_r5: 0.6236 - val_r10: 0.7238 - val_p5: 0.1247 - val_p10: 0.0724 - lr: 9.0001e-05 - 891ms/epoch - 14ms/step
Epoch 102/1000
63/63 - 1s - loss: 0.0089 - r1: 0.4496 - r5: 0.7003 - r10: 0.7950 - p5: 0.1401 - p10: 0.0795 - val_loss: 0.0118 - val_r1: 0.3903 - val_r5: 0.6241 - val_r10: 0.7245 - val_p5: 0.1249 - val_p10: 0.0725 - lr: 8.9902e-05 - 892ms/epoch - 14ms/step
Epoch 103/1000
63/63 - 1s - loss: 0.0089 - r1: 0.4501 - r5: 0.7042 - r10: 0.8012 - p5: 0.1408 - p10: 0.0801 - val_loss: 0.0117 - val_r1: 0.3924 - val_r5: 0.6257 - val_r10: 0.7276 - val_p5: 0.1251 - val_p10: 0.0728 - lr: 8.9803e-05 - 899ms/epoch - 14ms/step
Epoch 104/1000
63/63 - 1s - loss: 0.0089 - r1: 0.4522 - r5: 0.7029 - r10: 0.7972 - p5: 0.1406 - p10: 0.0797 - val_loss: 0.0117 - val_r1: 0.3914 - val_r5: 0.6216 - val_r10: 0.7266 - val_p5: 0.1244 - val_p10: 0.0727 - lr: 8.9704e-05 - 891ms/epoch - 14ms/step
Epoch 105/1000
63/63 - 1s - loss: 0.0089 - r1: 0.4546 - r5: 0.7032 - r10: 0.7998 - p5: 0.1406 - p10: 0.0800 - val_loss: 0.0117 - val_r1: 0.3995 - val_r5: 0.6229 - val_r10: 0.7184 - val_p5: 0.1246 - val_p10: 0.0719 - lr: 8.9605e-05 - 895ms/epoch - 14ms/step
Epoch 105: early stopping
[92m[INFO] Loading best model...[0m
[93m[WARNING] Model folder already exists...[0m
Model: "ATT2ITM_1"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 162)]        0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 149)]        0           []                               
                                                                                                  
 embedding (Embedding)          (None, 162, 384)     926976      ['input_1[0][0]']                
                                                                                                  
 in_rsts (Embedding)            (None, 149, 384)     57216       ['input_2[0][0]']                
                                                                                                  
 dense (Dense)                  (None, 162, 256)     98560       ['embedding[0][0]']              
                                                                                                  
 dense_2 (Dense)                (None, 149, 256)     98560       ['in_rsts[0][0]']                
                                                                                                  
 tf.math.not_equal (TFOpLambda)  (None, 162)         0           ['input_1[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 162, 128)     32896       ['dense[0][0]']                  
                                                                                                  
 dense_3 (Dense)                (None, 149, 128)     32896       ['dense_2[0][0]']                
                                                                                                  
 tf.cast (TFOpLambda)           (None, 162)          0           ['tf.math.not_equal[0][0]']      
                                                                                                  
 word_emb (Lambda)              (None, 162, 128)     0           ['dense_1[0][0]']                
                                                                                                  
 rest_emb (Lambda)              (None, 149, 128)     0           ['dense_3[0][0]']                
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 162, 1)       0           ['tf.cast[0][0]']                
                                                                                                  
 lambda (Lambda)                (None, 162, 149)     0           ['word_emb[0][0]',               
                                                                  'rest_emb[0][0]']               
                                                                                                  
 tf.tile (TFOpLambda)           (None, 162, 149)     0           ['tf.expand_dims[0][0]']         
                                                                                                  
 lambda_1 (Lambda)              (None, 162, 149)     0           ['lambda[0][0]',                 
                                                                  'tf.tile[0][0]']                
                                                                                                  
 dotprod (Activation)           (None, 162, 149)     0           ['lambda_1[0][0]']               
                                                                                                  
 dropout (Dropout)              (None, 162, 149)     0           ['dotprod[0][0]']                
                                                                                                  
 sum (Lambda)                   (None, 149)          0           ['dropout[0][0]']                
                                                                                                  
 out (Activation)               (None, 149)          0           ['sum[0][0]']                    
                                                                                                  
==================================================================================================
Total params: 1,247,104
Trainable params: 1,247,104
Non-trainable params: 0
__________________________________________________________________________________________________
None
[92m[INFO] Model already trained. Loading weights...[0m
[93m[WARNING] Model folder already exists...[0m
Model: "ATT2ITM_1"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 162)]        0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 149)]        0           []                               
                                                                                                  
 embedding (Embedding)          (None, 162, 384)     926976      ['input_1[0][0]']                
                                                                                                  
 in_rsts (Embedding)            (None, 149, 384)     57216       ['input_2[0][0]']                
                                                                                                  
 dense (Dense)                  (None, 162, 256)     98560       ['embedding[0][0]']              
                                                                                                  
 dense_2 (Dense)                (None, 149, 256)     98560       ['in_rsts[0][0]']                
                                                                                                  
 tf.math.not_equal (TFOpLambda)  (None, 162)         0           ['input_1[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 162, 128)     32896       ['dense[0][0]']                  
                                                                                                  
 dense_3 (Dense)                (None, 149, 128)     32896       ['dense_2[0][0]']                
                                                                                                  
 tf.cast (TFOpLambda)           (None, 162)          0           ['tf.math.not_equal[0][0]']      
                                                                                                  
 word_emb (Lambda)              (None, 162, 128)     0           ['dense_1[0][0]']                
                                                                                                  
 rest_emb (Lambda)              (None, 149, 128)     0           ['dense_3[0][0]']                
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 162, 1)       0           ['tf.cast[0][0]']                
                                                                                                  
 lambda (Lambda)                (None, 162, 149)     0           ['word_emb[0][0]',               
                                                                  'rest_emb[0][0]']               
                                                                                                  
 tf.tile (TFOpLambda)           (None, 162, 149)     0           ['tf.expand_dims[0][0]']         
                                                                                                  
 lambda_1 (Lambda)              (None, 162, 149)     0           ['lambda[0][0]',                 
                                                                  'tf.tile[0][0]']                
                                                                                                  
 dotprod (Activation)           (None, 162, 149)     0           ['lambda_1[0][0]']               
                                                                                                  
 dropout (Dropout)              (None, 162, 149)     0           ['dotprod[0][0]']                
                                                                                                  
 sum (Lambda)                   (None, 149)          0           ['dropout[0][0]']                
                                                                                                  
 out (Activation)               (None, 149)          0           ['sum[0][0]']                    
                                                                                                  
==================================================================================================
Total params: 1,247,104
Trainable params: 1,247,104
Non-trainable params: 0
__________________________________________________________________________________________________
None
[92m[INFO] Model already trained. Loading weights...[0m
[93m[WARNING] Model folder already exists...[0m
Model: "ATT2ITM_1"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 162)]        0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 149)]        0           []                               
                                                                                                  
 embedding (Embedding)          (None, 162, 384)     926976      ['input_1[0][0]']                
                                                                                                  
 in_rsts (Embedding)            (None, 149, 384)     57216       ['input_2[0][0]']                
                                                                                                  
 dense (Dense)                  (None, 162, 256)     98560       ['embedding[0][0]']              
                                                                                                  
 dense_2 (Dense)                (None, 149, 256)     98560       ['in_rsts[0][0]']                
                                                                                                  
 tf.math.not_equal (TFOpLambda)  (None, 162)         0           ['input_1[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 162, 128)     32896       ['dense[0][0]']                  
                                                                                                  
 dense_3 (Dense)                (None, 149, 128)     32896       ['dense_2[0][0]']                
                                                                                                  
 tf.cast (TFOpLambda)           (None, 162)          0           ['tf.math.not_equal[0][0]']      
                                                                                                  
 word_emb (Lambda)              (None, 162, 128)     0           ['dense_1[0][0]']                
                                                                                                  
 rest_emb (Lambda)              (None, 149, 128)     0           ['dense_3[0][0]']                
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 162, 1)       0           ['tf.cast[0][0]']                
                                                                                                  
 lambda (Lambda)                (None, 162, 149)     0           ['word_emb[0][0]',               
                                                                  'rest_emb[0][0]']               
                                                                                                  
 tf.tile (TFOpLambda)           (None, 162, 149)     0           ['tf.expand_dims[0][0]']         
                                                                                                  
 lambda_1 (Lambda)              (None, 162, 149)     0           ['lambda[0][0]',                 
                                                                  'tf.tile[0][0]']                
                                                                                                  
 dotprod (Activation)           (None, 162, 149)     0           ['lambda_1[0][0]']               
                                                                                                  
 dropout (Dropout)              (None, 162, 149)     0           ['dotprod[0][0]']                
                                                                                                  
 sum (Lambda)                   (None, 149)          0           ['dropout[0][0]']                
                                                                                                  
 out (Activation)               (None, 149)          0           ['sum[0][0]']                    
                                                                                                  
==================================================================================================
Total params: 1,247,104
Trainable params: 1,247,104
Non-trainable params: 0
__________________________________________________________________________________________________
None
[92m[INFO] Model already trained. Loading weights...[0m
