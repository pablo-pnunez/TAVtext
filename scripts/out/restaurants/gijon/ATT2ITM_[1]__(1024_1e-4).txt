Model: "ATT2ITM_1"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 162)]        0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 149)]        0           []                               
                                                                                                  
 embedding (Embedding)          (None, 162, 384)     926976      ['input_1[0][0]']                
                                                                                                  
 in_rsts (Embedding)            (None, 149, 384)     57216       ['input_2[0][0]']                
                                                                                                  
 dense (Dense)                  (None, 162, 256)     98560       ['embedding[0][0]']              
                                                                                                  
 dense_2 (Dense)                (None, 149, 256)     98560       ['in_rsts[0][0]']                
                                                                                                  
 tf.math.not_equal (TFOpLambda)  (None, 162)         0           ['input_1[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 162, 128)     32896       ['dense[0][0]']                  
                                                                                                  
 dense_3 (Dense)                (None, 149, 128)     32896       ['dense_2[0][0]']                
                                                                                                  
 tf.cast (TFOpLambda)           (None, 162)          0           ['tf.math.not_equal[0][0]']      
                                                                                                  
 word_emb (Lambda)              (None, 162, 128)     0           ['dense_1[0][0]']                
                                                                                                  
 rest_emb (Lambda)              (None, 149, 128)     0           ['dense_3[0][0]']                
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 162, 1)       0           ['tf.cast[0][0]']                
                                                                                                  
 lambda (Lambda)                (None, 162, 149)     0           ['word_emb[0][0]',               
                                                                  'rest_emb[0][0]']               
                                                                                                  
 tf.tile (TFOpLambda)           (None, 162, 149)     0           ['tf.expand_dims[0][0]']         
                                                                                                  
 lambda_1 (Lambda)              (None, 162, 149)     0           ['lambda[0][0]',                 
                                                                  'tf.tile[0][0]']                
                                                                                                  
 dotprod (Activation)           (None, 162, 149)     0           ['lambda_1[0][0]']               
                                                                                                  
 dropout (Dropout)              (None, 162, 149)     0           ['dotprod[0][0]']                
                                                                                                  
 sum (Lambda)                   (None, 149)          0           ['dropout[0][0]']                
                                                                                                  
 out (Activation)               (None, 149)          0           ['sum[0][0]']                    
                                                                                                  
==================================================================================================
Total params: 1,247,104
Trainable params: 1,247,104
Non-trainable params: 0
__________________________________________________________________________________________________
None
Epoch 1/1000
32/32 - 4s - loss: 0.0760 - r1: 0.0071 - r5: 0.0317 - r10: 0.0654 - p5: 0.0063 - p10: 0.0065 - val_loss: 0.0249 - val_r1: 0.0623 - val_r5: 0.1243 - val_r10: 0.1621 - val_p5: 0.0249 - val_p10: 0.0162 - lr: 9.9901e-05 - 4s/epoch - 111ms/step
Epoch 2/1000
32/32 - 1s - loss: 0.0243 - r1: 0.0559 - r5: 0.1432 - r10: 0.2014 - p5: 0.0286 - p10: 0.0201 - val_loss: 0.0217 - val_r1: 0.0600 - val_r5: 0.1718 - val_r10: 0.2501 - val_p5: 0.0344 - val_p10: 0.0250 - lr: 9.9802e-05 - 943ms/epoch - 29ms/step
Epoch 3/1000
32/32 - 1s - loss: 0.0219 - r1: 0.0570 - r5: 0.1529 - r10: 0.2322 - p5: 0.0306 - p10: 0.0232 - val_loss: 0.0205 - val_r1: 0.0671 - val_r5: 0.1825 - val_r10: 0.2526 - val_p5: 0.0365 - val_p10: 0.0253 - lr: 9.9703e-05 - 947ms/epoch - 30ms/step
Epoch 4/1000
32/32 - 1s - loss: 0.0208 - r1: 0.0571 - r5: 0.1610 - r10: 0.2354 - p5: 0.0322 - p10: 0.0235 - val_loss: 0.0195 - val_r1: 0.0673 - val_r5: 0.1931 - val_r10: 0.2633 - val_p5: 0.0386 - val_p10: 0.0264 - lr: 9.9604e-05 - 949ms/epoch - 30ms/step
Epoch 5/1000
32/32 - 1s - loss: 0.0198 - r1: 0.0564 - r5: 0.1610 - r10: 0.2378 - p5: 0.0322 - p10: 0.0238 - val_loss: 0.0187 - val_r1: 0.0689 - val_r5: 0.2013 - val_r10: 0.2712 - val_p5: 0.0403 - val_p10: 0.0272 - lr: 9.9505e-05 - 970ms/epoch - 30ms/step
Epoch 6/1000
32/32 - 1s - loss: 0.0193 - r1: 0.0575 - r5: 0.1638 - r10: 0.2413 - p5: 0.0328 - p10: 0.0241 - val_loss: 0.0181 - val_r1: 0.0714 - val_r5: 0.2074 - val_r10: 0.2816 - val_p5: 0.0415 - val_p10: 0.0282 - lr: 9.9406e-05 - 953ms/epoch - 30ms/step
Epoch 7/1000
32/32 - 1s - loss: 0.0187 - r1: 0.0621 - r5: 0.1698 - r10: 0.2441 - p5: 0.0340 - p10: 0.0244 - val_loss: 0.0177 - val_r1: 0.0734 - val_r5: 0.2160 - val_r10: 0.2948 - val_p5: 0.0432 - val_p10: 0.0295 - lr: 9.9307e-05 - 960ms/epoch - 30ms/step
Epoch 8/1000
32/32 - 1s - loss: 0.0184 - r1: 0.0662 - r5: 0.1761 - r10: 0.2520 - p5: 0.0352 - p10: 0.0252 - val_loss: 0.0174 - val_r1: 0.0785 - val_r5: 0.2247 - val_r10: 0.3057 - val_p5: 0.0449 - val_p10: 0.0305 - lr: 9.9208e-05 - 948ms/epoch - 30ms/step
Epoch 9/1000
32/32 - 1s - loss: 0.0181 - r1: 0.0697 - r5: 0.1854 - r10: 0.2626 - p5: 0.0371 - p10: 0.0263 - val_loss: 0.0172 - val_r1: 0.0849 - val_r5: 0.2371 - val_r10: 0.3166 - val_p5: 0.0475 - val_p10: 0.0317 - lr: 9.9109e-05 - 947ms/epoch - 30ms/step
Epoch 10/1000
32/32 - 1s - loss: 0.0179 - r1: 0.0771 - r5: 0.1897 - r10: 0.2693 - p5: 0.0380 - p10: 0.0269 - val_loss: 0.0170 - val_r1: 0.0928 - val_r5: 0.2460 - val_r10: 0.3233 - val_p5: 0.0492 - val_p10: 0.0323 - lr: 9.9010e-05 - 949ms/epoch - 30ms/step
Epoch 11/1000
32/32 - 1s - loss: 0.0177 - r1: 0.0862 - r5: 0.2034 - r10: 0.2794 - p5: 0.0407 - p10: 0.0279 - val_loss: 0.0168 - val_r1: 0.1044 - val_r5: 0.2633 - val_r10: 0.3360 - val_p5: 0.0527 - val_p10: 0.0336 - lr: 9.8911e-05 - 951ms/epoch - 30ms/step
Epoch 12/1000
32/32 - 1s - loss: 0.0175 - r1: 0.0926 - r5: 0.2131 - r10: 0.2897 - p5: 0.0426 - p10: 0.0290 - val_loss: 0.0166 - val_r1: 0.1136 - val_r5: 0.2773 - val_r10: 0.3497 - val_p5: 0.0555 - val_p10: 0.0350 - lr: 9.8812e-05 - 951ms/epoch - 30ms/step
Epoch 13/1000
32/32 - 1s - loss: 0.0173 - r1: 0.1025 - r5: 0.2218 - r10: 0.3009 - p5: 0.0444 - p10: 0.0301 - val_loss: 0.0164 - val_r1: 0.1286 - val_r5: 0.2900 - val_r10: 0.3626 - val_p5: 0.0580 - val_p10: 0.0362 - lr: 9.8713e-05 - 946ms/epoch - 30ms/step
Epoch 14/1000
32/32 - 1s - loss: 0.0170 - r1: 0.1127 - r5: 0.2422 - r10: 0.3190 - p5: 0.0484 - p10: 0.0319 - val_loss: 0.0161 - val_r1: 0.1418 - val_r5: 0.3019 - val_r10: 0.3804 - val_p5: 0.0604 - val_p10: 0.0380 - lr: 9.8614e-05 - 1s/epoch - 33ms/step
Epoch 15/1000
32/32 - 1s - loss: 0.0168 - r1: 0.1242 - r5: 0.2536 - r10: 0.3323 - p5: 0.0507 - p10: 0.0332 - val_loss: 0.0159 - val_r1: 0.1578 - val_r5: 0.3139 - val_r10: 0.4053 - val_p5: 0.0627 - val_p10: 0.0405 - lr: 9.8515e-05 - 955ms/epoch - 30ms/step
Epoch 16/1000
32/32 - 1s - loss: 0.0165 - r1: 0.1322 - r5: 0.2688 - r10: 0.3491 - p5: 0.0538 - p10: 0.0349 - val_loss: 0.0156 - val_r1: 0.1700 - val_r5: 0.3314 - val_r10: 0.4216 - val_p5: 0.0662 - val_p10: 0.0422 - lr: 9.8416e-05 - 950ms/epoch - 30ms/step
Epoch 17/1000
32/32 - 1s - loss: 0.0163 - r1: 0.1421 - r5: 0.2849 - r10: 0.3676 - p5: 0.0570 - p10: 0.0368 - val_loss: 0.0154 - val_r1: 0.1830 - val_r5: 0.3499 - val_r10: 0.4457 - val_p5: 0.0700 - val_p10: 0.0446 - lr: 9.8317e-05 - 952ms/epoch - 30ms/step
Epoch 18/1000
32/32 - 1s - loss: 0.0160 - r1: 0.1500 - r5: 0.2973 - r10: 0.3823 - p5: 0.0595 - p10: 0.0382 - val_loss: 0.0151 - val_r1: 0.1939 - val_r5: 0.3693 - val_r10: 0.4648 - val_p5: 0.0739 - val_p10: 0.0465 - lr: 9.8218e-05 - 946ms/epoch - 30ms/step
Epoch 19/1000
32/32 - 1s - loss: 0.0157 - r1: 0.1595 - r5: 0.3136 - r10: 0.4032 - p5: 0.0627 - p10: 0.0403 - val_loss: 0.0149 - val_r1: 0.2030 - val_r5: 0.3901 - val_r10: 0.4872 - val_p5: 0.0780 - val_p10: 0.0487 - lr: 9.8119e-05 - 953ms/epoch - 30ms/step
Epoch 20/1000
32/32 - 1s - loss: 0.0154 - r1: 0.1685 - r5: 0.3273 - r10: 0.4190 - p5: 0.0655 - p10: 0.0419 - val_loss: 0.0146 - val_r1: 0.2175 - val_r5: 0.4066 - val_r10: 0.5047 - val_p5: 0.0814 - val_p10: 0.0504 - lr: 9.8020e-05 - 951ms/epoch - 30ms/step
Epoch 21/1000
32/32 - 1s - loss: 0.0152 - r1: 0.1786 - r5: 0.3401 - r10: 0.4328 - p5: 0.0680 - p10: 0.0433 - val_loss: 0.0144 - val_r1: 0.2282 - val_r5: 0.4259 - val_r10: 0.5222 - val_p5: 0.0852 - val_p10: 0.0522 - lr: 9.7921e-05 - 949ms/epoch - 30ms/step
Epoch 22/1000
32/32 - 1s - loss: 0.0149 - r1: 0.1856 - r5: 0.3546 - r10: 0.4519 - p5: 0.0709 - p10: 0.0452 - val_loss: 0.0141 - val_r1: 0.2358 - val_r5: 0.4437 - val_r10: 0.5423 - val_p5: 0.0888 - val_p10: 0.0542 - lr: 9.7822e-05 - 1s/epoch - 33ms/step
Epoch 23/1000
32/32 - 1s - loss: 0.0148 - r1: 0.1913 - r5: 0.3637 - r10: 0.4589 - p5: 0.0727 - p10: 0.0459 - val_loss: 0.0139 - val_r1: 0.2450 - val_r5: 0.4569 - val_r10: 0.5568 - val_p5: 0.0913 - val_p10: 0.0557 - lr: 9.7723e-05 - 948ms/epoch - 30ms/step
Epoch 24/1000
32/32 - 1s - loss: 0.0145 - r1: 0.2009 - r5: 0.3779 - r10: 0.4775 - p5: 0.0756 - p10: 0.0478 - val_loss: 0.0137 - val_r1: 0.2592 - val_r5: 0.4673 - val_r10: 0.5700 - val_p5: 0.0935 - val_p10: 0.0570 - lr: 9.7624e-05 - 957ms/epoch - 30ms/step
Epoch 25/1000
32/32 - 1s - loss: 0.0143 - r1: 0.2095 - r5: 0.3901 - r10: 0.4900 - p5: 0.0780 - p10: 0.0490 - val_loss: 0.0135 - val_r1: 0.2668 - val_r5: 0.4760 - val_r10: 0.5837 - val_p5: 0.0952 - val_p10: 0.0584 - lr: 9.7525e-05 - 956ms/epoch - 30ms/step
Epoch 26/1000
32/32 - 1s - loss: 0.0141 - r1: 0.2137 - r5: 0.4005 - r10: 0.5030 - p5: 0.0801 - p10: 0.0503 - val_loss: 0.0134 - val_r1: 0.2757 - val_r5: 0.4882 - val_r10: 0.5985 - val_p5: 0.0976 - val_p10: 0.0598 - lr: 9.7426e-05 - 955ms/epoch - 30ms/step
Epoch 27/1000
32/32 - 1s - loss: 0.0139 - r1: 0.2234 - r5: 0.4104 - r10: 0.5162 - p5: 0.0821 - p10: 0.0516 - val_loss: 0.0132 - val_r1: 0.2823 - val_r5: 0.5001 - val_r10: 0.6084 - val_p5: 0.1001 - val_p10: 0.0608 - lr: 9.7327e-05 - 955ms/epoch - 30ms/step
Epoch 28/1000
32/32 - 1s - loss: 0.0138 - r1: 0.2296 - r5: 0.4245 - r10: 0.5289 - p5: 0.0849 - p10: 0.0529 - val_loss: 0.0131 - val_r1: 0.2839 - val_r5: 0.5060 - val_r10: 0.6140 - val_p5: 0.1011 - val_p10: 0.0614 - lr: 9.7228e-05 - 942ms/epoch - 29ms/step
Epoch 29/1000
32/32 - 1s - loss: 0.0136 - r1: 0.2331 - r5: 0.4326 - r10: 0.5377 - p5: 0.0865 - p10: 0.0538 - val_loss: 0.0129 - val_r1: 0.2917 - val_r5: 0.5164 - val_r10: 0.6259 - val_p5: 0.1033 - val_p10: 0.0626 - lr: 9.7129e-05 - 950ms/epoch - 30ms/step
Epoch 30/1000
32/32 - 1s - loss: 0.0135 - r1: 0.2411 - r5: 0.4421 - r10: 0.5474 - p5: 0.0884 - p10: 0.0547 - val_loss: 0.0128 - val_r1: 0.2973 - val_r5: 0.5245 - val_r10: 0.6323 - val_p5: 0.1049 - val_p10: 0.0632 - lr: 9.7030e-05 - 1s/epoch - 34ms/step
Epoch 31/1000
32/32 - 1s - loss: 0.0133 - r1: 0.2481 - r5: 0.4470 - r10: 0.5519 - p5: 0.0894 - p10: 0.0552 - val_loss: 0.0127 - val_r1: 0.3019 - val_r5: 0.5342 - val_r10: 0.6402 - val_p5: 0.1068 - val_p10: 0.0640 - lr: 9.6931e-05 - 1s/epoch - 34ms/step
Epoch 32/1000
32/32 - 1s - loss: 0.0132 - r1: 0.2525 - r5: 0.4563 - r10: 0.5635 - p5: 0.0913 - p10: 0.0564 - val_loss: 0.0126 - val_r1: 0.3088 - val_r5: 0.5390 - val_r10: 0.6478 - val_p5: 0.1076 - val_p10: 0.0648 - lr: 9.6832e-05 - 948ms/epoch - 30ms/step
Epoch 33/1000
32/32 - 1s - loss: 0.0131 - r1: 0.2583 - r5: 0.4622 - r10: 0.5726 - p5: 0.0925 - p10: 0.0573 - val_loss: 0.0125 - val_r1: 0.3088 - val_r5: 0.5443 - val_r10: 0.6516 - val_p5: 0.1089 - val_p10: 0.0652 - lr: 9.6733e-05 - 945ms/epoch - 30ms/step
Epoch 34/1000
32/32 - 1s - loss: 0.0130 - r1: 0.2627 - r5: 0.4704 - r10: 0.5768 - p5: 0.0941 - p10: 0.0577 - val_loss: 0.0124 - val_r1: 0.3131 - val_r5: 0.5517 - val_r10: 0.6595 - val_p5: 0.1103 - val_p10: 0.0659 - lr: 9.6634e-05 - 949ms/epoch - 30ms/step
Epoch 35/1000
32/32 - 1s - loss: 0.0129 - r1: 0.2640 - r5: 0.4755 - r10: 0.5849 - p5: 0.0951 - p10: 0.0585 - val_loss: 0.0123 - val_r1: 0.3197 - val_r5: 0.5553 - val_r10: 0.6635 - val_p5: 0.1110 - val_p10: 0.0664 - lr: 9.6535e-05 - 948ms/epoch - 30ms/step
Epoch 36/1000
32/32 - 1s - loss: 0.0128 - r1: 0.2677 - r5: 0.4835 - r10: 0.5919 - p5: 0.0967 - p10: 0.0592 - val_loss: 0.0123 - val_r1: 0.3164 - val_r5: 0.5588 - val_r10: 0.6722 - val_p5: 0.1118 - val_p10: 0.0672 - lr: 9.6436e-05 - 951ms/epoch - 30ms/step
Epoch 37/1000
32/32 - 1s - loss: 0.0126 - r1: 0.2785 - r5: 0.4924 - r10: 0.6023 - p5: 0.0985 - p10: 0.0602 - val_loss: 0.0122 - val_r1: 0.3238 - val_r5: 0.5698 - val_r10: 0.6765 - val_p5: 0.1140 - val_p10: 0.0676 - lr: 9.6337e-05 - 949ms/epoch - 30ms/step
Epoch 38/1000
32/32 - 1s - loss: 0.0126 - r1: 0.2778 - r5: 0.4945 - r10: 0.6040 - p5: 0.0989 - p10: 0.0604 - val_loss: 0.0121 - val_r1: 0.3266 - val_r5: 0.5657 - val_r10: 0.6765 - val_p5: 0.1131 - val_p10: 0.0676 - lr: 9.6238e-05 - 954ms/epoch - 30ms/step
Epoch 39/1000
32/32 - 1s - loss: 0.0125 - r1: 0.2830 - r5: 0.5002 - r10: 0.6094 - p5: 0.1000 - p10: 0.0609 - val_loss: 0.0121 - val_r1: 0.3309 - val_r5: 0.5726 - val_r10: 0.6864 - val_p5: 0.1145 - val_p10: 0.0686 - lr: 9.6139e-05 - 950ms/epoch - 30ms/step
Epoch 40/1000
32/32 - 1s - loss: 0.0124 - r1: 0.2873 - r5: 0.5103 - r10: 0.6198 - p5: 0.1020 - p10: 0.0620 - val_loss: 0.0120 - val_r1: 0.3352 - val_r5: 0.5781 - val_r10: 0.6841 - val_p5: 0.1156 - val_p10: 0.0684 - lr: 9.6040e-05 - 953ms/epoch - 30ms/step
Epoch 41/1000
32/32 - 1s - loss: 0.0123 - r1: 0.2910 - r5: 0.5113 - r10: 0.6190 - p5: 0.1023 - p10: 0.0619 - val_loss: 0.0119 - val_r1: 0.3436 - val_r5: 0.5825 - val_r10: 0.6915 - val_p5: 0.1165 - val_p10: 0.0692 - lr: 9.5941e-05 - 950ms/epoch - 30ms/step
Epoch 42/1000
32/32 - 1s - loss: 0.0122 - r1: 0.2915 - r5: 0.5167 - r10: 0.6259 - p5: 0.1033 - p10: 0.0626 - val_loss: 0.0119 - val_r1: 0.3410 - val_r5: 0.5865 - val_r10: 0.6943 - val_p5: 0.1173 - val_p10: 0.0694 - lr: 9.5842e-05 - 953ms/epoch - 30ms/step
Epoch 43/1000
32/32 - 1s - loss: 0.0122 - r1: 0.2978 - r5: 0.5177 - r10: 0.6313 - p5: 0.1035 - p10: 0.0631 - val_loss: 0.0119 - val_r1: 0.3461 - val_r5: 0.5924 - val_r10: 0.6943 - val_p5: 0.1185 - val_p10: 0.0694 - lr: 9.5743e-05 - 951ms/epoch - 30ms/step
Epoch 44/1000
32/32 - 1s - loss: 0.0121 - r1: 0.3035 - r5: 0.5244 - r10: 0.6321 - p5: 0.1049 - p10: 0.0632 - val_loss: 0.0118 - val_r1: 0.3466 - val_r5: 0.5919 - val_r10: 0.7006 - val_p5: 0.1184 - val_p10: 0.0701 - lr: 9.5644e-05 - 945ms/epoch - 30ms/step
Epoch 45/1000
32/32 - 1s - loss: 0.0120 - r1: 0.3028 - r5: 0.5253 - r10: 0.6383 - p5: 0.1050 - p10: 0.0638 - val_loss: 0.0118 - val_r1: 0.3499 - val_r5: 0.5970 - val_r10: 0.7014 - val_p5: 0.1193 - val_p10: 0.0701 - lr: 9.5545e-05 - 954ms/epoch - 30ms/step
Epoch 46/1000
32/32 - 1s - loss: 0.0120 - r1: 0.3069 - r5: 0.5310 - r10: 0.6429 - p5: 0.1062 - p10: 0.0643 - val_loss: 0.0118 - val_r1: 0.3522 - val_r5: 0.5990 - val_r10: 0.7024 - val_p5: 0.1198 - val_p10: 0.0702 - lr: 9.5446e-05 - 952ms/epoch - 30ms/step
Epoch 47/1000
32/32 - 1s - loss: 0.0119 - r1: 0.3112 - r5: 0.5370 - r10: 0.6445 - p5: 0.1074 - p10: 0.0644 - val_loss: 0.0117 - val_r1: 0.3565 - val_r5: 0.6003 - val_r10: 0.7078 - val_p5: 0.1201 - val_p10: 0.0707 - lr: 9.5347e-05 - 949ms/epoch - 30ms/step
Epoch 48/1000
32/32 - 1s - loss: 0.0118 - r1: 0.3142 - r5: 0.5426 - r10: 0.6510 - p5: 0.1085 - p10: 0.0651 - val_loss: 0.0117 - val_r1: 0.3591 - val_r5: 0.6048 - val_r10: 0.7060 - val_p5: 0.1210 - val_p10: 0.0706 - lr: 9.5248e-05 - 951ms/epoch - 30ms/step
Epoch 49/1000
32/32 - 1s - loss: 0.0117 - r1: 0.3173 - r5: 0.5474 - r10: 0.6576 - p5: 0.1095 - p10: 0.0658 - val_loss: 0.0117 - val_r1: 0.3568 - val_r5: 0.6058 - val_r10: 0.7083 - val_p5: 0.1212 - val_p10: 0.0708 - lr: 9.5149e-05 - 950ms/epoch - 30ms/step
Epoch 50/1000
32/32 - 1s - loss: 0.0117 - r1: 0.3210 - r5: 0.5531 - r10: 0.6597 - p5: 0.1106 - p10: 0.0660 - val_loss: 0.0117 - val_r1: 0.3604 - val_r5: 0.6084 - val_r10: 0.7105 - val_p5: 0.1217 - val_p10: 0.0710 - lr: 9.5050e-05 - 785ms/epoch - 25ms/step
Epoch 51/1000
32/32 - 1s - loss: 0.0116 - r1: 0.3224 - r5: 0.5511 - r10: 0.6586 - p5: 0.1102 - p10: 0.0659 - val_loss: 0.0116 - val_r1: 0.3604 - val_r5: 0.6081 - val_r10: 0.7156 - val_p5: 0.1217 - val_p10: 0.0715 - lr: 9.4951e-05 - 964ms/epoch - 30ms/step
Epoch 52/1000
32/32 - 1s - loss: 0.0116 - r1: 0.3241 - r5: 0.5544 - r10: 0.6639 - p5: 0.1109 - p10: 0.0664 - val_loss: 0.0117 - val_r1: 0.3624 - val_r5: 0.6079 - val_r10: 0.7146 - val_p5: 0.1216 - val_p10: 0.0714 - lr: 9.4852e-05 - 785ms/epoch - 25ms/step
Epoch 53/1000
32/32 - 1s - loss: 0.0115 - r1: 0.3259 - r5: 0.5572 - r10: 0.6673 - p5: 0.1114 - p10: 0.0667 - val_loss: 0.0116 - val_r1: 0.3672 - val_r5: 0.6125 - val_r10: 0.7182 - val_p5: 0.1225 - val_p10: 0.0718 - lr: 9.4753e-05 - 949ms/epoch - 30ms/step
Epoch 54/1000
32/32 - 1s - loss: 0.0114 - r1: 0.3328 - r5: 0.5636 - r10: 0.6709 - p5: 0.1127 - p10: 0.0671 - val_loss: 0.0117 - val_r1: 0.3675 - val_r5: 0.6112 - val_r10: 0.7172 - val_p5: 0.1222 - val_p10: 0.0717 - lr: 9.4654e-05 - 785ms/epoch - 25ms/step
Epoch 55/1000
32/32 - 1s - loss: 0.0114 - r1: 0.3321 - r5: 0.5654 - r10: 0.6737 - p5: 0.1131 - p10: 0.0674 - val_loss: 0.0115 - val_r1: 0.3662 - val_r5: 0.6137 - val_r10: 0.7161 - val_p5: 0.1227 - val_p10: 0.0716 - lr: 9.4555e-05 - 950ms/epoch - 30ms/step
Epoch 56/1000
32/32 - 1s - loss: 0.0114 - r1: 0.3351 - r5: 0.5667 - r10: 0.6752 - p5: 0.1133 - p10: 0.0675 - val_loss: 0.0116 - val_r1: 0.3715 - val_r5: 0.6150 - val_r10: 0.7174 - val_p5: 0.1230 - val_p10: 0.0717 - lr: 9.4456e-05 - 787ms/epoch - 25ms/step
Epoch 57/1000
32/32 - 1s - loss: 0.0113 - r1: 0.3364 - r5: 0.5705 - r10: 0.6784 - p5: 0.1141 - p10: 0.0678 - val_loss: 0.0115 - val_r1: 0.3731 - val_r5: 0.6130 - val_r10: 0.7197 - val_p5: 0.1226 - val_p10: 0.0720 - lr: 9.4357e-05 - 950ms/epoch - 30ms/step
Epoch 58/1000
32/32 - 1s - loss: 0.0113 - r1: 0.3370 - r5: 0.5726 - r10: 0.6797 - p5: 0.1145 - p10: 0.0680 - val_loss: 0.0115 - val_r1: 0.3736 - val_r5: 0.6175 - val_r10: 0.7194 - val_p5: 0.1236 - val_p10: 0.0720 - lr: 9.4258e-05 - 788ms/epoch - 25ms/step
Epoch 59/1000
32/32 - 1s - loss: 0.0112 - r1: 0.3420 - r5: 0.5747 - r10: 0.6814 - p5: 0.1149 - p10: 0.0681 - val_loss: 0.0115 - val_r1: 0.3741 - val_r5: 0.6168 - val_r10: 0.7250 - val_p5: 0.1235 - val_p10: 0.0725 - lr: 9.4159e-05 - 952ms/epoch - 30ms/step
Epoch 60/1000
32/32 - 1s - loss: 0.0112 - r1: 0.3407 - r5: 0.5779 - r10: 0.6865 - p5: 0.1156 - p10: 0.0687 - val_loss: 0.0115 - val_r1: 0.3731 - val_r5: 0.6158 - val_r10: 0.7222 - val_p5: 0.1232 - val_p10: 0.0722 - lr: 9.4060e-05 - 951ms/epoch - 30ms/step
Epoch 61/1000
32/32 - 1s - loss: 0.0111 - r1: 0.3451 - r5: 0.5810 - r10: 0.6887 - p5: 0.1162 - p10: 0.0689 - val_loss: 0.0115 - val_r1: 0.3759 - val_r5: 0.6152 - val_r10: 0.7250 - val_p5: 0.1231 - val_p10: 0.0725 - lr: 9.3961e-05 - 785ms/epoch - 25ms/step
Epoch 62/1000
32/32 - 1s - loss: 0.0111 - r1: 0.3488 - r5: 0.5839 - r10: 0.6904 - p5: 0.1168 - p10: 0.0690 - val_loss: 0.0115 - val_r1: 0.3835 - val_r5: 0.6219 - val_r10: 0.7235 - val_p5: 0.1244 - val_p10: 0.0724 - lr: 9.3862e-05 - 784ms/epoch - 24ms/step
Epoch 63/1000
32/32 - 1s - loss: 0.0110 - r1: 0.3494 - r5: 0.5843 - r10: 0.6936 - p5: 0.1169 - p10: 0.0694 - val_loss: 0.0115 - val_r1: 0.3784 - val_r5: 0.6213 - val_r10: 0.7238 - val_p5: 0.1243 - val_p10: 0.0724 - lr: 9.3763e-05 - 787ms/epoch - 25ms/step
Epoch 64/1000
32/32 - 1s - loss: 0.0110 - r1: 0.3521 - r5: 0.5872 - r10: 0.6950 - p5: 0.1174 - p10: 0.0695 - val_loss: 0.0115 - val_r1: 0.3799 - val_r5: 0.6211 - val_r10: 0.7258 - val_p5: 0.1242 - val_p10: 0.0726 - lr: 9.3664e-05 - 786ms/epoch - 25ms/step
Epoch 65/1000
32/32 - 1s - loss: 0.0110 - r1: 0.3528 - r5: 0.5909 - r10: 0.6981 - p5: 0.1182 - p10: 0.0698 - val_loss: 0.0114 - val_r1: 0.3794 - val_r5: 0.6226 - val_r10: 0.7266 - val_p5: 0.1245 - val_p10: 0.0727 - lr: 9.3565e-05 - 953ms/epoch - 30ms/step
Epoch 66/1000
32/32 - 1s - loss: 0.0109 - r1: 0.3540 - r5: 0.5914 - r10: 0.6984 - p5: 0.1183 - p10: 0.0698 - val_loss: 0.0114 - val_r1: 0.3799 - val_r5: 0.6219 - val_r10: 0.7255 - val_p5: 0.1244 - val_p10: 0.0726 - lr: 9.3466e-05 - 787ms/epoch - 25ms/step
Epoch 67/1000
32/32 - 1s - loss: 0.0109 - r1: 0.3582 - r5: 0.5945 - r10: 0.6995 - p5: 0.1189 - p10: 0.0699 - val_loss: 0.0114 - val_r1: 0.3787 - val_r5: 0.6188 - val_r10: 0.7253 - val_p5: 0.1237 - val_p10: 0.0725 - lr: 9.3367e-05 - 786ms/epoch - 25ms/step
Epoch 68/1000
32/32 - 1s - loss: 0.0108 - r1: 0.3593 - r5: 0.5969 - r10: 0.7047 - p5: 0.1194 - p10: 0.0705 - val_loss: 0.0114 - val_r1: 0.3802 - val_r5: 0.6203 - val_r10: 0.7263 - val_p5: 0.1241 - val_p10: 0.0726 - lr: 9.3268e-05 - 786ms/epoch - 25ms/step
Epoch 69/1000
32/32 - 1s - loss: 0.0108 - r1: 0.3574 - r5: 0.6007 - r10: 0.7066 - p5: 0.1201 - p10: 0.0707 - val_loss: 0.0114 - val_r1: 0.3812 - val_r5: 0.6206 - val_r10: 0.7248 - val_p5: 0.1241 - val_p10: 0.0725 - lr: 9.3169e-05 - 787ms/epoch - 25ms/step
Epoch 70/1000
32/32 - 1s - loss: 0.0108 - r1: 0.3601 - r5: 0.6017 - r10: 0.7067 - p5: 0.1204 - p10: 0.0707 - val_loss: 0.0114 - val_r1: 0.3870 - val_r5: 0.6262 - val_r10: 0.7273 - val_p5: 0.1252 - val_p10: 0.0727 - lr: 9.3070e-05 - 954ms/epoch - 30ms/step
Epoch 71/1000
32/32 - 1s - loss: 0.0108 - r1: 0.3637 - r5: 0.6039 - r10: 0.7080 - p5: 0.1208 - p10: 0.0708 - val_loss: 0.0115 - val_r1: 0.3850 - val_r5: 0.6231 - val_r10: 0.7291 - val_p5: 0.1246 - val_p10: 0.0729 - lr: 9.2971e-05 - 785ms/epoch - 25ms/step
Epoch 72/1000
32/32 - 1s - loss: 0.0107 - r1: 0.3631 - r5: 0.6059 - r10: 0.7119 - p5: 0.1212 - p10: 0.0712 - val_loss: 0.0115 - val_r1: 0.3822 - val_r5: 0.6290 - val_r10: 0.7291 - val_p5: 0.1258 - val_p10: 0.0729 - lr: 9.2872e-05 - 787ms/epoch - 25ms/step
Epoch 73/1000
32/32 - 1s - loss: 0.0107 - r1: 0.3667 - r5: 0.6068 - r10: 0.7117 - p5: 0.1213 - p10: 0.0712 - val_loss: 0.0114 - val_r1: 0.3848 - val_r5: 0.6257 - val_r10: 0.7263 - val_p5: 0.1251 - val_p10: 0.0726 - lr: 9.2773e-05 - 785ms/epoch - 25ms/step
Epoch 74/1000
32/32 - 1s - loss: 0.0106 - r1: 0.3703 - r5: 0.6040 - r10: 0.7126 - p5: 0.1208 - p10: 0.0713 - val_loss: 0.0114 - val_r1: 0.3840 - val_r5: 0.6287 - val_r10: 0.7266 - val_p5: 0.1257 - val_p10: 0.0726 - lr: 9.2674e-05 - 786ms/epoch - 25ms/step
Epoch 75/1000
32/32 - 1s - loss: 0.0106 - r1: 0.3707 - r5: 0.6109 - r10: 0.7166 - p5: 0.1222 - p10: 0.0717 - val_loss: 0.0115 - val_r1: 0.3845 - val_r5: 0.6290 - val_r10: 0.7299 - val_p5: 0.1258 - val_p10: 0.0730 - lr: 9.2575e-05 - 783ms/epoch - 24ms/step
Epoch 76/1000
32/32 - 1s - loss: 0.0106 - r1: 0.3723 - r5: 0.6124 - r10: 0.7178 - p5: 0.1225 - p10: 0.0718 - val_loss: 0.0115 - val_r1: 0.3840 - val_r5: 0.6287 - val_r10: 0.7301 - val_p5: 0.1257 - val_p10: 0.0730 - lr: 9.2476e-05 - 790ms/epoch - 25ms/step
Epoch 77/1000
32/32 - 1s - loss: 0.0105 - r1: 0.3736 - r5: 0.6136 - r10: 0.7183 - p5: 0.1227 - p10: 0.0718 - val_loss: 0.0115 - val_r1: 0.3906 - val_r5: 0.6302 - val_r10: 0.7327 - val_p5: 0.1260 - val_p10: 0.0732 - lr: 9.2377e-05 - 783ms/epoch - 24ms/step
Epoch 78/1000
32/32 - 1s - loss: 0.0105 - r1: 0.3754 - r5: 0.6173 - r10: 0.7226 - p5: 0.1235 - p10: 0.0723 - val_loss: 0.0115 - val_r1: 0.3870 - val_r5: 0.6330 - val_r10: 0.7314 - val_p5: 0.1267 - val_p10: 0.0731 - lr: 9.2278e-05 - 784ms/epoch - 24ms/step
Epoch 79/1000
32/32 - 1s - loss: 0.0105 - r1: 0.3763 - r5: 0.6191 - r10: 0.7221 - p5: 0.1238 - p10: 0.0722 - val_loss: 0.0115 - val_r1: 0.3878 - val_r5: 0.6300 - val_r10: 0.7288 - val_p5: 0.1259 - val_p10: 0.0729 - lr: 9.2179e-05 - 787ms/epoch - 25ms/step
Epoch 80/1000
32/32 - 1s - loss: 0.0105 - r1: 0.3779 - r5: 0.6163 - r10: 0.7245 - p5: 0.1232 - p10: 0.0725 - val_loss: 0.0115 - val_r1: 0.3835 - val_r5: 0.6310 - val_r10: 0.7306 - val_p5: 0.1262 - val_p10: 0.0731 - lr: 9.2080e-05 - 788ms/epoch - 25ms/step
Epoch 81/1000
32/32 - 1s - loss: 0.0104 - r1: 0.3768 - r5: 0.6176 - r10: 0.7264 - p5: 0.1235 - p10: 0.0726 - val_loss: 0.0115 - val_r1: 0.3868 - val_r5: 0.6315 - val_r10: 0.7309 - val_p5: 0.1263 - val_p10: 0.0731 - lr: 9.1981e-05 - 789ms/epoch - 25ms/step
Epoch 82/1000
32/32 - 1s - loss: 0.0104 - r1: 0.3751 - r5: 0.6228 - r10: 0.7267 - p5: 0.1246 - p10: 0.0727 - val_loss: 0.0114 - val_r1: 0.3875 - val_r5: 0.6325 - val_r10: 0.7337 - val_p5: 0.1265 - val_p10: 0.0734 - lr: 9.1882e-05 - 789ms/epoch - 25ms/step
Epoch 83/1000
32/32 - 1s - loss: 0.0103 - r1: 0.3829 - r5: 0.6264 - r10: 0.7290 - p5: 0.1253 - p10: 0.0729 - val_loss: 0.0114 - val_r1: 0.3878 - val_r5: 0.6343 - val_r10: 0.7309 - val_p5: 0.1269 - val_p10: 0.0731 - lr: 9.1783e-05 - 785ms/epoch - 25ms/step
Epoch 84/1000
32/32 - 1s - loss: 0.0103 - r1: 0.3834 - r5: 0.6252 - r10: 0.7267 - p5: 0.1250 - p10: 0.0727 - val_loss: 0.0115 - val_r1: 0.3883 - val_r5: 0.6338 - val_r10: 0.7309 - val_p5: 0.1269 - val_p10: 0.0731 - lr: 9.1684e-05 - 791ms/epoch - 25ms/step
Epoch 85/1000
32/32 - 1s - loss: 0.0103 - r1: 0.3832 - r5: 0.6286 - r10: 0.7326 - p5: 0.1257 - p10: 0.0733 - val_loss: 0.0115 - val_r1: 0.3873 - val_r5: 0.6330 - val_r10: 0.7316 - val_p5: 0.1266 - val_p10: 0.0732 - lr: 9.1585e-05 - 785ms/epoch - 25ms/step
Epoch 86/1000
32/32 - 1s - loss: 0.0103 - r1: 0.3883 - r5: 0.6305 - r10: 0.7345 - p5: 0.1261 - p10: 0.0735 - val_loss: 0.0115 - val_r1: 0.3881 - val_r5: 0.6292 - val_r10: 0.7291 - val_p5: 0.1258 - val_p10: 0.0729 - lr: 9.1486e-05 - 786ms/epoch - 25ms/step
Epoch 87/1000
32/32 - 1s - loss: 0.0103 - r1: 0.3886 - r5: 0.6334 - r10: 0.7328 - p5: 0.1267 - p10: 0.0733 - val_loss: 0.0115 - val_r1: 0.3901 - val_r5: 0.6292 - val_r10: 0.7319 - val_p5: 0.1258 - val_p10: 0.0732 - lr: 9.1387e-05 - 785ms/epoch - 25ms/step
Epoch 88/1000
32/32 - 1s - loss: 0.0102 - r1: 0.3902 - r5: 0.6314 - r10: 0.7348 - p5: 0.1263 - p10: 0.0735 - val_loss: 0.0116 - val_r1: 0.3881 - val_r5: 0.6323 - val_r10: 0.7296 - val_p5: 0.1265 - val_p10: 0.0730 - lr: 9.1288e-05 - 788ms/epoch - 25ms/step
Epoch 89/1000
32/32 - 1s - loss: 0.0102 - r1: 0.3897 - r5: 0.6336 - r10: 0.7348 - p5: 0.1267 - p10: 0.0735 - val_loss: 0.0115 - val_r1: 0.3934 - val_r5: 0.6341 - val_r10: 0.7306 - val_p5: 0.1268 - val_p10: 0.0731 - lr: 9.1189e-05 - 789ms/epoch - 25ms/step
Epoch 90/1000
32/32 - 1s - loss: 0.0101 - r1: 0.3932 - r5: 0.6362 - r10: 0.7379 - p5: 0.1272 - p10: 0.0738 - val_loss: 0.0115 - val_r1: 0.3924 - val_r5: 0.6330 - val_r10: 0.7337 - val_p5: 0.1266 - val_p10: 0.0734 - lr: 9.1090e-05 - 788ms/epoch - 25ms/step
Epoch 91/1000
32/32 - 1s - loss: 0.0101 - r1: 0.3887 - r5: 0.6351 - r10: 0.7401 - p5: 0.1270 - p10: 0.0740 - val_loss: 0.0114 - val_r1: 0.3909 - val_r5: 0.6330 - val_r10: 0.7327 - val_p5: 0.1266 - val_p10: 0.0733 - lr: 9.0991e-05 - 793ms/epoch - 25ms/step
Epoch 92/1000
32/32 - 1s - loss: 0.0101 - r1: 0.3928 - r5: 0.6395 - r10: 0.7415 - p5: 0.1279 - p10: 0.0742 - val_loss: 0.0115 - val_r1: 0.3891 - val_r5: 0.6346 - val_r10: 0.7324 - val_p5: 0.1269 - val_p10: 0.0732 - lr: 9.0892e-05 - 790ms/epoch - 25ms/step
Epoch 93/1000
32/32 - 1s - loss: 0.0101 - r1: 0.3918 - r5: 0.6384 - r10: 0.7422 - p5: 0.1277 - p10: 0.0742 - val_loss: 0.0115 - val_r1: 0.3891 - val_r5: 0.6310 - val_r10: 0.7342 - val_p5: 0.1261 - val_p10: 0.0734 - lr: 9.0793e-05 - 791ms/epoch - 25ms/step
Epoch 94/1000
32/32 - 1s - loss: 0.0101 - r1: 0.3946 - r5: 0.6382 - r10: 0.7419 - p5: 0.1276 - p10: 0.0742 - val_loss: 0.0116 - val_r1: 0.3901 - val_r5: 0.6307 - val_r10: 0.7334 - val_p5: 0.1262 - val_p10: 0.0733 - lr: 9.0694e-05 - 789ms/epoch - 25ms/step
Epoch 95/1000
32/32 - 1s - loss: 0.0100 - r1: 0.4016 - r5: 0.6457 - r10: 0.7461 - p5: 0.1291 - p10: 0.0746 - val_loss: 0.0115 - val_r1: 0.3939 - val_r5: 0.6333 - val_r10: 0.7334 - val_p5: 0.1267 - val_p10: 0.0733 - lr: 9.0595e-05 - 789ms/epoch - 25ms/step
Epoch 96/1000
32/32 - 1s - loss: 0.0100 - r1: 0.4000 - r5: 0.6403 - r10: 0.7446 - p5: 0.1281 - p10: 0.0745 - val_loss: 0.0115 - val_r1: 0.3891 - val_r5: 0.6320 - val_r10: 0.7316 - val_p5: 0.1265 - val_p10: 0.0732 - lr: 9.0496e-05 - 790ms/epoch - 25ms/step
Epoch 97/1000
32/32 - 1s - loss: 0.0099 - r1: 0.4005 - r5: 0.6474 - r10: 0.7498 - p5: 0.1295 - p10: 0.0750 - val_loss: 0.0115 - val_r1: 0.3916 - val_r5: 0.6292 - val_r10: 0.7316 - val_p5: 0.1258 - val_p10: 0.0732 - lr: 9.0397e-05 - 792ms/epoch - 25ms/step
Epoch 98/1000
32/32 - 1s - loss: 0.0100 - r1: 0.4026 - r5: 0.6459 - r10: 0.7471 - p5: 0.1292 - p10: 0.0747 - val_loss: 0.0115 - val_r1: 0.3924 - val_r5: 0.6315 - val_r10: 0.7327 - val_p5: 0.1262 - val_p10: 0.0733 - lr: 9.0298e-05 - 790ms/epoch - 25ms/step
Epoch 99/1000
32/32 - 1s - loss: 0.0099 - r1: 0.4065 - r5: 0.6507 - r10: 0.7502 - p5: 0.1301 - p10: 0.0750 - val_loss: 0.0116 - val_r1: 0.3934 - val_r5: 0.6328 - val_r10: 0.7321 - val_p5: 0.1266 - val_p10: 0.0732 - lr: 9.0199e-05 - 788ms/epoch - 25ms/step
Epoch 100/1000
32/32 - 1s - loss: 0.0099 - r1: 0.4021 - r5: 0.6473 - r10: 0.7497 - p5: 0.1294 - p10: 0.0750 - val_loss: 0.0115 - val_r1: 0.3949 - val_r5: 0.6320 - val_r10: 0.7321 - val_p5: 0.1264 - val_p10: 0.0732 - lr: 9.0100e-05 - 790ms/epoch - 25ms/step
Epoch 101/1000
32/32 - 1s - loss: 0.0099 - r1: 0.4043 - r5: 0.6489 - r10: 0.7500 - p5: 0.1298 - p10: 0.0750 - val_loss: 0.0116 - val_r1: 0.3939 - val_r5: 0.6313 - val_r10: 0.7337 - val_p5: 0.1263 - val_p10: 0.0734 - lr: 9.0001e-05 - 787ms/epoch - 25ms/step
Epoch 102/1000
32/32 - 1s - loss: 0.0099 - r1: 0.4023 - r5: 0.6527 - r10: 0.7511 - p5: 0.1306 - p10: 0.0751 - val_loss: 0.0115 - val_r1: 0.3906 - val_r5: 0.6302 - val_r10: 0.7334 - val_p5: 0.1261 - val_p10: 0.0733 - lr: 8.9902e-05 - 786ms/epoch - 25ms/step
Epoch 103/1000
32/32 - 1s - loss: 0.0098 - r1: 0.4060 - r5: 0.6543 - r10: 0.7566 - p5: 0.1309 - p10: 0.0757 - val_loss: 0.0116 - val_r1: 0.3972 - val_r5: 0.6300 - val_r10: 0.7342 - val_p5: 0.1261 - val_p10: 0.0734 - lr: 8.9803e-05 - 790ms/epoch - 25ms/step
Epoch 104/1000
32/32 - 1s - loss: 0.0098 - r1: 0.4043 - r5: 0.6499 - r10: 0.7516 - p5: 0.1300 - p10: 0.0752 - val_loss: 0.0115 - val_r1: 0.3964 - val_r5: 0.6333 - val_r10: 0.7352 - val_p5: 0.1267 - val_p10: 0.0735 - lr: 8.9704e-05 - 785ms/epoch - 25ms/step
Epoch 105/1000
32/32 - 1s - loss: 0.0098 - r1: 0.4063 - r5: 0.6544 - r10: 0.7574 - p5: 0.1309 - p10: 0.0757 - val_loss: 0.0116 - val_r1: 0.3949 - val_r5: 0.6297 - val_r10: 0.7327 - val_p5: 0.1259 - val_p10: 0.0732 - lr: 8.9605e-05 - 794ms/epoch - 25ms/step
Epoch 106/1000
32/32 - 1s - loss: 0.0098 - r1: 0.4091 - r5: 0.6549 - r10: 0.7562 - p5: 0.1310 - p10: 0.0756 - val_loss: 0.0116 - val_r1: 0.3883 - val_r5: 0.6305 - val_r10: 0.7296 - val_p5: 0.1261 - val_p10: 0.0729 - lr: 8.9506e-05 - 792ms/epoch - 25ms/step
Epoch 107/1000
32/32 - 1s - loss: 0.0098 - r1: 0.4097 - r5: 0.6559 - r10: 0.7552 - p5: 0.1312 - p10: 0.0755 - val_loss: 0.0117 - val_r1: 0.3921 - val_r5: 0.6323 - val_r10: 0.7327 - val_p5: 0.1265 - val_p10: 0.0732 - lr: 8.9407e-05 - 789ms/epoch - 25ms/step
Epoch 108/1000
32/32 - 1s - loss: 0.0097 - r1: 0.4131 - r5: 0.6586 - r10: 0.7573 - p5: 0.1317 - p10: 0.0757 - val_loss: 0.0117 - val_r1: 0.3926 - val_r5: 0.6302 - val_r10: 0.7344 - val_p5: 0.1260 - val_p10: 0.0735 - lr: 8.9308e-05 - 786ms/epoch - 25ms/step
Epoch 109/1000
32/32 - 1s - loss: 0.0097 - r1: 0.4145 - r5: 0.6598 - r10: 0.7586 - p5: 0.1320 - p10: 0.0759 - val_loss: 0.0116 - val_r1: 0.3967 - val_r5: 0.6282 - val_r10: 0.7332 - val_p5: 0.1256 - val_p10: 0.0733 - lr: 8.9209e-05 - 794ms/epoch - 25ms/step
Epoch 110/1000
32/32 - 1s - loss: 0.0097 - r1: 0.4129 - r5: 0.6592 - r10: 0.7598 - p5: 0.1318 - p10: 0.0760 - val_loss: 0.0116 - val_r1: 0.3959 - val_r5: 0.6333 - val_r10: 0.7324 - val_p5: 0.1267 - val_p10: 0.0733 - lr: 8.9110e-05 - 791ms/epoch - 25ms/step
Epoch 111/1000
32/32 - 1s - loss: 0.0097 - r1: 0.4154 - r5: 0.6615 - r10: 0.7622 - p5: 0.1323 - p10: 0.0762 - val_loss: 0.0117 - val_r1: 0.3987 - val_r5: 0.6343 - val_r10: 0.7357 - val_p5: 0.1268 - val_p10: 0.0736 - lr: 8.9011e-05 - 791ms/epoch - 25ms/step
Epoch 112/1000
32/32 - 1s - loss: 0.0096 - r1: 0.4190 - r5: 0.6648 - r10: 0.7616 - p5: 0.1330 - p10: 0.0762 - val_loss: 0.0116 - val_r1: 0.3985 - val_r5: 0.6323 - val_r10: 0.7327 - val_p5: 0.1265 - val_p10: 0.0733 - lr: 8.8912e-05 - 792ms/epoch - 25ms/step
Epoch 113/1000
32/32 - 1s - loss: 0.0096 - r1: 0.4165 - r5: 0.6633 - r10: 0.7631 - p5: 0.1327 - p10: 0.0763 - val_loss: 0.0116 - val_r1: 0.3954 - val_r5: 0.6356 - val_r10: 0.7349 - val_p5: 0.1271 - val_p10: 0.0735 - lr: 8.8813e-05 - 787ms/epoch - 25ms/step
Epoch 114/1000
32/32 - 1s - loss: 0.0096 - r1: 0.4176 - r5: 0.6648 - r10: 0.7644 - p5: 0.1330 - p10: 0.0764 - val_loss: 0.0116 - val_r1: 0.4015 - val_r5: 0.6346 - val_r10: 0.7339 - val_p5: 0.1269 - val_p10: 0.0734 - lr: 8.8714e-05 - 788ms/epoch - 25ms/step
Epoch 115/1000
32/32 - 1s - loss: 0.0096 - r1: 0.4173 - r5: 0.6641 - r10: 0.7654 - p5: 0.1328 - p10: 0.0766 - val_loss: 0.0116 - val_r1: 0.3987 - val_r5: 0.6302 - val_r10: 0.7352 - val_p5: 0.1260 - val_p10: 0.0735 - lr: 8.8615e-05 - 795ms/epoch - 25ms/step
Epoch 116/1000
32/32 - 1s - loss: 0.0096 - r1: 0.4210 - r5: 0.6677 - r10: 0.7672 - p5: 0.1335 - p10: 0.0767 - val_loss: 0.0116 - val_r1: 0.3959 - val_r5: 0.6320 - val_r10: 0.7337 - val_p5: 0.1264 - val_p10: 0.0733 - lr: 8.8516e-05 - 792ms/epoch - 25ms/step
Epoch 117/1000
32/32 - 1s - loss: 0.0096 - r1: 0.4189 - r5: 0.6658 - r10: 0.7667 - p5: 0.1332 - p10: 0.0767 - val_loss: 0.0117 - val_r1: 0.3924 - val_r5: 0.6267 - val_r10: 0.7309 - val_p5: 0.1253 - val_p10: 0.0731 - lr: 8.8417e-05 - 790ms/epoch - 25ms/step
Epoch 118/1000
32/32 - 1s - loss: 0.0095 - r1: 0.4206 - r5: 0.6684 - r10: 0.7683 - p5: 0.1337 - p10: 0.0768 - val_loss: 0.0117 - val_r1: 0.3954 - val_r5: 0.6277 - val_r10: 0.7301 - val_p5: 0.1255 - val_p10: 0.0730 - lr: 8.8318e-05 - 788ms/epoch - 25ms/step
Epoch 119/1000
32/32 - 1s - loss: 0.0095 - r1: 0.4244 - r5: 0.6687 - r10: 0.7721 - p5: 0.1338 - p10: 0.0772 - val_loss: 0.0119 - val_r1: 0.3952 - val_r5: 0.6259 - val_r10: 0.7299 - val_p5: 0.1251 - val_p10: 0.0730 - lr: 8.8219e-05 - 790ms/epoch - 25ms/step
Epoch 120/1000
32/32 - 1s - loss: 0.0095 - r1: 0.4207 - r5: 0.6731 - r10: 0.7718 - p5: 0.1346 - p10: 0.0772 - val_loss: 0.0117 - val_r1: 0.3924 - val_r5: 0.6264 - val_r10: 0.7329 - val_p5: 0.1253 - val_p10: 0.0733 - lr: 8.8120e-05 - 789ms/epoch - 25ms/step
Epoch 120: early stopping
[92m[INFO] Loading best model...[0m
[93m[WARNING] Model folder already exists...[0m
Model: "ATT2ITM_1"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 162)]        0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 149)]        0           []                               
                                                                                                  
 embedding (Embedding)          (None, 162, 384)     926976      ['input_1[0][0]']                
                                                                                                  
 in_rsts (Embedding)            (None, 149, 384)     57216       ['input_2[0][0]']                
                                                                                                  
 dense (Dense)                  (None, 162, 256)     98560       ['embedding[0][0]']              
                                                                                                  
 dense_2 (Dense)                (None, 149, 256)     98560       ['in_rsts[0][0]']                
                                                                                                  
 tf.math.not_equal (TFOpLambda)  (None, 162)         0           ['input_1[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 162, 128)     32896       ['dense[0][0]']                  
                                                                                                  
 dense_3 (Dense)                (None, 149, 128)     32896       ['dense_2[0][0]']                
                                                                                                  
 tf.cast (TFOpLambda)           (None, 162)          0           ['tf.math.not_equal[0][0]']      
                                                                                                  
 word_emb (Lambda)              (None, 162, 128)     0           ['dense_1[0][0]']                
                                                                                                  
 rest_emb (Lambda)              (None, 149, 128)     0           ['dense_3[0][0]']                
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 162, 1)       0           ['tf.cast[0][0]']                
                                                                                                  
 lambda (Lambda)                (None, 162, 149)     0           ['word_emb[0][0]',               
                                                                  'rest_emb[0][0]']               
                                                                                                  
 tf.tile (TFOpLambda)           (None, 162, 149)     0           ['tf.expand_dims[0][0]']         
                                                                                                  
 lambda_1 (Lambda)              (None, 162, 149)     0           ['lambda[0][0]',                 
                                                                  'tf.tile[0][0]']                
                                                                                                  
 dotprod (Activation)           (None, 162, 149)     0           ['lambda_1[0][0]']               
                                                                                                  
 dropout (Dropout)              (None, 162, 149)     0           ['dotprod[0][0]']                
                                                                                                  
 sum (Lambda)                   (None, 149)          0           ['dropout[0][0]']                
                                                                                                  
 out (Activation)               (None, 149)          0           ['sum[0][0]']                    
                                                                                                  
==================================================================================================
Total params: 1,247,104
Trainable params: 1,247,104
Non-trainable params: 0
__________________________________________________________________________________________________
None
[92m[INFO] Model already trained. Loading weights...[0m
[93m[WARNING] Model folder already exists...[0m
Model: "ATT2ITM_1"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 162)]        0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 149)]        0           []                               
                                                                                                  
 embedding (Embedding)          (None, 162, 384)     926976      ['input_1[0][0]']                
                                                                                                  
 in_rsts (Embedding)            (None, 149, 384)     57216       ['input_2[0][0]']                
                                                                                                  
 dense (Dense)                  (None, 162, 256)     98560       ['embedding[0][0]']              
                                                                                                  
 dense_2 (Dense)                (None, 149, 256)     98560       ['in_rsts[0][0]']                
                                                                                                  
 tf.math.not_equal (TFOpLambda)  (None, 162)         0           ['input_1[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 162, 128)     32896       ['dense[0][0]']                  
                                                                                                  
 dense_3 (Dense)                (None, 149, 128)     32896       ['dense_2[0][0]']                
                                                                                                  
 tf.cast (TFOpLambda)           (None, 162)          0           ['tf.math.not_equal[0][0]']      
                                                                                                  
 word_emb (Lambda)              (None, 162, 128)     0           ['dense_1[0][0]']                
                                                                                                  
 rest_emb (Lambda)              (None, 149, 128)     0           ['dense_3[0][0]']                
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 162, 1)       0           ['tf.cast[0][0]']                
                                                                                                  
 lambda (Lambda)                (None, 162, 149)     0           ['word_emb[0][0]',               
                                                                  'rest_emb[0][0]']               
                                                                                                  
 tf.tile (TFOpLambda)           (None, 162, 149)     0           ['tf.expand_dims[0][0]']         
                                                                                                  
 lambda_1 (Lambda)              (None, 162, 149)     0           ['lambda[0][0]',                 
                                                                  'tf.tile[0][0]']                
                                                                                                  
 dotprod (Activation)           (None, 162, 149)     0           ['lambda_1[0][0]']               
                                                                                                  
 dropout (Dropout)              (None, 162, 149)     0           ['dotprod[0][0]']                
                                                                                                  
 sum (Lambda)                   (None, 149)          0           ['dropout[0][0]']                
                                                                                                  
 out (Activation)               (None, 149)          0           ['sum[0][0]']                    
                                                                                                  
==================================================================================================
Total params: 1,247,104
Trainable params: 1,247,104
Non-trainable params: 0
__________________________________________________________________________________________________
None
[92m[INFO] Model already trained. Loading weights...[0m
[93m[WARNING] Model folder already exists...[0m
Model: "ATT2ITM_1"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 162)]        0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 149)]        0           []                               
                                                                                                  
 embedding (Embedding)          (None, 162, 384)     926976      ['input_1[0][0]']                
                                                                                                  
 in_rsts (Embedding)            (None, 149, 384)     57216       ['input_2[0][0]']                
                                                                                                  
 dense (Dense)                  (None, 162, 256)     98560       ['embedding[0][0]']              
                                                                                                  
 dense_2 (Dense)                (None, 149, 256)     98560       ['in_rsts[0][0]']                
                                                                                                  
 tf.math.not_equal (TFOpLambda)  (None, 162)         0           ['input_1[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 162, 128)     32896       ['dense[0][0]']                  
                                                                                                  
 dense_3 (Dense)                (None, 149, 128)     32896       ['dense_2[0][0]']                
                                                                                                  
 tf.cast (TFOpLambda)           (None, 162)          0           ['tf.math.not_equal[0][0]']      
                                                                                                  
 word_emb (Lambda)              (None, 162, 128)     0           ['dense_1[0][0]']                
                                                                                                  
 rest_emb (Lambda)              (None, 149, 128)     0           ['dense_3[0][0]']                
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 162, 1)       0           ['tf.cast[0][0]']                
                                                                                                  
 lambda (Lambda)                (None, 162, 149)     0           ['word_emb[0][0]',               
                                                                  'rest_emb[0][0]']               
                                                                                                  
 tf.tile (TFOpLambda)           (None, 162, 149)     0           ['tf.expand_dims[0][0]']         
                                                                                                  
 lambda_1 (Lambda)              (None, 162, 149)     0           ['lambda[0][0]',                 
                                                                  'tf.tile[0][0]']                
                                                                                                  
 dotprod (Activation)           (None, 162, 149)     0           ['lambda_1[0][0]']               
                                                                                                  
 dropout (Dropout)              (None, 162, 149)     0           ['dotprod[0][0]']                
                                                                                                  
 sum (Lambda)                   (None, 149)          0           ['dropout[0][0]']                
                                                                                                  
 out (Activation)               (None, 149)          0           ['sum[0][0]']                    
                                                                                                  
==================================================================================================
Total params: 1,247,104
Trainable params: 1,247,104
Non-trainable params: 0
__________________________________________________________________________________________________
None
[92m[INFO] Model already trained. Loading weights...[0m
