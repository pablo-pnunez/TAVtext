Model: "ATT2ITM_0"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 162)]        0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 149)]        0           []                               
                                                                                                  
 embedding (Embedding)          (None, 162, 384)     926976      ['input_1[0][0]']                
                                                                                                  
 in_rsts (Embedding)            (None, 149, 384)     57216       ['input_2[0][0]']                
                                                                                                  
 dense (Dense)                  (None, 162, 256)     98560       ['embedding[0][0]']              
                                                                                                  
 dense_2 (Dense)                (None, 149, 256)     98560       ['in_rsts[0][0]']                
                                                                                                  
 tf.math.not_equal (TFOpLambda)  (None, 162)         0           ['input_1[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 162, 128)     32896       ['dense[0][0]']                  
                                                                                                  
 dense_3 (Dense)                (None, 149, 128)     32896       ['dense_2[0][0]']                
                                                                                                  
 tf.cast (TFOpLambda)           (None, 162)          0           ['tf.math.not_equal[0][0]']      
                                                                                                  
 word_emb (Lambda)              (None, 162, 128)     0           ['dense_1[0][0]']                
                                                                                                  
 rest_emb (Lambda)              (None, 149, 128)     0           ['dense_3[0][0]']                
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 162, 1)       0           ['tf.cast[0][0]']                
                                                                                                  
 lambda (Lambda)                (None, 162, 149)     0           ['word_emb[0][0]',               
                                                                  'rest_emb[0][0]']               
                                                                                                  
 tf.tile (TFOpLambda)           (None, 162, 149)     0           ['tf.expand_dims[0][0]']         
                                                                                                  
 lambda_1 (Lambda)              (None, 162, 149)     0           ['lambda[0][0]',                 
                                                                  'tf.tile[0][0]']                
                                                                                                  
 dotprod (Activation)           (None, 162, 149)     0           ['lambda_1[0][0]']               
                                                                                                  
 dropout (Dropout)              (None, 162, 149)     0           ['dotprod[0][0]']                
                                                                                                  
 sum (Lambda)                   (None, 149)          0           ['dropout[0][0]']                
                                                                                                  
 out (Activation)               (None, 149)          0           ['sum[0][0]']                    
                                                                                                  
==================================================================================================
Total params: 1,247,104
Trainable params: 1,247,104
Non-trainable params: 0
__________________________________________________________________________________________________
None
Epoch 1/1000
63/63 - 4s - loss: 4.8199 - r1: 0.0610 - r5: 0.1704 - r10: 0.2438 - p5: 0.0341 - p10: 0.0244 - val_loss: 4.7150 - val_r1: 0.0747 - val_r5: 0.2137 - val_r10: 0.2943 - val_p5: 0.0427 - val_p10: 0.0294 - lr: 9.9901e-05 - 4s/epoch - 58ms/step
Epoch 2/1000
63/63 - 1s - loss: 4.6129 - r1: 0.0900 - r5: 0.2320 - r10: 0.3197 - p5: 0.0464 - p10: 0.0320 - val_loss: 4.4916 - val_r1: 0.1083 - val_r5: 0.2663 - val_r10: 0.3502 - val_p5: 0.0533 - val_p10: 0.0350 - lr: 9.9802e-05 - 1s/epoch - 17ms/step
Epoch 3/1000
63/63 - 1s - loss: 4.3544 - r1: 0.1259 - r5: 0.2878 - r10: 0.3817 - p5: 0.0576 - p10: 0.0382 - val_loss: 4.1855 - val_r1: 0.1693 - val_r5: 0.3360 - val_r10: 0.4346 - val_p5: 0.0672 - val_p10: 0.0435 - lr: 9.9703e-05 - 1s/epoch - 17ms/step
Epoch 4/1000
63/63 - 1s - loss: 4.0640 - r1: 0.1604 - r5: 0.3434 - r10: 0.4542 - p5: 0.0687 - p10: 0.0454 - val_loss: 3.8930 - val_r1: 0.2117 - val_r5: 0.4114 - val_r10: 0.5189 - val_p5: 0.0823 - val_p10: 0.0519 - lr: 9.9604e-05 - 1s/epoch - 17ms/step
Epoch 5/1000
63/63 - 1s - loss: 3.8285 - r1: 0.1895 - r5: 0.3932 - r10: 0.5092 - p5: 0.0786 - p10: 0.0509 - val_loss: 3.6883 - val_r1: 0.2419 - val_r5: 0.4579 - val_r10: 0.5753 - val_p5: 0.0916 - val_p10: 0.0575 - lr: 9.9505e-05 - 1s/epoch - 17ms/step
Epoch 6/1000
63/63 - 1s - loss: 3.6777 - r1: 0.2081 - r5: 0.4255 - r10: 0.5442 - p5: 0.0851 - p10: 0.0544 - val_loss: 3.5460 - val_r1: 0.2633 - val_r5: 0.4902 - val_r10: 0.6130 - val_p5: 0.0980 - val_p10: 0.0613 - lr: 9.9406e-05 - 1s/epoch - 17ms/step
Epoch 7/1000
63/63 - 1s - loss: 3.5415 - r1: 0.2302 - r5: 0.4536 - r10: 0.5784 - p5: 0.0907 - p10: 0.0579 - val_loss: 3.4290 - val_r1: 0.2915 - val_r5: 0.5215 - val_r10: 0.6409 - val_p5: 0.1043 - val_p10: 0.0641 - lr: 9.9307e-05 - 1s/epoch - 17ms/step
Epoch 8/1000
63/63 - 1s - loss: 3.4453 - r1: 0.2456 - r5: 0.4787 - r10: 0.5999 - p5: 0.0957 - p10: 0.0600 - val_loss: 3.3303 - val_r1: 0.3034 - val_r5: 0.5416 - val_r10: 0.6579 - val_p5: 0.1084 - val_p10: 0.0658 - lr: 9.9208e-05 - 1s/epoch - 17ms/step
Epoch 9/1000
63/63 - 1s - loss: 3.3410 - r1: 0.2637 - r5: 0.5020 - r10: 0.6229 - p5: 0.1004 - p10: 0.0623 - val_loss: 3.2402 - val_r1: 0.3266 - val_r5: 0.5593 - val_r10: 0.6750 - val_p5: 0.1119 - val_p10: 0.0675 - lr: 9.9109e-05 - 1s/epoch - 17ms/step
Epoch 10/1000
63/63 - 1s - loss: 3.2549 - r1: 0.2754 - r5: 0.5209 - r10: 0.6407 - p5: 0.1042 - p10: 0.0641 - val_loss: 3.1698 - val_r1: 0.3316 - val_r5: 0.5718 - val_r10: 0.6851 - val_p5: 0.1144 - val_p10: 0.0685 - lr: 9.9010e-05 - 1s/epoch - 17ms/step
Epoch 11/1000
63/63 - 1s - loss: 3.1732 - r1: 0.2887 - r5: 0.5386 - r10: 0.6560 - p5: 0.1077 - p10: 0.0656 - val_loss: 3.1035 - val_r1: 0.3418 - val_r5: 0.5863 - val_r10: 0.6910 - val_p5: 0.1173 - val_p10: 0.0691 - lr: 9.8911e-05 - 1s/epoch - 17ms/step
Epoch 12/1000
63/63 - 1s - loss: 3.1076 - r1: 0.2979 - r5: 0.5528 - r10: 0.6700 - p5: 0.1105 - p10: 0.0670 - val_loss: 3.0433 - val_r1: 0.3474 - val_r5: 0.5934 - val_r10: 0.6999 - val_p5: 0.1187 - val_p10: 0.0700 - lr: 9.8812e-05 - 1s/epoch - 17ms/step
Epoch 13/1000
63/63 - 1s - loss: 3.0630 - r1: 0.3077 - r5: 0.5612 - r10: 0.6763 - p5: 0.1122 - p10: 0.0676 - val_loss: 2.9979 - val_r1: 0.3606 - val_r5: 0.6025 - val_r10: 0.7121 - val_p5: 0.1205 - val_p10: 0.0712 - lr: 9.8713e-05 - 1s/epoch - 17ms/step
Epoch 14/1000
63/63 - 1s - loss: 2.9984 - r1: 0.3197 - r5: 0.5731 - r10: 0.6890 - p5: 0.1146 - p10: 0.0689 - val_loss: 2.9629 - val_r1: 0.3611 - val_r5: 0.6094 - val_r10: 0.7144 - val_p5: 0.1219 - val_p10: 0.0714 - lr: 9.8614e-05 - 1s/epoch - 17ms/step
Epoch 15/1000
63/63 - 1s - loss: 2.9601 - r1: 0.3244 - r5: 0.5824 - r10: 0.6967 - p5: 0.1165 - p10: 0.0697 - val_loss: 2.9260 - val_r1: 0.3698 - val_r5: 0.6099 - val_r10: 0.7172 - val_p5: 0.1220 - val_p10: 0.0717 - lr: 9.8515e-05 - 1s/epoch - 17ms/step
Epoch 16/1000
63/63 - 1s - loss: 2.9112 - r1: 0.3349 - r5: 0.5883 - r10: 0.7036 - p5: 0.1177 - p10: 0.0704 - val_loss: 2.9026 - val_r1: 0.3700 - val_r5: 0.6155 - val_r10: 0.7197 - val_p5: 0.1231 - val_p10: 0.0719 - lr: 9.8416e-05 - 1s/epoch - 17ms/step
Epoch 17/1000
63/63 - 1s - loss: 2.8808 - r1: 0.3399 - r5: 0.5970 - r10: 0.7094 - p5: 0.1194 - p10: 0.0709 - val_loss: 2.8871 - val_r1: 0.3731 - val_r5: 0.6193 - val_r10: 0.7194 - val_p5: 0.1239 - val_p10: 0.0719 - lr: 9.8317e-05 - 1s/epoch - 17ms/step
Epoch 18/1000
63/63 - 1s - loss: 2.8501 - r1: 0.3452 - r5: 0.6031 - r10: 0.7161 - p5: 0.1206 - p10: 0.0716 - val_loss: 2.8660 - val_r1: 0.3797 - val_r5: 0.6196 - val_r10: 0.7207 - val_p5: 0.1239 - val_p10: 0.0721 - lr: 9.8218e-05 - 1s/epoch - 17ms/step
Epoch 19/1000
63/63 - 1s - loss: 2.8092 - r1: 0.3535 - r5: 0.6113 - r10: 0.7237 - p5: 0.1222 - p10: 0.0724 - val_loss: 2.8433 - val_r1: 0.3825 - val_r5: 0.6249 - val_r10: 0.7263 - val_p5: 0.1250 - val_p10: 0.0726 - lr: 9.8119e-05 - 1s/epoch - 17ms/step
Epoch 20/1000
63/63 - 1s - loss: 2.7917 - r1: 0.3548 - r5: 0.6133 - r10: 0.7275 - p5: 0.1226 - p10: 0.0727 - val_loss: 2.8411 - val_r1: 0.3789 - val_r5: 0.6206 - val_r10: 0.7260 - val_p5: 0.1241 - val_p10: 0.0726 - lr: 9.8020e-05 - 1s/epoch - 17ms/step
Epoch 21/1000
63/63 - 1s - loss: 2.7608 - r1: 0.3622 - r5: 0.6222 - r10: 0.7291 - p5: 0.1244 - p10: 0.0729 - val_loss: 2.8208 - val_r1: 0.3827 - val_r5: 0.6315 - val_r10: 0.7255 - val_p5: 0.1263 - val_p10: 0.0726 - lr: 9.7921e-05 - 1s/epoch - 17ms/step
Epoch 22/1000
63/63 - 1s - loss: 2.7386 - r1: 0.3666 - r5: 0.6252 - r10: 0.7351 - p5: 0.1250 - p10: 0.0735 - val_loss: 2.8133 - val_r1: 0.3820 - val_r5: 0.6274 - val_r10: 0.7266 - val_p5: 0.1255 - val_p10: 0.0727 - lr: 9.7822e-05 - 1s/epoch - 17ms/step
Epoch 23/1000
63/63 - 1s - loss: 2.7135 - r1: 0.3672 - r5: 0.6320 - r10: 0.7410 - p5: 0.1264 - p10: 0.0741 - val_loss: 2.8076 - val_r1: 0.3848 - val_r5: 0.6247 - val_r10: 0.7286 - val_p5: 0.1249 - val_p10: 0.0729 - lr: 9.7723e-05 - 1s/epoch - 17ms/step
Epoch 24/1000
63/63 - 1s - loss: 2.6889 - r1: 0.3763 - r5: 0.6357 - r10: 0.7414 - p5: 0.1271 - p10: 0.0741 - val_loss: 2.7960 - val_r1: 0.3878 - val_r5: 0.6257 - val_r10: 0.7296 - val_p5: 0.1251 - val_p10: 0.0730 - lr: 9.7624e-05 - 1s/epoch - 17ms/step
Epoch 25/1000
63/63 - 1s - loss: 2.6792 - r1: 0.3757 - r5: 0.6364 - r10: 0.7433 - p5: 0.1273 - p10: 0.0743 - val_loss: 2.7905 - val_r1: 0.3873 - val_r5: 0.6318 - val_r10: 0.7311 - val_p5: 0.1264 - val_p10: 0.0731 - lr: 9.7525e-05 - 1s/epoch - 17ms/step
Epoch 26/1000
63/63 - 1s - loss: 2.6568 - r1: 0.3786 - r5: 0.6416 - r10: 0.7470 - p5: 0.1283 - p10: 0.0747 - val_loss: 2.7812 - val_r1: 0.3888 - val_r5: 0.6333 - val_r10: 0.7319 - val_p5: 0.1267 - val_p10: 0.0732 - lr: 9.7426e-05 - 1s/epoch - 17ms/step
Epoch 27/1000
63/63 - 1s - loss: 2.6353 - r1: 0.3834 - r5: 0.6436 - r10: 0.7524 - p5: 0.1287 - p10: 0.0752 - val_loss: 2.7799 - val_r1: 0.3883 - val_r5: 0.6300 - val_r10: 0.7304 - val_p5: 0.1260 - val_p10: 0.0730 - lr: 9.7327e-05 - 1s/epoch - 17ms/step
Epoch 28/1000
63/63 - 1s - loss: 2.6067 - r1: 0.3916 - r5: 0.6480 - r10: 0.7545 - p5: 0.1296 - p10: 0.0755 - val_loss: 2.7736 - val_r1: 0.3924 - val_r5: 0.6287 - val_r10: 0.7314 - val_p5: 0.1257 - val_p10: 0.0731 - lr: 9.7228e-05 - 1s/epoch - 17ms/step
Epoch 29/1000
63/63 - 1s - loss: 2.5934 - r1: 0.3918 - r5: 0.6527 - r10: 0.7585 - p5: 0.1305 - p10: 0.0759 - val_loss: 2.7659 - val_r1: 0.3911 - val_r5: 0.6310 - val_r10: 0.7306 - val_p5: 0.1262 - val_p10: 0.0731 - lr: 9.7129e-05 - 1s/epoch - 19ms/step
Epoch 30/1000
63/63 - 1s - loss: 2.5760 - r1: 0.3953 - r5: 0.6550 - r10: 0.7615 - p5: 0.1310 - p10: 0.0761 - val_loss: 2.7612 - val_r1: 0.3909 - val_r5: 0.6366 - val_r10: 0.7296 - val_p5: 0.1273 - val_p10: 0.0729 - lr: 9.7030e-05 - 1s/epoch - 19ms/step
Epoch 31/1000
63/63 - 1s - loss: 2.5678 - r1: 0.3956 - r5: 0.6582 - r10: 0.7621 - p5: 0.1316 - p10: 0.0762 - val_loss: 2.7597 - val_r1: 0.3848 - val_r5: 0.6325 - val_r10: 0.7324 - val_p5: 0.1265 - val_p10: 0.0732 - lr: 9.6931e-05 - 1s/epoch - 19ms/step
Epoch 32/1000
63/63 - 1s - loss: 2.5463 - r1: 0.4025 - r5: 0.6642 - r10: 0.7649 - p5: 0.1328 - p10: 0.0765 - val_loss: 2.7569 - val_r1: 0.3873 - val_r5: 0.6361 - val_r10: 0.7327 - val_p5: 0.1272 - val_p10: 0.0733 - lr: 9.6832e-05 - 1s/epoch - 19ms/step
Epoch 33/1000
63/63 - 1s - loss: 2.5349 - r1: 0.4036 - r5: 0.6636 - r10: 0.7669 - p5: 0.1327 - p10: 0.0767 - val_loss: 2.7513 - val_r1: 0.3949 - val_r5: 0.6328 - val_r10: 0.7337 - val_p5: 0.1265 - val_p10: 0.0734 - lr: 9.6733e-05 - 1s/epoch - 19ms/step
Epoch 34/1000
63/63 - 1s - loss: 2.5201 - r1: 0.4072 - r5: 0.6687 - r10: 0.7709 - p5: 0.1337 - p10: 0.0771 - val_loss: 2.7410 - val_r1: 0.3926 - val_r5: 0.6343 - val_r10: 0.7344 - val_p5: 0.1269 - val_p10: 0.0734 - lr: 9.6634e-05 - 1s/epoch - 19ms/step
Epoch 35/1000
63/63 - 1s - loss: 2.5089 - r1: 0.4087 - r5: 0.6688 - r10: 0.7716 - p5: 0.1338 - p10: 0.0772 - val_loss: 2.7424 - val_r1: 0.3957 - val_r5: 0.6302 - val_r10: 0.7355 - val_p5: 0.1260 - val_p10: 0.0735 - lr: 9.6535e-05 - 918ms/epoch - 15ms/step
Epoch 36/1000
63/63 - 1s - loss: 2.4929 - r1: 0.4119 - r5: 0.6724 - r10: 0.7750 - p5: 0.1345 - p10: 0.0775 - val_loss: 2.7407 - val_r1: 0.3919 - val_r5: 0.6335 - val_r10: 0.7324 - val_p5: 0.1267 - val_p10: 0.0732 - lr: 9.6436e-05 - 1s/epoch - 17ms/step
Epoch 37/1000
63/63 - 1s - loss: 2.4760 - r1: 0.4122 - r5: 0.6780 - r10: 0.7771 - p5: 0.1356 - p10: 0.0777 - val_loss: 2.7406 - val_r1: 0.3906 - val_r5: 0.6338 - val_r10: 0.7352 - val_p5: 0.1268 - val_p10: 0.0735 - lr: 9.6337e-05 - 1s/epoch - 17ms/step
Epoch 38/1000
63/63 - 1s - loss: 2.4734 - r1: 0.4130 - r5: 0.6792 - r10: 0.7776 - p5: 0.1358 - p10: 0.0778 - val_loss: 2.7373 - val_r1: 0.3893 - val_r5: 0.6341 - val_r10: 0.7347 - val_p5: 0.1268 - val_p10: 0.0735 - lr: 9.6238e-05 - 1s/epoch - 17ms/step
Epoch 39/1000
63/63 - 1s - loss: 2.4562 - r1: 0.4153 - r5: 0.6809 - r10: 0.7834 - p5: 0.1362 - p10: 0.0783 - val_loss: 2.7393 - val_r1: 0.3919 - val_r5: 0.6330 - val_r10: 0.7337 - val_p5: 0.1266 - val_p10: 0.0734 - lr: 9.6139e-05 - 916ms/epoch - 15ms/step
Epoch 40/1000
63/63 - 1s - loss: 2.4359 - r1: 0.4212 - r5: 0.6868 - r10: 0.7849 - p5: 0.1374 - p10: 0.0785 - val_loss: 2.7332 - val_r1: 0.3926 - val_r5: 0.6295 - val_r10: 0.7367 - val_p5: 0.1259 - val_p10: 0.0737 - lr: 9.6040e-05 - 1s/epoch - 17ms/step
Epoch 41/1000
63/63 - 1s - loss: 2.4341 - r1: 0.4193 - r5: 0.6873 - r10: 0.7858 - p5: 0.1375 - p10: 0.0786 - val_loss: 2.7359 - val_r1: 0.3952 - val_r5: 0.6323 - val_r10: 0.7388 - val_p5: 0.1265 - val_p10: 0.0739 - lr: 9.5941e-05 - 922ms/epoch - 15ms/step
Epoch 42/1000
63/63 - 1s - loss: 2.4190 - r1: 0.4201 - r5: 0.6863 - r10: 0.7865 - p5: 0.1373 - p10: 0.0786 - val_loss: 2.7363 - val_r1: 0.3926 - val_r5: 0.6267 - val_r10: 0.7403 - val_p5: 0.1253 - val_p10: 0.0740 - lr: 9.5842e-05 - 918ms/epoch - 15ms/step
Epoch 43/1000
63/63 - 1s - loss: 2.4082 - r1: 0.4222 - r5: 0.6903 - r10: 0.7893 - p5: 0.1381 - p10: 0.0789 - val_loss: 2.7274 - val_r1: 0.3936 - val_r5: 0.6320 - val_r10: 0.7400 - val_p5: 0.1264 - val_p10: 0.0740 - lr: 9.5743e-05 - 1s/epoch - 17ms/step
Epoch 44/1000
63/63 - 1s - loss: 2.3995 - r1: 0.4292 - r5: 0.6905 - r10: 0.7906 - p5: 0.1381 - p10: 0.0791 - val_loss: 2.7319 - val_r1: 0.3962 - val_r5: 0.6318 - val_r10: 0.7349 - val_p5: 0.1264 - val_p10: 0.0735 - lr: 9.5644e-05 - 918ms/epoch - 15ms/step
Epoch 45/1000
63/63 - 1s - loss: 2.3898 - r1: 0.4297 - r5: 0.6943 - r10: 0.7919 - p5: 0.1389 - p10: 0.0792 - val_loss: 2.7303 - val_r1: 0.3972 - val_r5: 0.6325 - val_r10: 0.7357 - val_p5: 0.1265 - val_p10: 0.0736 - lr: 9.5545e-05 - 913ms/epoch - 14ms/step
Epoch 46/1000
63/63 - 1s - loss: 2.3771 - r1: 0.4296 - r5: 0.6972 - r10: 0.7970 - p5: 0.1394 - p10: 0.0797 - val_loss: 2.7257 - val_r1: 0.3891 - val_r5: 0.6295 - val_r10: 0.7393 - val_p5: 0.1259 - val_p10: 0.0739 - lr: 9.5446e-05 - 1s/epoch - 19ms/step
Epoch 47/1000
63/63 - 1s - loss: 2.3666 - r1: 0.4321 - r5: 0.6967 - r10: 0.7962 - p5: 0.1393 - p10: 0.0796 - val_loss: 2.7207 - val_r1: 0.3959 - val_r5: 0.6338 - val_r10: 0.7370 - val_p5: 0.1267 - val_p10: 0.0737 - lr: 9.5347e-05 - 1s/epoch - 19ms/step
Epoch 48/1000
63/63 - 1s - loss: 2.3530 - r1: 0.4364 - r5: 0.7005 - r10: 0.7974 - p5: 0.1401 - p10: 0.0797 - val_loss: 2.7211 - val_r1: 0.3954 - val_r5: 0.6343 - val_r10: 0.7426 - val_p5: 0.1269 - val_p10: 0.0743 - lr: 9.5248e-05 - 913ms/epoch - 14ms/step
Epoch 49/1000
63/63 - 1s - loss: 2.3381 - r1: 0.4374 - r5: 0.7041 - r10: 0.7998 - p5: 0.1408 - p10: 0.0800 - val_loss: 2.7256 - val_r1: 0.3909 - val_r5: 0.6307 - val_r10: 0.7342 - val_p5: 0.1261 - val_p10: 0.0734 - lr: 9.5149e-05 - 917ms/epoch - 15ms/step
Epoch 50/1000
63/63 - 1s - loss: 2.3341 - r1: 0.4393 - r5: 0.7049 - r10: 0.7998 - p5: 0.1410 - p10: 0.0800 - val_loss: 2.7215 - val_r1: 0.3967 - val_r5: 0.6307 - val_r10: 0.7344 - val_p5: 0.1261 - val_p10: 0.0735 - lr: 9.5050e-05 - 919ms/epoch - 15ms/step
Epoch 51/1000
63/63 - 1s - loss: 2.3343 - r1: 0.4388 - r5: 0.7055 - r10: 0.7999 - p5: 0.1411 - p10: 0.0800 - val_loss: 2.7246 - val_r1: 0.3949 - val_r5: 0.6302 - val_r10: 0.7365 - val_p5: 0.1260 - val_p10: 0.0736 - lr: 9.4951e-05 - 912ms/epoch - 14ms/step
Epoch 52/1000
63/63 - 1s - loss: 2.3192 - r1: 0.4431 - r5: 0.7076 - r10: 0.8023 - p5: 0.1415 - p10: 0.0802 - val_loss: 2.7264 - val_r1: 0.3936 - val_r5: 0.6287 - val_r10: 0.7360 - val_p5: 0.1257 - val_p10: 0.0736 - lr: 9.4852e-05 - 909ms/epoch - 14ms/step
Epoch 53/1000
63/63 - 1s - loss: 2.3111 - r1: 0.4429 - r5: 0.7075 - r10: 0.8054 - p5: 0.1415 - p10: 0.0805 - val_loss: 2.7202 - val_r1: 0.3947 - val_r5: 0.6305 - val_r10: 0.7385 - val_p5: 0.1261 - val_p10: 0.0739 - lr: 9.4753e-05 - 1s/epoch - 17ms/step
Epoch 54/1000
63/63 - 1s - loss: 2.3012 - r1: 0.4464 - r5: 0.7093 - r10: 0.8065 - p5: 0.1419 - p10: 0.0807 - val_loss: 2.7263 - val_r1: 0.3970 - val_r5: 0.6274 - val_r10: 0.7347 - val_p5: 0.1255 - val_p10: 0.0735 - lr: 9.4654e-05 - 915ms/epoch - 15ms/step
Epoch 55/1000
63/63 - 1s - loss: 2.2881 - r1: 0.4480 - r5: 0.7133 - r10: 0.8081 - p5: 0.1427 - p10: 0.0808 - val_loss: 2.7230 - val_r1: 0.3975 - val_r5: 0.6305 - val_r10: 0.7360 - val_p5: 0.1261 - val_p10: 0.0736 - lr: 9.4555e-05 - 910ms/epoch - 14ms/step
Epoch 56/1000
63/63 - 1s - loss: 2.2888 - r1: 0.4436 - r5: 0.7140 - r10: 0.8099 - p5: 0.1428 - p10: 0.0810 - val_loss: 2.7286 - val_r1: 0.3942 - val_r5: 0.6297 - val_r10: 0.7329 - val_p5: 0.1259 - val_p10: 0.0733 - lr: 9.4456e-05 - 915ms/epoch - 15ms/step
Epoch 57/1000
63/63 - 1s - loss: 2.2724 - r1: 0.4526 - r5: 0.7171 - r10: 0.8090 - p5: 0.1434 - p10: 0.0809 - val_loss: 2.7215 - val_r1: 0.3926 - val_r5: 0.6323 - val_r10: 0.7360 - val_p5: 0.1264 - val_p10: 0.0736 - lr: 9.4357e-05 - 912ms/epoch - 14ms/step
Epoch 58/1000
63/63 - 1s - loss: 2.2676 - r1: 0.4513 - r5: 0.7143 - r10: 0.8112 - p5: 0.1429 - p10: 0.0811 - val_loss: 2.7177 - val_r1: 0.3949 - val_r5: 0.6297 - val_r10: 0.7385 - val_p5: 0.1259 - val_p10: 0.0739 - lr: 9.4258e-05 - 1s/epoch - 17ms/step
Epoch 59/1000
63/63 - 1s - loss: 2.2496 - r1: 0.4575 - r5: 0.7208 - r10: 0.8143 - p5: 0.1442 - p10: 0.0814 - val_loss: 2.7198 - val_r1: 0.3972 - val_r5: 0.6305 - val_r10: 0.7388 - val_p5: 0.1261 - val_p10: 0.0739 - lr: 9.4159e-05 - 919ms/epoch - 15ms/step
Epoch 60/1000
63/63 - 1s - loss: 2.2547 - r1: 0.4523 - r5: 0.7229 - r10: 0.8140 - p5: 0.1446 - p10: 0.0814 - val_loss: 2.7209 - val_r1: 0.3931 - val_r5: 0.6320 - val_r10: 0.7395 - val_p5: 0.1264 - val_p10: 0.0740 - lr: 9.4060e-05 - 922ms/epoch - 15ms/step
Epoch 61/1000
63/63 - 1s - loss: 2.2367 - r1: 0.4574 - r5: 0.7214 - r10: 0.8180 - p5: 0.1443 - p10: 0.0818 - val_loss: 2.7240 - val_r1: 0.3939 - val_r5: 0.6325 - val_r10: 0.7377 - val_p5: 0.1265 - val_p10: 0.0738 - lr: 9.3961e-05 - 926ms/epoch - 15ms/step
Epoch 62/1000
63/63 - 1s - loss: 2.2305 - r1: 0.4622 - r5: 0.7234 - r10: 0.8136 - p5: 0.1447 - p10: 0.0814 - val_loss: 2.7229 - val_r1: 0.3954 - val_r5: 0.6318 - val_r10: 0.7388 - val_p5: 0.1264 - val_p10: 0.0739 - lr: 9.3862e-05 - 925ms/epoch - 15ms/step
Epoch 63/1000
63/63 - 1s - loss: 2.2332 - r1: 0.4550 - r5: 0.7240 - r10: 0.8173 - p5: 0.1448 - p10: 0.0817 - val_loss: 2.7178 - val_r1: 0.3972 - val_r5: 0.6320 - val_r10: 0.7362 - val_p5: 0.1264 - val_p10: 0.0736 - lr: 9.3763e-05 - 923ms/epoch - 15ms/step
Epoch 64/1000
63/63 - 1s - loss: 2.2266 - r1: 0.4608 - r5: 0.7239 - r10: 0.8166 - p5: 0.1448 - p10: 0.0817 - val_loss: 2.7183 - val_r1: 0.3972 - val_r5: 0.6290 - val_r10: 0.7380 - val_p5: 0.1257 - val_p10: 0.0738 - lr: 9.3664e-05 - 917ms/epoch - 15ms/step
Epoch 65/1000
63/63 - 1s - loss: 2.2110 - r1: 0.4652 - r5: 0.7280 - r10: 0.8208 - p5: 0.1456 - p10: 0.0821 - val_loss: 2.7287 - val_r1: 0.3952 - val_r5: 0.6282 - val_r10: 0.7362 - val_p5: 0.1256 - val_p10: 0.0736 - lr: 9.3565e-05 - 921ms/epoch - 15ms/step
Epoch 66/1000
63/63 - 1s - loss: 2.1924 - r1: 0.4676 - r5: 0.7307 - r10: 0.8234 - p5: 0.1461 - p10: 0.0823 - val_loss: 2.7291 - val_r1: 0.3936 - val_r5: 0.6307 - val_r10: 0.7403 - val_p5: 0.1261 - val_p10: 0.0740 - lr: 9.3466e-05 - 916ms/epoch - 15ms/step
Epoch 67/1000
63/63 - 1s - loss: 2.1932 - r1: 0.4688 - r5: 0.7284 - r10: 0.8233 - p5: 0.1457 - p10: 0.0823 - val_loss: 2.7322 - val_r1: 0.3936 - val_r5: 0.6328 - val_r10: 0.7382 - val_p5: 0.1266 - val_p10: 0.0738 - lr: 9.3367e-05 - 926ms/epoch - 15ms/step
Epoch 68/1000
63/63 - 1s - loss: 2.1822 - r1: 0.4649 - r5: 0.7316 - r10: 0.8247 - p5: 0.1463 - p10: 0.0825 - val_loss: 2.7293 - val_r1: 0.3972 - val_r5: 0.6315 - val_r10: 0.7377 - val_p5: 0.1263 - val_p10: 0.0738 - lr: 9.3268e-05 - 920ms/epoch - 15ms/step
Epoch 69/1000
63/63 - 1s - loss: 2.1851 - r1: 0.4690 - r5: 0.7321 - r10: 0.8233 - p5: 0.1464 - p10: 0.0823 - val_loss: 2.7274 - val_r1: 0.3970 - val_r5: 0.6259 - val_r10: 0.7349 - val_p5: 0.1252 - val_p10: 0.0735 - lr: 9.3169e-05 - 917ms/epoch - 15ms/step
Epoch 70/1000
63/63 - 1s - loss: 2.1634 - r1: 0.4703 - r5: 0.7380 - r10: 0.8283 - p5: 0.1476 - p10: 0.0828 - val_loss: 2.7279 - val_r1: 0.3934 - val_r5: 0.6282 - val_r10: 0.7347 - val_p5: 0.1256 - val_p10: 0.0734 - lr: 9.3070e-05 - 915ms/epoch - 15ms/step
Epoch 71/1000
63/63 - 1s - loss: 2.1678 - r1: 0.4721 - r5: 0.7354 - r10: 0.8280 - p5: 0.1471 - p10: 0.0828 - val_loss: 2.7231 - val_r1: 0.3919 - val_r5: 0.6318 - val_r10: 0.7365 - val_p5: 0.1264 - val_p10: 0.0736 - lr: 9.2971e-05 - 917ms/epoch - 15ms/step
Epoch 72/1000
63/63 - 1s - loss: 2.1555 - r1: 0.4714 - r5: 0.7383 - r10: 0.8298 - p5: 0.1477 - p10: 0.0830 - val_loss: 2.7253 - val_r1: 0.3939 - val_r5: 0.6320 - val_r10: 0.7398 - val_p5: 0.1265 - val_p10: 0.0740 - lr: 9.2872e-05 - 919ms/epoch - 15ms/step
Epoch 73/1000
63/63 - 1s - loss: 2.1457 - r1: 0.4742 - r5: 0.7378 - r10: 0.8304 - p5: 0.1476 - p10: 0.0830 - val_loss: 2.7299 - val_r1: 0.3942 - val_r5: 0.6295 - val_r10: 0.7365 - val_p5: 0.1259 - val_p10: 0.0736 - lr: 9.2773e-05 - 921ms/epoch - 15ms/step
Epoch 74/1000
63/63 - 1s - loss: 2.1438 - r1: 0.4745 - r5: 0.7401 - r10: 0.8311 - p5: 0.1480 - p10: 0.0831 - val_loss: 2.7348 - val_r1: 0.3926 - val_r5: 0.6272 - val_r10: 0.7355 - val_p5: 0.1255 - val_p10: 0.0735 - lr: 9.2674e-05 - 913ms/epoch - 14ms/step
Epoch 75/1000
63/63 - 1s - loss: 2.1422 - r1: 0.4760 - r5: 0.7438 - r10: 0.8316 - p5: 0.1487 - p10: 0.0832 - val_loss: 2.7286 - val_r1: 0.3949 - val_r5: 0.6274 - val_r10: 0.7367 - val_p5: 0.1255 - val_p10: 0.0737 - lr: 9.2575e-05 - 912ms/epoch - 14ms/step
Epoch 76/1000
63/63 - 1s - loss: 2.1291 - r1: 0.4786 - r5: 0.7427 - r10: 0.8325 - p5: 0.1486 - p10: 0.0833 - val_loss: 2.7265 - val_r1: 0.3959 - val_r5: 0.6280 - val_r10: 0.7349 - val_p5: 0.1256 - val_p10: 0.0735 - lr: 9.2476e-05 - 915ms/epoch - 15ms/step
Epoch 77/1000
63/63 - 1s - loss: 2.1366 - r1: 0.4747 - r5: 0.7425 - r10: 0.8340 - p5: 0.1485 - p10: 0.0834 - val_loss: 2.7345 - val_r1: 0.3967 - val_r5: 0.6280 - val_r10: 0.7347 - val_p5: 0.1256 - val_p10: 0.0735 - lr: 9.2377e-05 - 915ms/epoch - 15ms/step
Epoch 78/1000
63/63 - 1s - loss: 2.1225 - r1: 0.4794 - r5: 0.7425 - r10: 0.8330 - p5: 0.1485 - p10: 0.0833 - val_loss: 2.7365 - val_r1: 0.3995 - val_r5: 0.6257 - val_r10: 0.7349 - val_p5: 0.1251 - val_p10: 0.0735 - lr: 9.2278e-05 - 914ms/epoch - 15ms/step
Epoch 79/1000
63/63 - 1s - loss: 2.1117 - r1: 0.4836 - r5: 0.7485 - r10: 0.8364 - p5: 0.1497 - p10: 0.0836 - val_loss: 2.7366 - val_r1: 0.3959 - val_r5: 0.6267 - val_r10: 0.7337 - val_p5: 0.1253 - val_p10: 0.0734 - lr: 9.2179e-05 - 913ms/epoch - 14ms/step
Epoch 80/1000
63/63 - 1s - loss: 2.1163 - r1: 0.4791 - r5: 0.7468 - r10: 0.8344 - p5: 0.1494 - p10: 0.0834 - val_loss: 2.7402 - val_r1: 0.3939 - val_r5: 0.6264 - val_r10: 0.7314 - val_p5: 0.1253 - val_p10: 0.0731 - lr: 9.2080e-05 - 919ms/epoch - 15ms/step
Epoch 81/1000
63/63 - 1s - loss: 2.1065 - r1: 0.4825 - r5: 0.7489 - r10: 0.8370 - p5: 0.1498 - p10: 0.0837 - val_loss: 2.7421 - val_r1: 0.3952 - val_r5: 0.6231 - val_r10: 0.7349 - val_p5: 0.1245 - val_p10: 0.0735 - lr: 9.1981e-05 - 916ms/epoch - 15ms/step
Epoch 82/1000
63/63 - 1s - loss: 2.1017 - r1: 0.4841 - r5: 0.7488 - r10: 0.8358 - p5: 0.1497 - p10: 0.0836 - val_loss: 2.7373 - val_r1: 0.3949 - val_r5: 0.6267 - val_r10: 0.7332 - val_p5: 0.1253 - val_p10: 0.0733 - lr: 9.1882e-05 - 906ms/epoch - 14ms/step
Epoch 83/1000
63/63 - 1s - loss: 2.0817 - r1: 0.4874 - r5: 0.7527 - r10: 0.8401 - p5: 0.1506 - p10: 0.0840 - val_loss: 2.7401 - val_r1: 0.3959 - val_r5: 0.6272 - val_r10: 0.7339 - val_p5: 0.1254 - val_p10: 0.0734 - lr: 9.1783e-05 - 922ms/epoch - 15ms/step
Epoch 84/1000
63/63 - 1s - loss: 2.0838 - r1: 0.4901 - r5: 0.7496 - r10: 0.8386 - p5: 0.1499 - p10: 0.0839 - val_loss: 2.7424 - val_r1: 0.3926 - val_r5: 0.6262 - val_r10: 0.7306 - val_p5: 0.1252 - val_p10: 0.0731 - lr: 9.1684e-05 - 921ms/epoch - 15ms/step
Epoch 85/1000
63/63 - 1s - loss: 2.0764 - r1: 0.4893 - r5: 0.7534 - r10: 0.8408 - p5: 0.1507 - p10: 0.0841 - val_loss: 2.7457 - val_r1: 0.3959 - val_r5: 0.6244 - val_r10: 0.7291 - val_p5: 0.1249 - val_p10: 0.0729 - lr: 9.1585e-05 - 925ms/epoch - 15ms/step
Epoch 86/1000
63/63 - 1s - loss: 2.0706 - r1: 0.4900 - r5: 0.7534 - r10: 0.8413 - p5: 0.1507 - p10: 0.0841 - val_loss: 2.7465 - val_r1: 0.3949 - val_r5: 0.6231 - val_r10: 0.7283 - val_p5: 0.1246 - val_p10: 0.0728 - lr: 9.1486e-05 - 922ms/epoch - 15ms/step
Epoch 87/1000
63/63 - 1s - loss: 2.0600 - r1: 0.4927 - r5: 0.7574 - r10: 0.8428 - p5: 0.1515 - p10: 0.0843 - val_loss: 2.7446 - val_r1: 0.3911 - val_r5: 0.6269 - val_r10: 0.7304 - val_p5: 0.1254 - val_p10: 0.0730 - lr: 9.1387e-05 - 915ms/epoch - 15ms/step
Epoch 88/1000
63/63 - 1s - loss: 2.0522 - r1: 0.4950 - r5: 0.7553 - r10: 0.8427 - p5: 0.1511 - p10: 0.0843 - val_loss: 2.7505 - val_r1: 0.3939 - val_r5: 0.6252 - val_r10: 0.7278 - val_p5: 0.1250 - val_p10: 0.0728 - lr: 9.1288e-05 - 917ms/epoch - 15ms/step
Epoch 89/1000
63/63 - 1s - loss: 2.0544 - r1: 0.4929 - r5: 0.7569 - r10: 0.8460 - p5: 0.1514 - p10: 0.0846 - val_loss: 2.7513 - val_r1: 0.3947 - val_r5: 0.6234 - val_r10: 0.7309 - val_p5: 0.1247 - val_p10: 0.0731 - lr: 9.1189e-05 - 921ms/epoch - 15ms/step
Epoch 90/1000
63/63 - 1s - loss: 2.0586 - r1: 0.4916 - r5: 0.7564 - r10: 0.8438 - p5: 0.1513 - p10: 0.0844 - val_loss: 2.7454 - val_r1: 0.3957 - val_r5: 0.6241 - val_r10: 0.7299 - val_p5: 0.1248 - val_p10: 0.0730 - lr: 9.1090e-05 - 911ms/epoch - 14ms/step
Epoch 91/1000
63/63 - 1s - loss: 2.0541 - r1: 0.4926 - r5: 0.7558 - r10: 0.8445 - p5: 0.1511 - p10: 0.0845 - val_loss: 2.7460 - val_r1: 0.3954 - val_r5: 0.6274 - val_r10: 0.7321 - val_p5: 0.1255 - val_p10: 0.0732 - lr: 9.0991e-05 - 916ms/epoch - 15ms/step
Epoch 92/1000
63/63 - 1s - loss: 2.0395 - r1: 0.4948 - r5: 0.7605 - r10: 0.8471 - p5: 0.1521 - p10: 0.0847 - val_loss: 2.7522 - val_r1: 0.3949 - val_r5: 0.6252 - val_r10: 0.7288 - val_p5: 0.1250 - val_p10: 0.0729 - lr: 9.0892e-05 - 922ms/epoch - 15ms/step
Epoch 93/1000
63/63 - 1s - loss: 2.0395 - r1: 0.4959 - r5: 0.7607 - r10: 0.8485 - p5: 0.1522 - p10: 0.0849 - val_loss: 2.7504 - val_r1: 0.3934 - val_r5: 0.6236 - val_r10: 0.7311 - val_p5: 0.1247 - val_p10: 0.0731 - lr: 9.0793e-05 - 913ms/epoch - 14ms/step
Epoch 94/1000
63/63 - 1s - loss: 2.0288 - r1: 0.4987 - r5: 0.7629 - r10: 0.8496 - p5: 0.1526 - p10: 0.0850 - val_loss: 2.7501 - val_r1: 0.3957 - val_r5: 0.6239 - val_r10: 0.7339 - val_p5: 0.1248 - val_p10: 0.0734 - lr: 9.0694e-05 - 919ms/epoch - 15ms/step
Epoch 95/1000
63/63 - 1s - loss: 2.0207 - r1: 0.5005 - r5: 0.7624 - r10: 0.8486 - p5: 0.1525 - p10: 0.0849 - val_loss: 2.7613 - val_r1: 0.3942 - val_r5: 0.6213 - val_r10: 0.7314 - val_p5: 0.1243 - val_p10: 0.0731 - lr: 9.0595e-05 - 916ms/epoch - 15ms/step
Epoch 96/1000
63/63 - 1s - loss: 2.0197 - r1: 0.4992 - r5: 0.7642 - r10: 0.8498 - p5: 0.1528 - p10: 0.0850 - val_loss: 2.7580 - val_r1: 0.3929 - val_r5: 0.6219 - val_r10: 0.7278 - val_p5: 0.1244 - val_p10: 0.0728 - lr: 9.0496e-05 - 914ms/epoch - 15ms/step
Epoch 97/1000
63/63 - 1s - loss: 2.0205 - r1: 0.5017 - r5: 0.7643 - r10: 0.8484 - p5: 0.1529 - p10: 0.0848 - val_loss: 2.7576 - val_r1: 0.3931 - val_r5: 0.6236 - val_r10: 0.7273 - val_p5: 0.1247 - val_p10: 0.0727 - lr: 9.0397e-05 - 921ms/epoch - 15ms/step
Epoch 98/1000
63/63 - 1s - loss: 2.0145 - r1: 0.5005 - r5: 0.7634 - r10: 0.8513 - p5: 0.1527 - p10: 0.0851 - val_loss: 2.7617 - val_r1: 0.3977 - val_r5: 0.6229 - val_r10: 0.7248 - val_p5: 0.1246 - val_p10: 0.0725 - lr: 9.0298e-05 - 919ms/epoch - 15ms/step
Epoch 99/1000
63/63 - 1s - loss: 2.0077 - r1: 0.5015 - r5: 0.7695 - r10: 0.8514 - p5: 0.1539 - p10: 0.0851 - val_loss: 2.7641 - val_r1: 0.3901 - val_r5: 0.6254 - val_r10: 0.7266 - val_p5: 0.1251 - val_p10: 0.0727 - lr: 9.0199e-05 - 917ms/epoch - 15ms/step
Epoch 100/1000
63/63 - 1s - loss: 2.0068 - r1: 0.5031 - r5: 0.7665 - r10: 0.8525 - p5: 0.1533 - p10: 0.0852 - val_loss: 2.7678 - val_r1: 0.3939 - val_r5: 0.6277 - val_r10: 0.7258 - val_p5: 0.1255 - val_p10: 0.0726 - lr: 9.0100e-05 - 913ms/epoch - 14ms/step
Epoch 101/1000
63/63 - 1s - loss: 1.9961 - r1: 0.5045 - r5: 0.7700 - r10: 0.8526 - p5: 0.1540 - p10: 0.0853 - val_loss: 2.7560 - val_r1: 0.3954 - val_r5: 0.6249 - val_r10: 0.7294 - val_p5: 0.1250 - val_p10: 0.0729 - lr: 9.0001e-05 - 915ms/epoch - 15ms/step
Epoch 102/1000
63/63 - 1s - loss: 1.9935 - r1: 0.5041 - r5: 0.7679 - r10: 0.8542 - p5: 0.1536 - p10: 0.0854 - val_loss: 2.7710 - val_r1: 0.3914 - val_r5: 0.6224 - val_r10: 0.7240 - val_p5: 0.1245 - val_p10: 0.0724 - lr: 8.9902e-05 - 916ms/epoch - 15ms/step
Epoch 103/1000
63/63 - 1s - loss: 1.9832 - r1: 0.5054 - r5: 0.7715 - r10: 0.8555 - p5: 0.1543 - p10: 0.0855 - val_loss: 2.7706 - val_r1: 0.3939 - val_r5: 0.6191 - val_r10: 0.7255 - val_p5: 0.1238 - val_p10: 0.0726 - lr: 8.9803e-05 - 914ms/epoch - 15ms/step
Epoch 104/1000
63/63 - 1s - loss: 1.9854 - r1: 0.5042 - r5: 0.7721 - r10: 0.8555 - p5: 0.1544 - p10: 0.0856 - val_loss: 2.7681 - val_r1: 0.3931 - val_r5: 0.6150 - val_r10: 0.7243 - val_p5: 0.1229 - val_p10: 0.0724 - lr: 8.9704e-05 - 914ms/epoch - 15ms/step
Epoch 105/1000
63/63 - 1s - loss: 1.9744 - r1: 0.5101 - r5: 0.7729 - r10: 0.8564 - p5: 0.1546 - p10: 0.0856 - val_loss: 2.7671 - val_r1: 0.3929 - val_r5: 0.6219 - val_r10: 0.7243 - val_p5: 0.1243 - val_p10: 0.0724 - lr: 8.9605e-05 - 916ms/epoch - 15ms/step
Epoch 106/1000
63/63 - 1s - loss: 1.9747 - r1: 0.5099 - r5: 0.7727 - r10: 0.8560 - p5: 0.1546 - p10: 0.0856 - val_loss: 2.7679 - val_r1: 0.3929 - val_r5: 0.6226 - val_r10: 0.7273 - val_p5: 0.1246 - val_p10: 0.0727 - lr: 8.9506e-05 - 924ms/epoch - 15ms/step
Epoch 107/1000
63/63 - 1s - loss: 1.9611 - r1: 0.5101 - r5: 0.7731 - r10: 0.8566 - p5: 0.1546 - p10: 0.0857 - val_loss: 2.7724 - val_r1: 0.3886 - val_r5: 0.6211 - val_r10: 0.7235 - val_p5: 0.1242 - val_p10: 0.0724 - lr: 8.9407e-05 - 921ms/epoch - 15ms/step
Epoch 108/1000
63/63 - 1s - loss: 1.9560 - r1: 0.5135 - r5: 0.7778 - r10: 0.8583 - p5: 0.1556 - p10: 0.0858 - val_loss: 2.7778 - val_r1: 0.3903 - val_r5: 0.6231 - val_r10: 0.7235 - val_p5: 0.1246 - val_p10: 0.0724 - lr: 8.9308e-05 - 913ms/epoch - 14ms/step
Epoch 108: early stopping
[92m[INFO] Loading best model...[0m
[93m[WARNING] Model folder already exists...[0m
Model: "ATT2ITM_0"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 162)]        0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 149)]        0           []                               
                                                                                                  
 embedding (Embedding)          (None, 162, 384)     926976      ['input_1[0][0]']                
                                                                                                  
 in_rsts (Embedding)            (None, 149, 384)     57216       ['input_2[0][0]']                
                                                                                                  
 dense (Dense)                  (None, 162, 256)     98560       ['embedding[0][0]']              
                                                                                                  
 dense_2 (Dense)                (None, 149, 256)     98560       ['in_rsts[0][0]']                
                                                                                                  
 tf.math.not_equal (TFOpLambda)  (None, 162)         0           ['input_1[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 162, 128)     32896       ['dense[0][0]']                  
                                                                                                  
 dense_3 (Dense)                (None, 149, 128)     32896       ['dense_2[0][0]']                
                                                                                                  
 tf.cast (TFOpLambda)           (None, 162)          0           ['tf.math.not_equal[0][0]']      
                                                                                                  
 word_emb (Lambda)              (None, 162, 128)     0           ['dense_1[0][0]']                
                                                                                                  
 rest_emb (Lambda)              (None, 149, 128)     0           ['dense_3[0][0]']                
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 162, 1)       0           ['tf.cast[0][0]']                
                                                                                                  
 lambda (Lambda)                (None, 162, 149)     0           ['word_emb[0][0]',               
                                                                  'rest_emb[0][0]']               
                                                                                                  
 tf.tile (TFOpLambda)           (None, 162, 149)     0           ['tf.expand_dims[0][0]']         
                                                                                                  
 lambda_1 (Lambda)              (None, 162, 149)     0           ['lambda[0][0]',                 
                                                                  'tf.tile[0][0]']                
                                                                                                  
 dotprod (Activation)           (None, 162, 149)     0           ['lambda_1[0][0]']               
                                                                                                  
 dropout (Dropout)              (None, 162, 149)     0           ['dotprod[0][0]']                
                                                                                                  
 sum (Lambda)                   (None, 149)          0           ['dropout[0][0]']                
                                                                                                  
 out (Activation)               (None, 149)          0           ['sum[0][0]']                    
                                                                                                  
==================================================================================================
Total params: 1,247,104
Trainable params: 1,247,104
Non-trainable params: 0
__________________________________________________________________________________________________
None
[92m[INFO] Model already trained. Loading weights...[0m
[93m[WARNING] Model folder already exists...[0m
Model: "ATT2ITM_0"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 162)]        0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 149)]        0           []                               
                                                                                                  
 embedding (Embedding)          (None, 162, 384)     926976      ['input_1[0][0]']                
                                                                                                  
 in_rsts (Embedding)            (None, 149, 384)     57216       ['input_2[0][0]']                
                                                                                                  
 dense (Dense)                  (None, 162, 256)     98560       ['embedding[0][0]']              
                                                                                                  
 dense_2 (Dense)                (None, 149, 256)     98560       ['in_rsts[0][0]']                
                                                                                                  
 tf.math.not_equal (TFOpLambda)  (None, 162)         0           ['input_1[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 162, 128)     32896       ['dense[0][0]']                  
                                                                                                  
 dense_3 (Dense)                (None, 149, 128)     32896       ['dense_2[0][0]']                
                                                                                                  
 tf.cast (TFOpLambda)           (None, 162)          0           ['tf.math.not_equal[0][0]']      
                                                                                                  
 word_emb (Lambda)              (None, 162, 128)     0           ['dense_1[0][0]']                
                                                                                                  
 rest_emb (Lambda)              (None, 149, 128)     0           ['dense_3[0][0]']                
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 162, 1)       0           ['tf.cast[0][0]']                
                                                                                                  
 lambda (Lambda)                (None, 162, 149)     0           ['word_emb[0][0]',               
                                                                  'rest_emb[0][0]']               
                                                                                                  
 tf.tile (TFOpLambda)           (None, 162, 149)     0           ['tf.expand_dims[0][0]']         
                                                                                                  
 lambda_1 (Lambda)              (None, 162, 149)     0           ['lambda[0][0]',                 
                                                                  'tf.tile[0][0]']                
                                                                                                  
 dotprod (Activation)           (None, 162, 149)     0           ['lambda_1[0][0]']               
                                                                                                  
 dropout (Dropout)              (None, 162, 149)     0           ['dotprod[0][0]']                
                                                                                                  
 sum (Lambda)                   (None, 149)          0           ['dropout[0][0]']                
                                                                                                  
 out (Activation)               (None, 149)          0           ['sum[0][0]']                    
                                                                                                  
==================================================================================================
Total params: 1,247,104
Trainable params: 1,247,104
Non-trainable params: 0
__________________________________________________________________________________________________
None
[92m[INFO] Model already trained. Loading weights...[0m
[93m[WARNING] Model folder already exists...[0m
Model: "ATT2ITM_0"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 162)]        0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 149)]        0           []                               
                                                                                                  
 embedding (Embedding)          (None, 162, 384)     926976      ['input_1[0][0]']                
                                                                                                  
 in_rsts (Embedding)            (None, 149, 384)     57216       ['input_2[0][0]']                
                                                                                                  
 dense (Dense)                  (None, 162, 256)     98560       ['embedding[0][0]']              
                                                                                                  
 dense_2 (Dense)                (None, 149, 256)     98560       ['in_rsts[0][0]']                
                                                                                                  
 tf.math.not_equal (TFOpLambda)  (None, 162)         0           ['input_1[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 162, 128)     32896       ['dense[0][0]']                  
                                                                                                  
 dense_3 (Dense)                (None, 149, 128)     32896       ['dense_2[0][0]']                
                                                                                                  
 tf.cast (TFOpLambda)           (None, 162)          0           ['tf.math.not_equal[0][0]']      
                                                                                                  
 word_emb (Lambda)              (None, 162, 128)     0           ['dense_1[0][0]']                
                                                                                                  
 rest_emb (Lambda)              (None, 149, 128)     0           ['dense_3[0][0]']                
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 162, 1)       0           ['tf.cast[0][0]']                
                                                                                                  
 lambda (Lambda)                (None, 162, 149)     0           ['word_emb[0][0]',               
                                                                  'rest_emb[0][0]']               
                                                                                                  
 tf.tile (TFOpLambda)           (None, 162, 149)     0           ['tf.expand_dims[0][0]']         
                                                                                                  
 lambda_1 (Lambda)              (None, 162, 149)     0           ['lambda[0][0]',                 
                                                                  'tf.tile[0][0]']                
                                                                                                  
 dotprod (Activation)           (None, 162, 149)     0           ['lambda_1[0][0]']               
                                                                                                  
 dropout (Dropout)              (None, 162, 149)     0           ['dotprod[0][0]']                
                                                                                                  
 sum (Lambda)                   (None, 149)          0           ['dropout[0][0]']                
                                                                                                  
 out (Activation)               (None, 149)          0           ['sum[0][0]']                    
                                                                                                  
==================================================================================================
Total params: 1,247,104
Trainable params: 1,247,104
Non-trainable params: 0
__________________________________________________________________________________________________
None
[92m[INFO] Model already trained. Loading weights...[0m
