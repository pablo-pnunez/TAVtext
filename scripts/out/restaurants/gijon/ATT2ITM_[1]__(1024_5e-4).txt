Model: "ATT2ITM_1"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 162)]        0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 149)]        0           []                               
                                                                                                  
 embedding (Embedding)          (None, 162, 384)     926976      ['input_1[0][0]']                
                                                                                                  
 in_rsts (Embedding)            (None, 149, 384)     57216       ['input_2[0][0]']                
                                                                                                  
 dense (Dense)                  (None, 162, 256)     98560       ['embedding[0][0]']              
                                                                                                  
 dense_2 (Dense)                (None, 149, 256)     98560       ['in_rsts[0][0]']                
                                                                                                  
 tf.math.not_equal (TFOpLambda)  (None, 162)         0           ['input_1[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 162, 128)     32896       ['dense[0][0]']                  
                                                                                                  
 dense_3 (Dense)                (None, 149, 128)     32896       ['dense_2[0][0]']                
                                                                                                  
 tf.cast (TFOpLambda)           (None, 162)          0           ['tf.math.not_equal[0][0]']      
                                                                                                  
 word_emb (Lambda)              (None, 162, 128)     0           ['dense_1[0][0]']                
                                                                                                  
 rest_emb (Lambda)              (None, 149, 128)     0           ['dense_3[0][0]']                
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 162, 1)       0           ['tf.cast[0][0]']                
                                                                                                  
 lambda (Lambda)                (None, 162, 149)     0           ['word_emb[0][0]',               
                                                                  'rest_emb[0][0]']               
                                                                                                  
 tf.tile (TFOpLambda)           (None, 162, 149)     0           ['tf.expand_dims[0][0]']         
                                                                                                  
 lambda_1 (Lambda)              (None, 162, 149)     0           ['lambda[0][0]',                 
                                                                  'tf.tile[0][0]']                
                                                                                                  
 dotprod (Activation)           (None, 162, 149)     0           ['lambda_1[0][0]']               
                                                                                                  
 dropout (Dropout)              (None, 162, 149)     0           ['dotprod[0][0]']                
                                                                                                  
 sum (Lambda)                   (None, 149)          0           ['dropout[0][0]']                
                                                                                                  
 out (Activation)               (None, 149)          0           ['sum[0][0]']                    
                                                                                                  
==================================================================================================
Total params: 1,247,104
Trainable params: 1,247,104
Non-trainable params: 0
__________________________________________________________________________________________________
None
Epoch 1/1000
32/32 - 5s - loss: 0.0412 - r1: 0.0301 - r5: 0.0939 - r10: 0.1514 - p5: 0.0188 - p10: 0.0151 - val_loss: 0.0209 - val_r1: 0.0689 - val_r5: 0.1436 - val_r10: 0.2483 - val_p5: 0.0288 - val_p10: 0.0248 - lr: 4.9951e-04 - 5s/epoch - 143ms/step
Epoch 2/1000
32/32 - 1s - loss: 0.0200 - r1: 0.0569 - r5: 0.1547 - r10: 0.2267 - p5: 0.0310 - p10: 0.0227 - val_loss: 0.0178 - val_r1: 0.0811 - val_r5: 0.2280 - val_r10: 0.3004 - val_p5: 0.0455 - val_p10: 0.0300 - lr: 4.9901e-04 - 954ms/epoch - 30ms/step
Epoch 3/1000
32/32 - 1s - loss: 0.0183 - r1: 0.0720 - r5: 0.1868 - r10: 0.2648 - p5: 0.0374 - p10: 0.0265 - val_loss: 0.0169 - val_r1: 0.0897 - val_r5: 0.2635 - val_r10: 0.3319 - val_p5: 0.0527 - val_p10: 0.0332 - lr: 4.9852e-04 - 959ms/epoch - 30ms/step
Epoch 4/1000
32/32 - 1s - loss: 0.0174 - r1: 0.1003 - r5: 0.2226 - r10: 0.3010 - p5: 0.0445 - p10: 0.0301 - val_loss: 0.0161 - val_r1: 0.1395 - val_r5: 0.3052 - val_r10: 0.3822 - val_p5: 0.0611 - val_p10: 0.0383 - lr: 4.9802e-04 - 978ms/epoch - 31ms/step
Epoch 5/1000
32/32 - 1s - loss: 0.0165 - r1: 0.1375 - r5: 0.2742 - r10: 0.3552 - p5: 0.0548 - p10: 0.0355 - val_loss: 0.0152 - val_r1: 0.1924 - val_r5: 0.3698 - val_r10: 0.4656 - val_p5: 0.0740 - val_p10: 0.0465 - lr: 4.9753e-04 - 959ms/epoch - 30ms/step
Epoch 6/1000
32/32 - 1s - loss: 0.0156 - r1: 0.1690 - r5: 0.3278 - r10: 0.4194 - p5: 0.0656 - p10: 0.0419 - val_loss: 0.0142 - val_r1: 0.2254 - val_r5: 0.4376 - val_r10: 0.5403 - val_p5: 0.0875 - val_p10: 0.0541 - lr: 4.9703e-04 - 959ms/epoch - 30ms/step
Epoch 7/1000
32/32 - 1s - loss: 0.0147 - r1: 0.1987 - r5: 0.3746 - r10: 0.4763 - p5: 0.0749 - p10: 0.0476 - val_loss: 0.0135 - val_r1: 0.2562 - val_r5: 0.4801 - val_r10: 0.5888 - val_p5: 0.0960 - val_p10: 0.0589 - lr: 4.9654e-04 - 965ms/epoch - 30ms/step
Epoch 8/1000
32/32 - 1s - loss: 0.0140 - r1: 0.2256 - r5: 0.4147 - r10: 0.5172 - p5: 0.0829 - p10: 0.0517 - val_loss: 0.0129 - val_r1: 0.2945 - val_r5: 0.5179 - val_r10: 0.6241 - val_p5: 0.1036 - val_p10: 0.0624 - lr: 4.9604e-04 - 963ms/epoch - 30ms/step
Epoch 9/1000
32/32 - 1s - loss: 0.0134 - r1: 0.2483 - r5: 0.4528 - r10: 0.5581 - p5: 0.0905 - p10: 0.0558 - val_loss: 0.0125 - val_r1: 0.3093 - val_r5: 0.5362 - val_r10: 0.6490 - val_p5: 0.1072 - val_p10: 0.0649 - lr: 4.9555e-04 - 958ms/epoch - 30ms/step
Epoch 10/1000
32/32 - 1s - loss: 0.0130 - r1: 0.2668 - r5: 0.4776 - r10: 0.5855 - p5: 0.0955 - p10: 0.0585 - val_loss: 0.0122 - val_r1: 0.3182 - val_r5: 0.5543 - val_r10: 0.6696 - val_p5: 0.1109 - val_p10: 0.0669 - lr: 4.9505e-04 - 960ms/epoch - 30ms/step
Epoch 11/1000
32/32 - 1s - loss: 0.0126 - r1: 0.2817 - r5: 0.5028 - r10: 0.6093 - p5: 0.1006 - p10: 0.0609 - val_loss: 0.0119 - val_r1: 0.3375 - val_r5: 0.5728 - val_r10: 0.6834 - val_p5: 0.1145 - val_p10: 0.0683 - lr: 4.9456e-04 - 956ms/epoch - 30ms/step
Epoch 12/1000
32/32 - 1s - loss: 0.0123 - r1: 0.2968 - r5: 0.5195 - r10: 0.6305 - p5: 0.1039 - p10: 0.0631 - val_loss: 0.0117 - val_r1: 0.3431 - val_r5: 0.5870 - val_r10: 0.6981 - val_p5: 0.1174 - val_p10: 0.0698 - lr: 4.9406e-04 - 957ms/epoch - 30ms/step
Epoch 13/1000
32/32 - 1s - loss: 0.0121 - r1: 0.3054 - r5: 0.5322 - r10: 0.6427 - p5: 0.1064 - p10: 0.0643 - val_loss: 0.0116 - val_r1: 0.3522 - val_r5: 0.5942 - val_r10: 0.7083 - val_p5: 0.1189 - val_p10: 0.0708 - lr: 4.9357e-04 - 956ms/epoch - 30ms/step
Epoch 14/1000
32/32 - 1s - loss: 0.0118 - r1: 0.3185 - r5: 0.5517 - r10: 0.6596 - p5: 0.1103 - p10: 0.0660 - val_loss: 0.0115 - val_r1: 0.3596 - val_r5: 0.6036 - val_r10: 0.7090 - val_p5: 0.1208 - val_p10: 0.0710 - lr: 4.9307e-04 - 956ms/epoch - 30ms/step
Epoch 15/1000
32/32 - 1s - loss: 0.0115 - r1: 0.3315 - r5: 0.5656 - r10: 0.6706 - p5: 0.1131 - p10: 0.0671 - val_loss: 0.0114 - val_r1: 0.3708 - val_r5: 0.6089 - val_r10: 0.7159 - val_p5: 0.1218 - val_p10: 0.0716 - lr: 4.9258e-04 - 954ms/epoch - 30ms/step
Epoch 16/1000
32/32 - 1s - loss: 0.0113 - r1: 0.3386 - r5: 0.5732 - r10: 0.6794 - p5: 0.1146 - p10: 0.0679 - val_loss: 0.0114 - val_r1: 0.3677 - val_r5: 0.6147 - val_r10: 0.7189 - val_p5: 0.1230 - val_p10: 0.0719 - lr: 4.9208e-04 - 961ms/epoch - 30ms/step
Epoch 17/1000
32/32 - 1s - loss: 0.0112 - r1: 0.3458 - r5: 0.5822 - r10: 0.6924 - p5: 0.1164 - p10: 0.0693 - val_loss: 0.0114 - val_r1: 0.3756 - val_r5: 0.6173 - val_r10: 0.7177 - val_p5: 0.1235 - val_p10: 0.0718 - lr: 4.9159e-04 - 785ms/epoch - 25ms/step
Epoch 18/1000
32/32 - 1s - loss: 0.0110 - r1: 0.3547 - r5: 0.5920 - r10: 0.6981 - p5: 0.1184 - p10: 0.0698 - val_loss: 0.0113 - val_r1: 0.3809 - val_r5: 0.6221 - val_r10: 0.7255 - val_p5: 0.1244 - val_p10: 0.0726 - lr: 4.9109e-04 - 942ms/epoch - 29ms/step
Epoch 19/1000
32/32 - 1s - loss: 0.0108 - r1: 0.3667 - r5: 0.6046 - r10: 0.7105 - p5: 0.1209 - p10: 0.0710 - val_loss: 0.0114 - val_r1: 0.3764 - val_r5: 0.6208 - val_r10: 0.7245 - val_p5: 0.1242 - val_p10: 0.0725 - lr: 4.9060e-04 - 779ms/epoch - 24ms/step
Epoch 20/1000
32/32 - 1s - loss: 0.0107 - r1: 0.3659 - r5: 0.6096 - r10: 0.7147 - p5: 0.1219 - p10: 0.0715 - val_loss: 0.0113 - val_r1: 0.3751 - val_r5: 0.6183 - val_r10: 0.7240 - val_p5: 0.1237 - val_p10: 0.0724 - lr: 4.9010e-04 - 946ms/epoch - 30ms/step
Epoch 21/1000
32/32 - 1s - loss: 0.0106 - r1: 0.3743 - r5: 0.6161 - r10: 0.7217 - p5: 0.1232 - p10: 0.0722 - val_loss: 0.0112 - val_r1: 0.3860 - val_r5: 0.6236 - val_r10: 0.7253 - val_p5: 0.1248 - val_p10: 0.0725 - lr: 4.8961e-04 - 949ms/epoch - 30ms/step
Epoch 22/1000
32/32 - 1s - loss: 0.0104 - r1: 0.3847 - r5: 0.6265 - r10: 0.7293 - p5: 0.1253 - p10: 0.0729 - val_loss: 0.0113 - val_r1: 0.3797 - val_r5: 0.6203 - val_r10: 0.7253 - val_p5: 0.1241 - val_p10: 0.0725 - lr: 4.8911e-04 - 774ms/epoch - 24ms/step
Epoch 23/1000
32/32 - 1s - loss: 0.0104 - r1: 0.3840 - r5: 0.6274 - r10: 0.7282 - p5: 0.1255 - p10: 0.0728 - val_loss: 0.0113 - val_r1: 0.3769 - val_r5: 0.6208 - val_r10: 0.7311 - val_p5: 0.1241 - val_p10: 0.0730 - lr: 4.8862e-04 - 766ms/epoch - 24ms/step
Epoch 24/1000
32/32 - 1s - loss: 0.0102 - r1: 0.3897 - r5: 0.6338 - r10: 0.7376 - p5: 0.1268 - p10: 0.0738 - val_loss: 0.0114 - val_r1: 0.3850 - val_r5: 0.6241 - val_r10: 0.7266 - val_p5: 0.1248 - val_p10: 0.0727 - lr: 4.8812e-04 - 777ms/epoch - 24ms/step
Epoch 25/1000
32/32 - 1s - loss: 0.0101 - r1: 0.4013 - r5: 0.6432 - r10: 0.7460 - p5: 0.1286 - p10: 0.0746 - val_loss: 0.0116 - val_r1: 0.3870 - val_r5: 0.6221 - val_r10: 0.7250 - val_p5: 0.1244 - val_p10: 0.0725 - lr: 4.8763e-04 - 779ms/epoch - 24ms/step
Epoch 26/1000
32/32 - 1s - loss: 0.0100 - r1: 0.4005 - r5: 0.6481 - r10: 0.7504 - p5: 0.1296 - p10: 0.0750 - val_loss: 0.0114 - val_r1: 0.3863 - val_r5: 0.6221 - val_r10: 0.7243 - val_p5: 0.1244 - val_p10: 0.0724 - lr: 4.8713e-04 - 781ms/epoch - 24ms/step
Epoch 27/1000
32/32 - 1s - loss: 0.0099 - r1: 0.4014 - r5: 0.6521 - r10: 0.7563 - p5: 0.1304 - p10: 0.0756 - val_loss: 0.0115 - val_r1: 0.3853 - val_r5: 0.6180 - val_r10: 0.7205 - val_p5: 0.1236 - val_p10: 0.0720 - lr: 4.8664e-04 - 789ms/epoch - 25ms/step
Epoch 28/1000
32/32 - 1s - loss: 0.0098 - r1: 0.4113 - r5: 0.6575 - r10: 0.7573 - p5: 0.1315 - p10: 0.0757 - val_loss: 0.0115 - val_r1: 0.3799 - val_r5: 0.6163 - val_r10: 0.7215 - val_p5: 0.1234 - val_p10: 0.0721 - lr: 4.8614e-04 - 795ms/epoch - 25ms/step
Epoch 29/1000
32/32 - 1s - loss: 0.0097 - r1: 0.4168 - r5: 0.6622 - r10: 0.7623 - p5: 0.1324 - p10: 0.0762 - val_loss: 0.0116 - val_r1: 0.3812 - val_r5: 0.6147 - val_r10: 0.7205 - val_p5: 0.1229 - val_p10: 0.0720 - lr: 4.8565e-04 - 793ms/epoch - 25ms/step
Epoch 30/1000
32/32 - 1s - loss: 0.0096 - r1: 0.4214 - r5: 0.6711 - r10: 0.7686 - p5: 0.1342 - p10: 0.0769 - val_loss: 0.0116 - val_r1: 0.3804 - val_r5: 0.6198 - val_r10: 0.7202 - val_p5: 0.1239 - val_p10: 0.0720 - lr: 4.8515e-04 - 789ms/epoch - 25ms/step
Epoch 31/1000
32/32 - 1s - loss: 0.0095 - r1: 0.4212 - r5: 0.6720 - r10: 0.7709 - p5: 0.1344 - p10: 0.0771 - val_loss: 0.0116 - val_r1: 0.3845 - val_r5: 0.6198 - val_r10: 0.7283 - val_p5: 0.1240 - val_p10: 0.0728 - lr: 4.8466e-04 - 788ms/epoch - 25ms/step
Epoch 32/1000
32/32 - 1s - loss: 0.0094 - r1: 0.4280 - r5: 0.6776 - r10: 0.7751 - p5: 0.1355 - p10: 0.0775 - val_loss: 0.0118 - val_r1: 0.3868 - val_r5: 0.6132 - val_r10: 0.7210 - val_p5: 0.1226 - val_p10: 0.0721 - lr: 4.8416e-04 - 792ms/epoch - 25ms/step
Epoch 33/1000
32/32 - 1s - loss: 0.0094 - r1: 0.4291 - r5: 0.6804 - r10: 0.7795 - p5: 0.1361 - p10: 0.0779 - val_loss: 0.0117 - val_r1: 0.3835 - val_r5: 0.6107 - val_r10: 0.7207 - val_p5: 0.1222 - val_p10: 0.0721 - lr: 4.8367e-04 - 791ms/epoch - 25ms/step
Epoch 34/1000
32/32 - 1s - loss: 0.0093 - r1: 0.4342 - r5: 0.6813 - r10: 0.7793 - p5: 0.1363 - p10: 0.0779 - val_loss: 0.0118 - val_r1: 0.3850 - val_r5: 0.6163 - val_r10: 0.7212 - val_p5: 0.1233 - val_p10: 0.0721 - lr: 4.8317e-04 - 793ms/epoch - 25ms/step
Epoch 35/1000
32/32 - 1s - loss: 0.0093 - r1: 0.4349 - r5: 0.6842 - r10: 0.7795 - p5: 0.1368 - p10: 0.0779 - val_loss: 0.0120 - val_r1: 0.3809 - val_r5: 0.6160 - val_r10: 0.7227 - val_p5: 0.1232 - val_p10: 0.0723 - lr: 4.8268e-04 - 791ms/epoch - 25ms/step
Epoch 36/1000
32/32 - 1s - loss: 0.0092 - r1: 0.4373 - r5: 0.6869 - r10: 0.7855 - p5: 0.1374 - p10: 0.0785 - val_loss: 0.0118 - val_r1: 0.3848 - val_r5: 0.6201 - val_r10: 0.7227 - val_p5: 0.1241 - val_p10: 0.0723 - lr: 4.8218e-04 - 792ms/epoch - 25ms/step
Epoch 37/1000
32/32 - 1s - loss: 0.0091 - r1: 0.4459 - r5: 0.6951 - r10: 0.7928 - p5: 0.1390 - p10: 0.0793 - val_loss: 0.0119 - val_r1: 0.3825 - val_r5: 0.6249 - val_r10: 0.7253 - val_p5: 0.1250 - val_p10: 0.0726 - lr: 4.8169e-04 - 789ms/epoch - 25ms/step
Epoch 38/1000
32/32 - 1s - loss: 0.0091 - r1: 0.4457 - r5: 0.6971 - r10: 0.7927 - p5: 0.1394 - p10: 0.0793 - val_loss: 0.0120 - val_r1: 0.3827 - val_r5: 0.6147 - val_r10: 0.7197 - val_p5: 0.1229 - val_p10: 0.0720 - lr: 4.8119e-04 - 794ms/epoch - 25ms/step
Epoch 39/1000
32/32 - 1s - loss: 0.0090 - r1: 0.4523 - r5: 0.6966 - r10: 0.7922 - p5: 0.1393 - p10: 0.0792 - val_loss: 0.0119 - val_r1: 0.3858 - val_r5: 0.6206 - val_r10: 0.7225 - val_p5: 0.1242 - val_p10: 0.0722 - lr: 4.8070e-04 - 794ms/epoch - 25ms/step
Epoch 40/1000
32/32 - 1s - loss: 0.0089 - r1: 0.4546 - r5: 0.7056 - r10: 0.8004 - p5: 0.1411 - p10: 0.0800 - val_loss: 0.0120 - val_r1: 0.3825 - val_r5: 0.6165 - val_r10: 0.7207 - val_p5: 0.1233 - val_p10: 0.0720 - lr: 4.8020e-04 - 790ms/epoch - 25ms/step
Epoch 41/1000
32/32 - 1s - loss: 0.0089 - r1: 0.4546 - r5: 0.7039 - r10: 0.7987 - p5: 0.1408 - p10: 0.0799 - val_loss: 0.0121 - val_r1: 0.3827 - val_r5: 0.6168 - val_r10: 0.7184 - val_p5: 0.1234 - val_p10: 0.0718 - lr: 4.7971e-04 - 788ms/epoch - 25ms/step
Epoch 42/1000
32/32 - 1s - loss: 0.0089 - r1: 0.4536 - r5: 0.7065 - r10: 0.8006 - p5: 0.1413 - p10: 0.0801 - val_loss: 0.0121 - val_r1: 0.3822 - val_r5: 0.6196 - val_r10: 0.7212 - val_p5: 0.1239 - val_p10: 0.0721 - lr: 4.7921e-04 - 790ms/epoch - 25ms/step
Epoch 43/1000
32/32 - 1s - loss: 0.0088 - r1: 0.4572 - r5: 0.7071 - r10: 0.8020 - p5: 0.1414 - p10: 0.0802 - val_loss: 0.0121 - val_r1: 0.3820 - val_r5: 0.6160 - val_r10: 0.7215 - val_p5: 0.1232 - val_p10: 0.0721 - lr: 4.7872e-04 - 791ms/epoch - 25ms/step
Epoch 44/1000
32/32 - 1s - loss: 0.0088 - r1: 0.4642 - r5: 0.7121 - r10: 0.8058 - p5: 0.1424 - p10: 0.0806 - val_loss: 0.0122 - val_r1: 0.3837 - val_r5: 0.6147 - val_r10: 0.7161 - val_p5: 0.1229 - val_p10: 0.0716 - lr: 4.7822e-04 - 789ms/epoch - 25ms/step
Epoch 45/1000
32/32 - 1s - loss: 0.0088 - r1: 0.4617 - r5: 0.7128 - r10: 0.8050 - p5: 0.1426 - p10: 0.0805 - val_loss: 0.0124 - val_r1: 0.3820 - val_r5: 0.6125 - val_r10: 0.7136 - val_p5: 0.1225 - val_p10: 0.0713 - lr: 4.7773e-04 - 787ms/epoch - 25ms/step
Epoch 46/1000
32/32 - 1s - loss: 0.0087 - r1: 0.4680 - r5: 0.7177 - r10: 0.8108 - p5: 0.1435 - p10: 0.0811 - val_loss: 0.0121 - val_r1: 0.3817 - val_r5: 0.6191 - val_r10: 0.7217 - val_p5: 0.1239 - val_p10: 0.0722 - lr: 4.7723e-04 - 792ms/epoch - 25ms/step
Epoch 47/1000
32/32 - 1s - loss: 0.0086 - r1: 0.4711 - r5: 0.7189 - r10: 0.8125 - p5: 0.1438 - p10: 0.0813 - val_loss: 0.0125 - val_r1: 0.3835 - val_r5: 0.6173 - val_r10: 0.7192 - val_p5: 0.1234 - val_p10: 0.0719 - lr: 4.7674e-04 - 790ms/epoch - 25ms/step
Epoch 48/1000
32/32 - 1s - loss: 0.0086 - r1: 0.4731 - r5: 0.7221 - r10: 0.8133 - p5: 0.1444 - p10: 0.0813 - val_loss: 0.0125 - val_r1: 0.3741 - val_r5: 0.6152 - val_r10: 0.7192 - val_p5: 0.1230 - val_p10: 0.0720 - lr: 4.7624e-04 - 791ms/epoch - 25ms/step
Epoch 49/1000
32/32 - 1s - loss: 0.0085 - r1: 0.4712 - r5: 0.7253 - r10: 0.8160 - p5: 0.1450 - p10: 0.0816 - val_loss: 0.0123 - val_r1: 0.3827 - val_r5: 0.6198 - val_r10: 0.7212 - val_p5: 0.1240 - val_p10: 0.0721 - lr: 4.7575e-04 - 788ms/epoch - 25ms/step
Epoch 50/1000
32/32 - 1s - loss: 0.0085 - r1: 0.4725 - r5: 0.7244 - r10: 0.8148 - p5: 0.1449 - p10: 0.0815 - val_loss: 0.0124 - val_r1: 0.3804 - val_r5: 0.6170 - val_r10: 0.7128 - val_p5: 0.1234 - val_p10: 0.0713 - lr: 4.7525e-04 - 787ms/epoch - 25ms/step
Epoch 51/1000
32/32 - 1s - loss: 0.0084 - r1: 0.4752 - r5: 0.7260 - r10: 0.8216 - p5: 0.1452 - p10: 0.0822 - val_loss: 0.0126 - val_r1: 0.3832 - val_r5: 0.6180 - val_r10: 0.7133 - val_p5: 0.1236 - val_p10: 0.0714 - lr: 4.7476e-04 - 785ms/epoch - 25ms/step
Epoch 52/1000
32/32 - 1s - loss: 0.0084 - r1: 0.4803 - r5: 0.7289 - r10: 0.8218 - p5: 0.1458 - p10: 0.0822 - val_loss: 0.0126 - val_r1: 0.3797 - val_r5: 0.6125 - val_r10: 0.7090 - val_p5: 0.1225 - val_p10: 0.0709 - lr: 4.7426e-04 - 792ms/epoch - 25ms/step
Epoch 53/1000
32/32 - 1s - loss: 0.0084 - r1: 0.4813 - r5: 0.7292 - r10: 0.8190 - p5: 0.1458 - p10: 0.0819 - val_loss: 0.0125 - val_r1: 0.3789 - val_r5: 0.6079 - val_r10: 0.7128 - val_p5: 0.1216 - val_p10: 0.0713 - lr: 4.7377e-04 - 788ms/epoch - 25ms/step
Epoch 54/1000
32/32 - 1s - loss: 0.0083 - r1: 0.4859 - r5: 0.7346 - r10: 0.8252 - p5: 0.1469 - p10: 0.0825 - val_loss: 0.0127 - val_r1: 0.3728 - val_r5: 0.6109 - val_r10: 0.7133 - val_p5: 0.1222 - val_p10: 0.0713 - lr: 4.7327e-04 - 790ms/epoch - 25ms/step
Epoch 55/1000
32/32 - 1s - loss: 0.0083 - r1: 0.4828 - r5: 0.7353 - r10: 0.8253 - p5: 0.1471 - p10: 0.0825 - val_loss: 0.0126 - val_r1: 0.3746 - val_r5: 0.6104 - val_r10: 0.7131 - val_p5: 0.1221 - val_p10: 0.0713 - lr: 4.7278e-04 - 791ms/epoch - 25ms/step
Epoch 56/1000
32/32 - 1s - loss: 0.0083 - r1: 0.4869 - r5: 0.7356 - r10: 0.8235 - p5: 0.1471 - p10: 0.0823 - val_loss: 0.0129 - val_r1: 0.3720 - val_r5: 0.6119 - val_r10: 0.7103 - val_p5: 0.1224 - val_p10: 0.0711 - lr: 4.7228e-04 - 793ms/epoch - 25ms/step
Epoch 57/1000
32/32 - 1s - loss: 0.0082 - r1: 0.4884 - r5: 0.7406 - r10: 0.8288 - p5: 0.1481 - p10: 0.0829 - val_loss: 0.0127 - val_r1: 0.3746 - val_r5: 0.6147 - val_r10: 0.7133 - val_p5: 0.1229 - val_p10: 0.0713 - lr: 4.7179e-04 - 787ms/epoch - 25ms/step
Epoch 58/1000
32/32 - 1s - loss: 0.0082 - r1: 0.4909 - r5: 0.7401 - r10: 0.8298 - p5: 0.1480 - p10: 0.0830 - val_loss: 0.0126 - val_r1: 0.3832 - val_r5: 0.6074 - val_r10: 0.7144 - val_p5: 0.1215 - val_p10: 0.0714 - lr: 4.7129e-04 - 790ms/epoch - 25ms/step
Epoch 59/1000
32/32 - 1s - loss: 0.0082 - r1: 0.4938 - r5: 0.7401 - r10: 0.8299 - p5: 0.1480 - p10: 0.0830 - val_loss: 0.0131 - val_r1: 0.3723 - val_r5: 0.6023 - val_r10: 0.7037 - val_p5: 0.1205 - val_p10: 0.0704 - lr: 4.7080e-04 - 790ms/epoch - 25ms/step
Epoch 60/1000
32/32 - 1s - loss: 0.0081 - r1: 0.4939 - r5: 0.7411 - r10: 0.8309 - p5: 0.1482 - p10: 0.0831 - val_loss: 0.0129 - val_r1: 0.3787 - val_r5: 0.6089 - val_r10: 0.7128 - val_p5: 0.1218 - val_p10: 0.0713 - lr: 4.7030e-04 - 791ms/epoch - 25ms/step
Epoch 61/1000
32/32 - 1s - loss: 0.0081 - r1: 0.4933 - r5: 0.7428 - r10: 0.8336 - p5: 0.1486 - p10: 0.0834 - val_loss: 0.0129 - val_r1: 0.3797 - val_r5: 0.6081 - val_r10: 0.7128 - val_p5: 0.1216 - val_p10: 0.0713 - lr: 4.6981e-04 - 792ms/epoch - 25ms/step
Epoch 62/1000
32/32 - 1s - loss: 0.0080 - r1: 0.4993 - r5: 0.7458 - r10: 0.8322 - p5: 0.1491 - p10: 0.0832 - val_loss: 0.0130 - val_r1: 0.3787 - val_r5: 0.6142 - val_r10: 0.7141 - val_p5: 0.1228 - val_p10: 0.0714 - lr: 4.6931e-04 - 789ms/epoch - 25ms/step
Epoch 63/1000
32/32 - 1s - loss: 0.0080 - r1: 0.4951 - r5: 0.7467 - r10: 0.8355 - p5: 0.1493 - p10: 0.0835 - val_loss: 0.0127 - val_r1: 0.3837 - val_r5: 0.6079 - val_r10: 0.7184 - val_p5: 0.1216 - val_p10: 0.0718 - lr: 4.6882e-04 - 789ms/epoch - 25ms/step
Epoch 64/1000
32/32 - 1s - loss: 0.0080 - r1: 0.5004 - r5: 0.7494 - r10: 0.8352 - p5: 0.1499 - p10: 0.0835 - val_loss: 0.0129 - val_r1: 0.3809 - val_r5: 0.6076 - val_r10: 0.7103 - val_p5: 0.1215 - val_p10: 0.0710 - lr: 4.6832e-04 - 789ms/epoch - 25ms/step
Epoch 65/1000
32/32 - 1s - loss: 0.0080 - r1: 0.5052 - r5: 0.7523 - r10: 0.8389 - p5: 0.1504 - p10: 0.0839 - val_loss: 0.0128 - val_r1: 0.3812 - val_r5: 0.6074 - val_r10: 0.7098 - val_p5: 0.1214 - val_p10: 0.0710 - lr: 4.6783e-04 - 790ms/epoch - 25ms/step
Epoch 66/1000
32/32 - 1s - loss: 0.0079 - r1: 0.5048 - r5: 0.7526 - r10: 0.8390 - p5: 0.1505 - p10: 0.0839 - val_loss: 0.0133 - val_r1: 0.3759 - val_r5: 0.6038 - val_r10: 0.7032 - val_p5: 0.1208 - val_p10: 0.0703 - lr: 4.6733e-04 - 792ms/epoch - 25ms/step
Epoch 67/1000
32/32 - 1s - loss: 0.0079 - r1: 0.5070 - r5: 0.7520 - r10: 0.8401 - p5: 0.1504 - p10: 0.0840 - val_loss: 0.0131 - val_r1: 0.3764 - val_r5: 0.6102 - val_r10: 0.7088 - val_p5: 0.1220 - val_p10: 0.0709 - lr: 4.6684e-04 - 792ms/epoch - 25ms/step
Epoch 68/1000
32/32 - 1s - loss: 0.0079 - r1: 0.5076 - r5: 0.7554 - r10: 0.8410 - p5: 0.1511 - p10: 0.0841 - val_loss: 0.0133 - val_r1: 0.3741 - val_r5: 0.6051 - val_r10: 0.7095 - val_p5: 0.1210 - val_p10: 0.0710 - lr: 4.6634e-04 - 791ms/epoch - 25ms/step
Epoch 69/1000
32/32 - 1s - loss: 0.0079 - r1: 0.5082 - r5: 0.7533 - r10: 0.8420 - p5: 0.1507 - p10: 0.0842 - val_loss: 0.0130 - val_r1: 0.3814 - val_r5: 0.6051 - val_r10: 0.7047 - val_p5: 0.1211 - val_p10: 0.0705 - lr: 4.6585e-04 - 787ms/epoch - 25ms/step
Epoch 70/1000
32/32 - 1s - loss: 0.0079 - r1: 0.5071 - r5: 0.7563 - r10: 0.8434 - p5: 0.1513 - p10: 0.0843 - val_loss: 0.0132 - val_r1: 0.3792 - val_r5: 0.6056 - val_r10: 0.7011 - val_p5: 0.1211 - val_p10: 0.0701 - lr: 4.6535e-04 - 791ms/epoch - 25ms/step
Epoch 71/1000
32/32 - 1s - loss: 0.0078 - r1: 0.5108 - r5: 0.7601 - r10: 0.8452 - p5: 0.1520 - p10: 0.0845 - val_loss: 0.0131 - val_r1: 0.3802 - val_r5: 0.6102 - val_r10: 0.7100 - val_p5: 0.1220 - val_p10: 0.0710 - lr: 4.6486e-04 - 789ms/epoch - 25ms/step
Epoch 71: early stopping
[92m[INFO] Loading best model...[0m
[93m[WARNING] Model folder already exists...[0m
Model: "ATT2ITM_1"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 162)]        0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 149)]        0           []                               
                                                                                                  
 embedding (Embedding)          (None, 162, 384)     926976      ['input_1[0][0]']                
                                                                                                  
 in_rsts (Embedding)            (None, 149, 384)     57216       ['input_2[0][0]']                
                                                                                                  
 dense (Dense)                  (None, 162, 256)     98560       ['embedding[0][0]']              
                                                                                                  
 dense_2 (Dense)                (None, 149, 256)     98560       ['in_rsts[0][0]']                
                                                                                                  
 tf.math.not_equal (TFOpLambda)  (None, 162)         0           ['input_1[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 162, 128)     32896       ['dense[0][0]']                  
                                                                                                  
 dense_3 (Dense)                (None, 149, 128)     32896       ['dense_2[0][0]']                
                                                                                                  
 tf.cast (TFOpLambda)           (None, 162)          0           ['tf.math.not_equal[0][0]']      
                                                                                                  
 word_emb (Lambda)              (None, 162, 128)     0           ['dense_1[0][0]']                
                                                                                                  
 rest_emb (Lambda)              (None, 149, 128)     0           ['dense_3[0][0]']                
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 162, 1)       0           ['tf.cast[0][0]']                
                                                                                                  
 lambda (Lambda)                (None, 162, 149)     0           ['word_emb[0][0]',               
                                                                  'rest_emb[0][0]']               
                                                                                                  
 tf.tile (TFOpLambda)           (None, 162, 149)     0           ['tf.expand_dims[0][0]']         
                                                                                                  
 lambda_1 (Lambda)              (None, 162, 149)     0           ['lambda[0][0]',                 
                                                                  'tf.tile[0][0]']                
                                                                                                  
 dotprod (Activation)           (None, 162, 149)     0           ['lambda_1[0][0]']               
                                                                                                  
 dropout (Dropout)              (None, 162, 149)     0           ['dotprod[0][0]']                
                                                                                                  
 sum (Lambda)                   (None, 149)          0           ['dropout[0][0]']                
                                                                                                  
 out (Activation)               (None, 149)          0           ['sum[0][0]']                    
                                                                                                  
==================================================================================================
Total params: 1,247,104
Trainable params: 1,247,104
Non-trainable params: 0
__________________________________________________________________________________________________
None
[92m[INFO] Model already trained. Loading weights...[0m
[93m[WARNING] Model folder already exists...[0m
Model: "ATT2ITM_1"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 162)]        0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 149)]        0           []                               
                                                                                                  
 embedding (Embedding)          (None, 162, 384)     926976      ['input_1[0][0]']                
                                                                                                  
 in_rsts (Embedding)            (None, 149, 384)     57216       ['input_2[0][0]']                
                                                                                                  
 dense (Dense)                  (None, 162, 256)     98560       ['embedding[0][0]']              
                                                                                                  
 dense_2 (Dense)                (None, 149, 256)     98560       ['in_rsts[0][0]']                
                                                                                                  
 tf.math.not_equal (TFOpLambda)  (None, 162)         0           ['input_1[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 162, 128)     32896       ['dense[0][0]']                  
                                                                                                  
 dense_3 (Dense)                (None, 149, 128)     32896       ['dense_2[0][0]']                
                                                                                                  
 tf.cast (TFOpLambda)           (None, 162)          0           ['tf.math.not_equal[0][0]']      
                                                                                                  
 word_emb (Lambda)              (None, 162, 128)     0           ['dense_1[0][0]']                
                                                                                                  
 rest_emb (Lambda)              (None, 149, 128)     0           ['dense_3[0][0]']                
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 162, 1)       0           ['tf.cast[0][0]']                
                                                                                                  
 lambda (Lambda)                (None, 162, 149)     0           ['word_emb[0][0]',               
                                                                  'rest_emb[0][0]']               
                                                                                                  
 tf.tile (TFOpLambda)           (None, 162, 149)     0           ['tf.expand_dims[0][0]']         
                                                                                                  
 lambda_1 (Lambda)              (None, 162, 149)     0           ['lambda[0][0]',                 
                                                                  'tf.tile[0][0]']                
                                                                                                  
 dotprod (Activation)           (None, 162, 149)     0           ['lambda_1[0][0]']               
                                                                                                  
 dropout (Dropout)              (None, 162, 149)     0           ['dotprod[0][0]']                
                                                                                                  
 sum (Lambda)                   (None, 149)          0           ['dropout[0][0]']                
                                                                                                  
 out (Activation)               (None, 149)          0           ['sum[0][0]']                    
                                                                                                  
==================================================================================================
Total params: 1,247,104
Trainable params: 1,247,104
Non-trainable params: 0
__________________________________________________________________________________________________
None
[92m[INFO] Model already trained. Loading weights...[0m
[93m[WARNING] Model folder already exists...[0m
Model: "ATT2ITM_1"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 162)]        0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 149)]        0           []                               
                                                                                                  
 embedding (Embedding)          (None, 162, 384)     926976      ['input_1[0][0]']                
                                                                                                  
 in_rsts (Embedding)            (None, 149, 384)     57216       ['input_2[0][0]']                
                                                                                                  
 dense (Dense)                  (None, 162, 256)     98560       ['embedding[0][0]']              
                                                                                                  
 dense_2 (Dense)                (None, 149, 256)     98560       ['in_rsts[0][0]']                
                                                                                                  
 tf.math.not_equal (TFOpLambda)  (None, 162)         0           ['input_1[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 162, 128)     32896       ['dense[0][0]']                  
                                                                                                  
 dense_3 (Dense)                (None, 149, 128)     32896       ['dense_2[0][0]']                
                                                                                                  
 tf.cast (TFOpLambda)           (None, 162)          0           ['tf.math.not_equal[0][0]']      
                                                                                                  
 word_emb (Lambda)              (None, 162, 128)     0           ['dense_1[0][0]']                
                                                                                                  
 rest_emb (Lambda)              (None, 149, 128)     0           ['dense_3[0][0]']                
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 162, 1)       0           ['tf.cast[0][0]']                
                                                                                                  
 lambda (Lambda)                (None, 162, 149)     0           ['word_emb[0][0]',               
                                                                  'rest_emb[0][0]']               
                                                                                                  
 tf.tile (TFOpLambda)           (None, 162, 149)     0           ['tf.expand_dims[0][0]']         
                                                                                                  
 lambda_1 (Lambda)              (None, 162, 149)     0           ['lambda[0][0]',                 
                                                                  'tf.tile[0][0]']                
                                                                                                  
 dotprod (Activation)           (None, 162, 149)     0           ['lambda_1[0][0]']               
                                                                                                  
 dropout (Dropout)              (None, 162, 149)     0           ['dotprod[0][0]']                
                                                                                                  
 sum (Lambda)                   (None, 149)          0           ['dropout[0][0]']                
                                                                                                  
 out (Activation)               (None, 149)          0           ['sum[0][0]']                    
                                                                                                  
==================================================================================================
Total params: 1,247,104
Trainable params: 1,247,104
Non-trainable params: 0
__________________________________________________________________________________________________
None
[92m[INFO] Model already trained. Loading weights...[0m
