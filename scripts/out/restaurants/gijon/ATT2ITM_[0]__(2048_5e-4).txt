Model: "ATT2ITM_0"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 162)]        0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 149)]        0           []                               
                                                                                                  
 embedding (Embedding)          (None, 162, 384)     926976      ['input_1[0][0]']                
                                                                                                  
 in_rsts (Embedding)            (None, 149, 384)     57216       ['input_2[0][0]']                
                                                                                                  
 dense (Dense)                  (None, 162, 256)     98560       ['embedding[0][0]']              
                                                                                                  
 dense_2 (Dense)                (None, 149, 256)     98560       ['in_rsts[0][0]']                
                                                                                                  
 tf.math.not_equal (TFOpLambda)  (None, 162)         0           ['input_1[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 162, 128)     32896       ['dense[0][0]']                  
                                                                                                  
 dense_3 (Dense)                (None, 149, 128)     32896       ['dense_2[0][0]']                
                                                                                                  
 tf.cast (TFOpLambda)           (None, 162)          0           ['tf.math.not_equal[0][0]']      
                                                                                                  
 word_emb (Lambda)              (None, 162, 128)     0           ['dense_1[0][0]']                
                                                                                                  
 rest_emb (Lambda)              (None, 149, 128)     0           ['dense_3[0][0]']                
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 162, 1)       0           ['tf.cast[0][0]']                
                                                                                                  
 lambda (Lambda)                (None, 162, 149)     0           ['word_emb[0][0]',               
                                                                  'rest_emb[0][0]']               
                                                                                                  
 tf.tile (TFOpLambda)           (None, 162, 149)     0           ['tf.expand_dims[0][0]']         
                                                                                                  
 lambda_1 (Lambda)              (None, 162, 149)     0           ['lambda[0][0]',                 
                                                                  'tf.tile[0][0]']                
                                                                                                  
 dotprod (Activation)           (None, 162, 149)     0           ['lambda_1[0][0]']               
                                                                                                  
 dropout (Dropout)              (None, 162, 149)     0           ['dotprod[0][0]']                
                                                                                                  
 sum (Lambda)                   (None, 149)          0           ['dropout[0][0]']                
                                                                                                  
 out (Activation)               (None, 149)          0           ['sum[0][0]']                    
                                                                                                  
==================================================================================================
Total params: 1,247,104
Trainable params: 1,247,104
Non-trainable params: 0
__________________________________________________________________________________________________
None
Epoch 1/1000
16/16 - 5s - loss: 4.7883 - r1: 0.0652 - r5: 0.1778 - r10: 0.2575 - p5: 0.0356 - p10: 0.0258 - val_loss: 4.6137 - val_r1: 0.0945 - val_r5: 0.2422 - val_r10: 0.3278 - val_p5: 0.0484 - val_p10: 0.0328 - lr: 4.9951e-04 - 5s/epoch - 284ms/step
Epoch 2/1000
16/16 - 2s - loss: 4.4319 - r1: 0.1181 - r5: 0.2735 - r10: 0.3693 - p5: 0.0547 - p10: 0.0369 - val_loss: 4.1879 - val_r1: 0.1685 - val_r5: 0.3344 - val_r10: 0.4348 - val_p5: 0.0668 - val_p10: 0.0435 - lr: 4.9901e-04 - 2s/epoch - 105ms/step
Epoch 3/1000
16/16 - 2s - loss: 3.9882 - r1: 0.1675 - r5: 0.3620 - r10: 0.4721 - p5: 0.0724 - p10: 0.0472 - val_loss: 3.7134 - val_r1: 0.2356 - val_r5: 0.4572 - val_r10: 0.5698 - val_p5: 0.0914 - val_p10: 0.0570 - lr: 4.9852e-04 - 2s/epoch - 104ms/step
Epoch 4/1000
16/16 - 1s - loss: 3.6447 - r1: 0.2136 - r5: 0.4326 - r10: 0.5523 - p5: 0.0865 - p10: 0.0552 - val_loss: 3.4538 - val_r1: 0.2828 - val_r5: 0.5131 - val_r10: 0.6302 - val_p5: 0.1026 - val_p10: 0.0631 - lr: 4.9802e-04 - 1s/epoch - 93ms/step
Epoch 5/1000
16/16 - 2s - loss: 3.3954 - r1: 0.2551 - r5: 0.4858 - r10: 0.6058 - p5: 0.0972 - p10: 0.0606 - val_loss: 3.2722 - val_r1: 0.3126 - val_r5: 0.5517 - val_r10: 0.6701 - val_p5: 0.1104 - val_p10: 0.0670 - lr: 4.9753e-04 - 2s/epoch - 96ms/step
Epoch 6/1000
16/16 - 2s - loss: 3.2228 - r1: 0.2806 - r5: 0.5254 - r10: 0.6465 - p5: 0.1051 - p10: 0.0647 - val_loss: 3.1577 - val_r1: 0.3327 - val_r5: 0.5779 - val_r10: 0.6828 - val_p5: 0.1155 - val_p10: 0.0683 - lr: 4.9703e-04 - 2s/epoch - 107ms/step
Epoch 7/1000
16/16 - 2s - loss: 3.0809 - r1: 0.3042 - r5: 0.5547 - r10: 0.6746 - p5: 0.1109 - p10: 0.0674 - val_loss: 3.0286 - val_r1: 0.3598 - val_r5: 0.5975 - val_r10: 0.6981 - val_p5: 0.1195 - val_p10: 0.0698 - lr: 4.9654e-04 - 2s/epoch - 105ms/step
Epoch 8/1000
16/16 - 2s - loss: 2.9699 - r1: 0.3231 - r5: 0.5792 - r10: 0.6937 - p5: 0.1158 - p10: 0.0694 - val_loss: 2.9402 - val_r1: 0.3667 - val_r5: 0.6069 - val_r10: 0.7029 - val_p5: 0.1213 - val_p10: 0.0703 - lr: 4.9604e-04 - 2s/epoch - 104ms/step
Epoch 9/1000
16/16 - 2s - loss: 2.8571 - r1: 0.3455 - r5: 0.6039 - r10: 0.7142 - p5: 0.1208 - p10: 0.0714 - val_loss: 2.8867 - val_r1: 0.3743 - val_r5: 0.6112 - val_r10: 0.7131 - val_p5: 0.1222 - val_p10: 0.0713 - lr: 4.9555e-04 - 2s/epoch - 106ms/step
Epoch 10/1000
16/16 - 2s - loss: 2.8035 - r1: 0.3523 - r5: 0.6110 - r10: 0.7229 - p5: 0.1222 - p10: 0.0723 - val_loss: 2.8664 - val_r1: 0.3713 - val_r5: 0.6135 - val_r10: 0.7177 - val_p5: 0.1227 - val_p10: 0.0718 - lr: 4.9505e-04 - 2s/epoch - 106ms/step
Epoch 11/1000
16/16 - 2s - loss: 2.7319 - r1: 0.3655 - r5: 0.6275 - r10: 0.7379 - p5: 0.1255 - p10: 0.0738 - val_loss: 2.8355 - val_r1: 0.3776 - val_r5: 0.6254 - val_r10: 0.7207 - val_p5: 0.1251 - val_p10: 0.0721 - lr: 4.9456e-04 - 2s/epoch - 104ms/step
Epoch 12/1000
16/16 - 2s - loss: 2.6689 - r1: 0.3751 - r5: 0.6408 - r10: 0.7479 - p5: 0.1282 - p10: 0.0748 - val_loss: 2.8063 - val_r1: 0.3799 - val_r5: 0.6287 - val_r10: 0.7238 - val_p5: 0.1257 - val_p10: 0.0724 - lr: 4.9406e-04 - 2s/epoch - 105ms/step
Epoch 13/1000
16/16 - 2s - loss: 2.6195 - r1: 0.3872 - r5: 0.6480 - r10: 0.7523 - p5: 0.1296 - p10: 0.0752 - val_loss: 2.7889 - val_r1: 0.3903 - val_r5: 0.6300 - val_r10: 0.7329 - val_p5: 0.1260 - val_p10: 0.0733 - lr: 4.9357e-04 - 2s/epoch - 104ms/step
Epoch 14/1000
16/16 - 1s - loss: 2.5765 - r1: 0.3929 - r5: 0.6571 - r10: 0.7623 - p5: 0.1314 - p10: 0.0762 - val_loss: 2.7980 - val_r1: 0.3814 - val_r5: 0.6229 - val_r10: 0.7276 - val_p5: 0.1245 - val_p10: 0.0728 - lr: 4.9307e-04 - 1s/epoch - 81ms/step
Epoch 15/1000
16/16 - 2s - loss: 2.5364 - r1: 0.4011 - r5: 0.6642 - r10: 0.7696 - p5: 0.1328 - p10: 0.0770 - val_loss: 2.7754 - val_r1: 0.3827 - val_r5: 0.6315 - val_r10: 0.7278 - val_p5: 0.1263 - val_p10: 0.0728 - lr: 4.9258e-04 - 2s/epoch - 106ms/step
Epoch 16/1000
16/16 - 2s - loss: 2.4899 - r1: 0.4061 - r5: 0.6754 - r10: 0.7773 - p5: 0.1351 - p10: 0.0777 - val_loss: 2.7742 - val_r1: 0.3814 - val_r5: 0.6269 - val_r10: 0.7349 - val_p5: 0.1254 - val_p10: 0.0735 - lr: 4.9208e-04 - 2s/epoch - 105ms/step
Epoch 17/1000
16/16 - 2s - loss: 2.4447 - r1: 0.4200 - r5: 0.6826 - r10: 0.7809 - p5: 0.1365 - p10: 0.0781 - val_loss: 2.7739 - val_r1: 0.3903 - val_r5: 0.6282 - val_r10: 0.7288 - val_p5: 0.1256 - val_p10: 0.0729 - lr: 4.9159e-04 - 2s/epoch - 105ms/step
Epoch 18/1000
16/16 - 2s - loss: 2.4139 - r1: 0.4254 - r5: 0.6900 - r10: 0.7891 - p5: 0.1380 - p10: 0.0789 - val_loss: 2.7505 - val_r1: 0.3944 - val_r5: 0.6285 - val_r10: 0.7324 - val_p5: 0.1257 - val_p10: 0.0732 - lr: 4.9109e-04 - 2s/epoch - 106ms/step
Epoch 19/1000
16/16 - 2s - loss: 2.3857 - r1: 0.4308 - r5: 0.6967 - r10: 0.7934 - p5: 0.1393 - p10: 0.0793 - val_loss: 2.7631 - val_r1: 0.3881 - val_r5: 0.6247 - val_r10: 0.7281 - val_p5: 0.1249 - val_p10: 0.0728 - lr: 4.9060e-04 - 2s/epoch - 96ms/step
Epoch 20/1000
16/16 - 2s - loss: 2.3533 - r1: 0.4347 - r5: 0.7020 - r10: 0.7987 - p5: 0.1404 - p10: 0.0799 - val_loss: 2.7658 - val_r1: 0.3873 - val_r5: 0.6244 - val_r10: 0.7332 - val_p5: 0.1249 - val_p10: 0.0733 - lr: 4.9010e-04 - 2s/epoch - 95ms/step
Epoch 21/1000
16/16 - 1s - loss: 2.3214 - r1: 0.4428 - r5: 0.7070 - r10: 0.8020 - p5: 0.1414 - p10: 0.0802 - val_loss: 2.7653 - val_r1: 0.3919 - val_r5: 0.6282 - val_r10: 0.7299 - val_p5: 0.1256 - val_p10: 0.0730 - lr: 4.8961e-04 - 1s/epoch - 93ms/step
Epoch 22/1000
16/16 - 2s - loss: 2.3057 - r1: 0.4451 - r5: 0.7103 - r10: 0.8060 - p5: 0.1421 - p10: 0.0806 - val_loss: 2.7623 - val_r1: 0.3947 - val_r5: 0.6302 - val_r10: 0.7311 - val_p5: 0.1261 - val_p10: 0.0731 - lr: 4.8911e-04 - 2s/epoch - 94ms/step
Epoch 23/1000
16/16 - 2s - loss: 2.2795 - r1: 0.4505 - r5: 0.7144 - r10: 0.8097 - p5: 0.1429 - p10: 0.0810 - val_loss: 2.7671 - val_r1: 0.3870 - val_r5: 0.6307 - val_r10: 0.7332 - val_p5: 0.1261 - val_p10: 0.0733 - lr: 4.8862e-04 - 2s/epoch - 96ms/step
Epoch 24/1000
16/16 - 2s - loss: 2.2574 - r1: 0.4545 - r5: 0.7166 - r10: 0.8100 - p5: 0.1433 - p10: 0.0810 - val_loss: 2.7662 - val_r1: 0.3903 - val_r5: 0.6285 - val_r10: 0.7321 - val_p5: 0.1257 - val_p10: 0.0732 - lr: 4.8812e-04 - 2s/epoch - 95ms/step
Epoch 25/1000
16/16 - 2s - loss: 2.2237 - r1: 0.4630 - r5: 0.7251 - r10: 0.8191 - p5: 0.1450 - p10: 0.0819 - val_loss: 2.7772 - val_r1: 0.3850 - val_r5: 0.6259 - val_r10: 0.7286 - val_p5: 0.1252 - val_p10: 0.0729 - lr: 4.8763e-04 - 2s/epoch - 95ms/step
Epoch 26/1000
16/16 - 2s - loss: 2.2215 - r1: 0.4594 - r5: 0.7285 - r10: 0.8203 - p5: 0.1457 - p10: 0.0820 - val_loss: 2.7736 - val_r1: 0.3850 - val_r5: 0.6241 - val_r10: 0.7309 - val_p5: 0.1248 - val_p10: 0.0731 - lr: 4.8713e-04 - 2s/epoch - 94ms/step
Epoch 27/1000
16/16 - 1s - loss: 2.1904 - r1: 0.4663 - r5: 0.7316 - r10: 0.8263 - p5: 0.1463 - p10: 0.0826 - val_loss: 2.7654 - val_r1: 0.3896 - val_r5: 0.6277 - val_r10: 0.7309 - val_p5: 0.1255 - val_p10: 0.0731 - lr: 4.8664e-04 - 1s/epoch - 83ms/step
Epoch 28/1000
16/16 - 1s - loss: 2.1760 - r1: 0.4695 - r5: 0.7348 - r10: 0.8273 - p5: 0.1470 - p10: 0.0827 - val_loss: 2.7646 - val_r1: 0.3967 - val_r5: 0.6259 - val_r10: 0.7301 - val_p5: 0.1252 - val_p10: 0.0730 - lr: 4.8614e-04 - 1s/epoch - 83ms/step
Epoch 29/1000
16/16 - 2s - loss: 2.1532 - r1: 0.4722 - r5: 0.7386 - r10: 0.8302 - p5: 0.1477 - p10: 0.0830 - val_loss: 2.7730 - val_r1: 0.3906 - val_r5: 0.6244 - val_r10: 0.7273 - val_p5: 0.1249 - val_p10: 0.0727 - lr: 4.8565e-04 - 2s/epoch - 96ms/step
Epoch 30/1000
16/16 - 2s - loss: 2.1232 - r1: 0.4804 - r5: 0.7426 - r10: 0.8339 - p5: 0.1485 - p10: 0.0834 - val_loss: 2.7698 - val_r1: 0.3919 - val_r5: 0.6224 - val_r10: 0.7291 - val_p5: 0.1245 - val_p10: 0.0729 - lr: 4.8515e-04 - 2s/epoch - 97ms/step
Epoch 31/1000
16/16 - 2s - loss: 2.1237 - r1: 0.4778 - r5: 0.7429 - r10: 0.8340 - p5: 0.1486 - p10: 0.0834 - val_loss: 2.7739 - val_r1: 0.3934 - val_r5: 0.6272 - val_r10: 0.7304 - val_p5: 0.1254 - val_p10: 0.0730 - lr: 4.8466e-04 - 2s/epoch - 96ms/step
Epoch 32/1000
16/16 - 2s - loss: 2.1072 - r1: 0.4835 - r5: 0.7477 - r10: 0.8375 - p5: 0.1495 - p10: 0.0837 - val_loss: 2.7792 - val_r1: 0.3929 - val_r5: 0.6272 - val_r10: 0.7260 - val_p5: 0.1254 - val_p10: 0.0726 - lr: 4.8416e-04 - 2s/epoch - 96ms/step
Epoch 33/1000
16/16 - 1s - loss: 2.0934 - r1: 0.4874 - r5: 0.7484 - r10: 0.8374 - p5: 0.1497 - p10: 0.0837 - val_loss: 2.7810 - val_r1: 0.3919 - val_r5: 0.6254 - val_r10: 0.7248 - val_p5: 0.1251 - val_p10: 0.0725 - lr: 4.8367e-04 - 1s/epoch - 80ms/step
Epoch 34/1000
16/16 - 2s - loss: 2.0610 - r1: 0.4917 - r5: 0.7543 - r10: 0.8409 - p5: 0.1509 - p10: 0.0841 - val_loss: 2.7733 - val_r1: 0.3909 - val_r5: 0.6262 - val_r10: 0.7250 - val_p5: 0.1252 - val_p10: 0.0725 - lr: 4.8317e-04 - 2s/epoch - 95ms/step
Epoch 35/1000
16/16 - 2s - loss: 2.0622 - r1: 0.4902 - r5: 0.7539 - r10: 0.8421 - p5: 0.1508 - p10: 0.0842 - val_loss: 2.7882 - val_r1: 0.3855 - val_r5: 0.6213 - val_r10: 0.7207 - val_p5: 0.1243 - val_p10: 0.0721 - lr: 4.8268e-04 - 2s/epoch - 95ms/step
Epoch 36/1000
16/16 - 2s - loss: 2.0449 - r1: 0.4934 - r5: 0.7614 - r10: 0.8451 - p5: 0.1523 - p10: 0.0845 - val_loss: 2.7844 - val_r1: 0.3898 - val_r5: 0.6231 - val_r10: 0.7248 - val_p5: 0.1247 - val_p10: 0.0725 - lr: 4.8218e-04 - 2s/epoch - 95ms/step
Epoch 37/1000
16/16 - 1s - loss: 2.0294 - r1: 0.4949 - r5: 0.7620 - r10: 0.8491 - p5: 0.1524 - p10: 0.0849 - val_loss: 2.7954 - val_r1: 0.3860 - val_r5: 0.6267 - val_r10: 0.7235 - val_p5: 0.1253 - val_p10: 0.0724 - lr: 4.8169e-04 - 1s/epoch - 94ms/step
Epoch 38/1000
16/16 - 2s - loss: 2.0203 - r1: 0.5002 - r5: 0.7627 - r10: 0.8501 - p5: 0.1525 - p10: 0.0850 - val_loss: 2.8048 - val_r1: 0.3842 - val_r5: 0.6213 - val_r10: 0.7243 - val_p5: 0.1243 - val_p10: 0.0724 - lr: 4.8119e-04 - 2s/epoch - 96ms/step
Epoch 39/1000
16/16 - 2s - loss: 2.0087 - r1: 0.5010 - r5: 0.7659 - r10: 0.8501 - p5: 0.1532 - p10: 0.0850 - val_loss: 2.7919 - val_r1: 0.3868 - val_r5: 0.6252 - val_r10: 0.7248 - val_p5: 0.1250 - val_p10: 0.0725 - lr: 4.8070e-04 - 2s/epoch - 94ms/step
Epoch 40/1000
16/16 - 2s - loss: 1.9873 - r1: 0.5029 - r5: 0.7714 - r10: 0.8554 - p5: 0.1543 - p10: 0.0855 - val_loss: 2.7896 - val_r1: 0.3855 - val_r5: 0.6244 - val_r10: 0.7266 - val_p5: 0.1249 - val_p10: 0.0727 - lr: 4.8020e-04 - 2s/epoch - 96ms/step
Epoch 41/1000
16/16 - 2s - loss: 1.9926 - r1: 0.5033 - r5: 0.7684 - r10: 0.8536 - p5: 0.1537 - p10: 0.0854 - val_loss: 2.8074 - val_r1: 0.3825 - val_r5: 0.6254 - val_r10: 0.7253 - val_p5: 0.1251 - val_p10: 0.0725 - lr: 4.7971e-04 - 2s/epoch - 94ms/step
Epoch 42/1000
16/16 - 1s - loss: 1.9630 - r1: 0.5124 - r5: 0.7778 - r10: 0.8591 - p5: 0.1556 - p10: 0.0859 - val_loss: 2.8133 - val_r1: 0.3797 - val_r5: 0.6224 - val_r10: 0.7233 - val_p5: 0.1245 - val_p10: 0.0724 - lr: 4.7921e-04 - 1s/epoch - 93ms/step
Epoch 43/1000
16/16 - 2s - loss: 1.9558 - r1: 0.5136 - r5: 0.7727 - r10: 0.8574 - p5: 0.1545 - p10: 0.0858 - val_loss: 2.8157 - val_r1: 0.3787 - val_r5: 0.6208 - val_r10: 0.7233 - val_p5: 0.1242 - val_p10: 0.0723 - lr: 4.7872e-04 - 2s/epoch - 94ms/step
Epoch 44/1000
16/16 - 1s - loss: 1.9404 - r1: 0.5140 - r5: 0.7795 - r10: 0.8623 - p5: 0.1559 - p10: 0.0862 - val_loss: 2.8180 - val_r1: 0.3807 - val_r5: 0.6168 - val_r10: 0.7187 - val_p5: 0.1234 - val_p10: 0.0719 - lr: 4.7822e-04 - 1s/epoch - 94ms/step
Epoch 45/1000
16/16 - 2s - loss: 1.9405 - r1: 0.5131 - r5: 0.7794 - r10: 0.8609 - p5: 0.1559 - p10: 0.0861 - val_loss: 2.8266 - val_r1: 0.3855 - val_r5: 0.6152 - val_r10: 0.7174 - val_p5: 0.1230 - val_p10: 0.0717 - lr: 4.7773e-04 - 2s/epoch - 94ms/step
Epoch 46/1000
16/16 - 1s - loss: 1.9232 - r1: 0.5140 - r5: 0.7828 - r10: 0.8635 - p5: 0.1566 - p10: 0.0863 - val_loss: 2.8290 - val_r1: 0.3845 - val_r5: 0.6158 - val_r10: 0.7161 - val_p5: 0.1232 - val_p10: 0.0716 - lr: 4.7723e-04 - 1s/epoch - 94ms/step
Epoch 47/1000
16/16 - 2s - loss: 1.9148 - r1: 0.5186 - r5: 0.7830 - r10: 0.8639 - p5: 0.1566 - p10: 0.0864 - val_loss: 2.8268 - val_r1: 0.3845 - val_r5: 0.6244 - val_r10: 0.7166 - val_p5: 0.1249 - val_p10: 0.0717 - lr: 4.7674e-04 - 2s/epoch - 95ms/step
Epoch 48/1000
16/16 - 2s - loss: 1.9072 - r1: 0.5200 - r5: 0.7851 - r10: 0.8660 - p5: 0.1570 - p10: 0.0866 - val_loss: 2.8454 - val_r1: 0.3809 - val_r5: 0.6175 - val_r10: 0.7210 - val_p5: 0.1236 - val_p10: 0.0721 - lr: 4.7624e-04 - 2s/epoch - 95ms/step
Epoch 49/1000
16/16 - 2s - loss: 1.9062 - r1: 0.5218 - r5: 0.7851 - r10: 0.8670 - p5: 0.1570 - p10: 0.0867 - val_loss: 2.8331 - val_r1: 0.3799 - val_r5: 0.6178 - val_r10: 0.7189 - val_p5: 0.1236 - val_p10: 0.0719 - lr: 4.7575e-04 - 2s/epoch - 94ms/step
Epoch 50/1000
16/16 - 2s - loss: 1.9001 - r1: 0.5180 - r5: 0.7882 - r10: 0.8690 - p5: 0.1576 - p10: 0.0869 - val_loss: 2.8324 - val_r1: 0.3845 - val_r5: 0.6239 - val_r10: 0.7154 - val_p5: 0.1248 - val_p10: 0.0715 - lr: 4.7525e-04 - 2s/epoch - 96ms/step
Epoch 51/1000
16/16 - 2s - loss: 1.8822 - r1: 0.5266 - r5: 0.7898 - r10: 0.8706 - p5: 0.1580 - p10: 0.0871 - val_loss: 2.8538 - val_r1: 0.3822 - val_r5: 0.6196 - val_r10: 0.7156 - val_p5: 0.1239 - val_p10: 0.0716 - lr: 4.7476e-04 - 2s/epoch - 94ms/step
Epoch 52/1000
16/16 - 2s - loss: 1.8799 - r1: 0.5267 - r5: 0.7901 - r10: 0.8676 - p5: 0.1580 - p10: 0.0868 - val_loss: 2.8414 - val_r1: 0.3875 - val_r5: 0.6196 - val_r10: 0.7159 - val_p5: 0.1239 - val_p10: 0.0716 - lr: 4.7426e-04 - 2s/epoch - 94ms/step
Epoch 53/1000
16/16 - 2s - loss: 1.8663 - r1: 0.5311 - r5: 0.7909 - r10: 0.8700 - p5: 0.1582 - p10: 0.0870 - val_loss: 2.8530 - val_r1: 0.3893 - val_r5: 0.6180 - val_r10: 0.7108 - val_p5: 0.1236 - val_p10: 0.0711 - lr: 4.7377e-04 - 2s/epoch - 95ms/step
Epoch 54/1000
16/16 - 2s - loss: 1.8584 - r1: 0.5300 - r5: 0.7940 - r10: 0.8749 - p5: 0.1588 - p10: 0.0875 - val_loss: 2.8535 - val_r1: 0.3860 - val_r5: 0.6165 - val_r10: 0.7098 - val_p5: 0.1233 - val_p10: 0.0710 - lr: 4.7327e-04 - 2s/epoch - 94ms/step
Epoch 55/1000
16/16 - 1s - loss: 1.8505 - r1: 0.5314 - r5: 0.7957 - r10: 0.8742 - p5: 0.1591 - p10: 0.0874 - val_loss: 2.8626 - val_r1: 0.3835 - val_r5: 0.6155 - val_r10: 0.7136 - val_p5: 0.1231 - val_p10: 0.0714 - lr: 4.7278e-04 - 1s/epoch - 81ms/step
Epoch 56/1000
16/16 - 2s - loss: 1.8377 - r1: 0.5359 - r5: 0.7965 - r10: 0.8748 - p5: 0.1593 - p10: 0.0875 - val_loss: 2.8646 - val_r1: 0.3853 - val_r5: 0.6112 - val_r10: 0.7098 - val_p5: 0.1222 - val_p10: 0.0710 - lr: 4.7228e-04 - 2s/epoch - 95ms/step
Epoch 57/1000
16/16 - 2s - loss: 1.8371 - r1: 0.5353 - r5: 0.7974 - r10: 0.8747 - p5: 0.1595 - p10: 0.0875 - val_loss: 2.8647 - val_r1: 0.3855 - val_r5: 0.6142 - val_r10: 0.7197 - val_p5: 0.1228 - val_p10: 0.0720 - lr: 4.7179e-04 - 2s/epoch - 96ms/step
Epoch 58/1000
16/16 - 2s - loss: 1.8229 - r1: 0.5386 - r5: 0.7986 - r10: 0.8790 - p5: 0.1597 - p10: 0.0879 - val_loss: 2.8723 - val_r1: 0.3814 - val_r5: 0.6168 - val_r10: 0.7111 - val_p5: 0.1233 - val_p10: 0.0711 - lr: 4.7129e-04 - 2s/epoch - 94ms/step
Epoch 59/1000
16/16 - 2s - loss: 1.8288 - r1: 0.5371 - r5: 0.7976 - r10: 0.8778 - p5: 0.1595 - p10: 0.0878 - val_loss: 2.8718 - val_r1: 0.3830 - val_r5: 0.6142 - val_r10: 0.7111 - val_p5: 0.1228 - val_p10: 0.0711 - lr: 4.7080e-04 - 2s/epoch - 96ms/step
Epoch 60/1000
16/16 - 2s - loss: 1.8173 - r1: 0.5395 - r5: 0.8006 - r10: 0.8772 - p5: 0.1601 - p10: 0.0877 - val_loss: 2.8646 - val_r1: 0.3832 - val_r5: 0.6155 - val_r10: 0.7146 - val_p5: 0.1231 - val_p10: 0.0715 - lr: 4.7030e-04 - 2s/epoch - 94ms/step
Epoch 61/1000
16/16 - 1s - loss: 1.8096 - r1: 0.5384 - r5: 0.8006 - r10: 0.8791 - p5: 0.1601 - p10: 0.0879 - val_loss: 2.8669 - val_r1: 0.3842 - val_r5: 0.6109 - val_r10: 0.7156 - val_p5: 0.1222 - val_p10: 0.0716 - lr: 4.6981e-04 - 1s/epoch - 94ms/step
Epoch 62/1000
16/16 - 2s - loss: 1.7965 - r1: 0.5432 - r5: 0.8029 - r10: 0.8827 - p5: 0.1606 - p10: 0.0883 - val_loss: 2.8707 - val_r1: 0.3787 - val_r5: 0.6137 - val_r10: 0.7156 - val_p5: 0.1227 - val_p10: 0.0716 - lr: 4.6931e-04 - 2s/epoch - 94ms/step
Epoch 63/1000
16/16 - 2s - loss: 1.7955 - r1: 0.5420 - r5: 0.8062 - r10: 0.8833 - p5: 0.1612 - p10: 0.0883 - val_loss: 2.8725 - val_r1: 0.3784 - val_r5: 0.6114 - val_r10: 0.7095 - val_p5: 0.1223 - val_p10: 0.0710 - lr: 4.6882e-04 - 2s/epoch - 95ms/step
Epoch 64/1000
16/16 - 2s - loss: 1.7876 - r1: 0.5436 - r5: 0.8088 - r10: 0.8845 - p5: 0.1618 - p10: 0.0885 - val_loss: 2.8790 - val_r1: 0.3799 - val_r5: 0.6076 - val_r10: 0.7098 - val_p5: 0.1215 - val_p10: 0.0710 - lr: 4.6832e-04 - 2s/epoch - 94ms/step
Epoch 65/1000
16/16 - 1s - loss: 1.7685 - r1: 0.5512 - r5: 0.8102 - r10: 0.8858 - p5: 0.1620 - p10: 0.0886 - val_loss: 2.8872 - val_r1: 0.3789 - val_r5: 0.6104 - val_r10: 0.7113 - val_p5: 0.1221 - val_p10: 0.0711 - lr: 4.6783e-04 - 1s/epoch - 82ms/step
Epoch 66/1000
16/16 - 2s - loss: 1.7702 - r1: 0.5482 - r5: 0.8080 - r10: 0.8845 - p5: 0.1616 - p10: 0.0885 - val_loss: 2.9038 - val_r1: 0.3784 - val_r5: 0.6125 - val_r10: 0.7113 - val_p5: 0.1225 - val_p10: 0.0711 - lr: 4.6733e-04 - 2s/epoch - 132ms/step
Epoch 67/1000
16/16 - 2s - loss: 1.7666 - r1: 0.5489 - r5: 0.8108 - r10: 0.8860 - p5: 0.1621 - p10: 0.0886 - val_loss: 2.8911 - val_r1: 0.3766 - val_r5: 0.6099 - val_r10: 0.7159 - val_p5: 0.1220 - val_p10: 0.0716 - lr: 4.6684e-04 - 2s/epoch - 95ms/step
Epoch 68/1000
16/16 - 2s - loss: 1.7660 - r1: 0.5483 - r5: 0.8100 - r10: 0.8862 - p5: 0.1620 - p10: 0.0886 - val_loss: 2.8953 - val_r1: 0.3784 - val_r5: 0.6112 - val_r10: 0.7149 - val_p5: 0.1222 - val_p10: 0.0715 - lr: 4.6634e-04 - 2s/epoch - 95ms/step
Epoch 68: early stopping
[92m[INFO] Loading best model...[0m
[93m[WARNING] Model folder already exists...[0m
Model: "ATT2ITM_0"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 162)]        0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 149)]        0           []                               
                                                                                                  
 embedding (Embedding)          (None, 162, 384)     926976      ['input_1[0][0]']                
                                                                                                  
 in_rsts (Embedding)            (None, 149, 384)     57216       ['input_2[0][0]']                
                                                                                                  
 dense (Dense)                  (None, 162, 256)     98560       ['embedding[0][0]']              
                                                                                                  
 dense_2 (Dense)                (None, 149, 256)     98560       ['in_rsts[0][0]']                
                                                                                                  
 tf.math.not_equal (TFOpLambda)  (None, 162)         0           ['input_1[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 162, 128)     32896       ['dense[0][0]']                  
                                                                                                  
 dense_3 (Dense)                (None, 149, 128)     32896       ['dense_2[0][0]']                
                                                                                                  
 tf.cast (TFOpLambda)           (None, 162)          0           ['tf.math.not_equal[0][0]']      
                                                                                                  
 word_emb (Lambda)              (None, 162, 128)     0           ['dense_1[0][0]']                
                                                                                                  
 rest_emb (Lambda)              (None, 149, 128)     0           ['dense_3[0][0]']                
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 162, 1)       0           ['tf.cast[0][0]']                
                                                                                                  
 lambda (Lambda)                (None, 162, 149)     0           ['word_emb[0][0]',               
                                                                  'rest_emb[0][0]']               
                                                                                                  
 tf.tile (TFOpLambda)           (None, 162, 149)     0           ['tf.expand_dims[0][0]']         
                                                                                                  
 lambda_1 (Lambda)              (None, 162, 149)     0           ['lambda[0][0]',                 
                                                                  'tf.tile[0][0]']                
                                                                                                  
 dotprod (Activation)           (None, 162, 149)     0           ['lambda_1[0][0]']               
                                                                                                  
 dropout (Dropout)              (None, 162, 149)     0           ['dotprod[0][0]']                
                                                                                                  
 sum (Lambda)                   (None, 149)          0           ['dropout[0][0]']                
                                                                                                  
 out (Activation)               (None, 149)          0           ['sum[0][0]']                    
                                                                                                  
==================================================================================================
Total params: 1,247,104
Trainable params: 1,247,104
Non-trainable params: 0
__________________________________________________________________________________________________
None
[92m[INFO] Model already trained. Loading weights...[0m
[93m[WARNING] Model folder already exists...[0m
Model: "ATT2ITM_0"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 162)]        0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 149)]        0           []                               
                                                                                                  
 embedding (Embedding)          (None, 162, 384)     926976      ['input_1[0][0]']                
                                                                                                  
 in_rsts (Embedding)            (None, 149, 384)     57216       ['input_2[0][0]']                
                                                                                                  
 dense (Dense)                  (None, 162, 256)     98560       ['embedding[0][0]']              
                                                                                                  
 dense_2 (Dense)                (None, 149, 256)     98560       ['in_rsts[0][0]']                
                                                                                                  
 tf.math.not_equal (TFOpLambda)  (None, 162)         0           ['input_1[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 162, 128)     32896       ['dense[0][0]']                  
                                                                                                  
 dense_3 (Dense)                (None, 149, 128)     32896       ['dense_2[0][0]']                
                                                                                                  
 tf.cast (TFOpLambda)           (None, 162)          0           ['tf.math.not_equal[0][0]']      
                                                                                                  
 word_emb (Lambda)              (None, 162, 128)     0           ['dense_1[0][0]']                
                                                                                                  
 rest_emb (Lambda)              (None, 149, 128)     0           ['dense_3[0][0]']                
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 162, 1)       0           ['tf.cast[0][0]']                
                                                                                                  
 lambda (Lambda)                (None, 162, 149)     0           ['word_emb[0][0]',               
                                                                  'rest_emb[0][0]']               
                                                                                                  
 tf.tile (TFOpLambda)           (None, 162, 149)     0           ['tf.expand_dims[0][0]']         
                                                                                                  
 lambda_1 (Lambda)              (None, 162, 149)     0           ['lambda[0][0]',                 
                                                                  'tf.tile[0][0]']                
                                                                                                  
 dotprod (Activation)           (None, 162, 149)     0           ['lambda_1[0][0]']               
                                                                                                  
 dropout (Dropout)              (None, 162, 149)     0           ['dotprod[0][0]']                
                                                                                                  
 sum (Lambda)                   (None, 149)          0           ['dropout[0][0]']                
                                                                                                  
 out (Activation)               (None, 149)          0           ['sum[0][0]']                    
                                                                                                  
==================================================================================================
Total params: 1,247,104
Trainable params: 1,247,104
Non-trainable params: 0
__________________________________________________________________________________________________
None
[92m[INFO] Model already trained. Loading weights...[0m
[93m[WARNING] Model folder already exists...[0m
Model: "ATT2ITM_0"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 162)]        0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 149)]        0           []                               
                                                                                                  
 embedding (Embedding)          (None, 162, 384)     926976      ['input_1[0][0]']                
                                                                                                  
 in_rsts (Embedding)            (None, 149, 384)     57216       ['input_2[0][0]']                
                                                                                                  
 dense (Dense)                  (None, 162, 256)     98560       ['embedding[0][0]']              
                                                                                                  
 dense_2 (Dense)                (None, 149, 256)     98560       ['in_rsts[0][0]']                
                                                                                                  
 tf.math.not_equal (TFOpLambda)  (None, 162)         0           ['input_1[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 162, 128)     32896       ['dense[0][0]']                  
                                                                                                  
 dense_3 (Dense)                (None, 149, 128)     32896       ['dense_2[0][0]']                
                                                                                                  
 tf.cast (TFOpLambda)           (None, 162)          0           ['tf.math.not_equal[0][0]']      
                                                                                                  
 word_emb (Lambda)              (None, 162, 128)     0           ['dense_1[0][0]']                
                                                                                                  
 rest_emb (Lambda)              (None, 149, 128)     0           ['dense_3[0][0]']                
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 162, 1)       0           ['tf.cast[0][0]']                
                                                                                                  
 lambda (Lambda)                (None, 162, 149)     0           ['word_emb[0][0]',               
                                                                  'rest_emb[0][0]']               
                                                                                                  
 tf.tile (TFOpLambda)           (None, 162, 149)     0           ['tf.expand_dims[0][0]']         
                                                                                                  
 lambda_1 (Lambda)              (None, 162, 149)     0           ['lambda[0][0]',                 
                                                                  'tf.tile[0][0]']                
                                                                                                  
 dotprod (Activation)           (None, 162, 149)     0           ['lambda_1[0][0]']               
                                                                                                  
 dropout (Dropout)              (None, 162, 149)     0           ['dotprod[0][0]']                
                                                                                                  
 sum (Lambda)                   (None, 149)          0           ['dropout[0][0]']                
                                                                                                  
 out (Activation)               (None, 149)          0           ['sum[0][0]']                    
                                                                                                  
==================================================================================================
Total params: 1,247,104
Trainable params: 1,247,104
Non-trainable params: 0
__________________________________________________________________________________________________
None
[92m[INFO] Model already trained. Loading weights...[0m
