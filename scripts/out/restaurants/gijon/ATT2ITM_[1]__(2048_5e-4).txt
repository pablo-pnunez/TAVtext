Model: "ATT2ITM_1"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 162)]        0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 149)]        0           []                               
                                                                                                  
 embedding (Embedding)          (None, 162, 384)     926976      ['input_1[0][0]']                
                                                                                                  
 in_rsts (Embedding)            (None, 149, 384)     57216       ['input_2[0][0]']                
                                                                                                  
 dense (Dense)                  (None, 162, 256)     98560       ['embedding[0][0]']              
                                                                                                  
 dense_2 (Dense)                (None, 149, 256)     98560       ['in_rsts[0][0]']                
                                                                                                  
 tf.math.not_equal (TFOpLambda)  (None, 162)         0           ['input_1[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 162, 128)     32896       ['dense[0][0]']                  
                                                                                                  
 dense_3 (Dense)                (None, 149, 128)     32896       ['dense_2[0][0]']                
                                                                                                  
 tf.cast (TFOpLambda)           (None, 162)          0           ['tf.math.not_equal[0][0]']      
                                                                                                  
 word_emb (Lambda)              (None, 162, 128)     0           ['dense_1[0][0]']                
                                                                                                  
 rest_emb (Lambda)              (None, 149, 128)     0           ['dense_3[0][0]']                
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 162, 1)       0           ['tf.cast[0][0]']                
                                                                                                  
 lambda (Lambda)                (None, 162, 149)     0           ['word_emb[0][0]',               
                                                                  'rest_emb[0][0]']               
                                                                                                  
 tf.tile (TFOpLambda)           (None, 162, 149)     0           ['tf.expand_dims[0][0]']         
                                                                                                  
 lambda_1 (Lambda)              (None, 162, 149)     0           ['lambda[0][0]',                 
                                                                  'tf.tile[0][0]']                
                                                                                                  
 dotprod (Activation)           (None, 162, 149)     0           ['lambda_1[0][0]']               
                                                                                                  
 dropout (Dropout)              (None, 162, 149)     0           ['dotprod[0][0]']                
                                                                                                  
 sum (Lambda)                   (None, 149)          0           ['dropout[0][0]']                
                                                                                                  
 out (Activation)               (None, 149)          0           ['sum[0][0]']                    
                                                                                                  
==================================================================================================
Total params: 1,247,104
Trainable params: 1,247,104
Non-trainable params: 0
__________________________________________________________________________________________________
None
Epoch 1/1000
16/16 - 5s - loss: 0.0583 - r1: 0.0284 - r5: 0.0764 - r10: 0.1218 - p5: 0.0153 - p10: 0.0122 - val_loss: 0.0273 - val_r1: 0.0414 - val_r5: 0.1644 - val_r10: 0.2338 - val_p5: 0.0329 - val_p10: 0.0234 - lr: 4.9951e-04 - 5s/epoch - 319ms/step
Epoch 2/1000
16/16 - 2s - loss: 0.0238 - r1: 0.0327 - r5: 0.1100 - r10: 0.1889 - p5: 0.0220 - p10: 0.0189 - val_loss: 0.0209 - val_r1: 0.0686 - val_r5: 0.1553 - val_r10: 0.2493 - val_p5: 0.0311 - val_p10: 0.0249 - lr: 4.9901e-04 - 2s/epoch - 104ms/step
Epoch 3/1000
16/16 - 2s - loss: 0.0206 - r1: 0.0588 - r5: 0.1519 - r10: 0.2182 - p5: 0.0304 - p10: 0.0218 - val_loss: 0.0188 - val_r1: 0.0691 - val_r5: 0.1820 - val_r10: 0.2694 - val_p5: 0.0364 - val_p10: 0.0270 - lr: 4.9852e-04 - 2s/epoch - 104ms/step
Epoch 4/1000
16/16 - 2s - loss: 0.0191 - r1: 0.0573 - r5: 0.1636 - r10: 0.2431 - p5: 0.0327 - p10: 0.0243 - val_loss: 0.0178 - val_r1: 0.0808 - val_r5: 0.2221 - val_r10: 0.3024 - val_p5: 0.0445 - val_p10: 0.0302 - lr: 4.9802e-04 - 2s/epoch - 104ms/step
Epoch 5/1000
16/16 - 2s - loss: 0.0182 - r1: 0.0691 - r5: 0.1845 - r10: 0.2621 - p5: 0.0369 - p10: 0.0262 - val_loss: 0.0172 - val_r1: 0.0780 - val_r5: 0.2376 - val_r10: 0.3146 - val_p5: 0.0475 - val_p10: 0.0315 - lr: 4.9753e-04 - 2s/epoch - 104ms/step
Epoch 6/1000
16/16 - 2s - loss: 0.0178 - r1: 0.0805 - r5: 0.2012 - r10: 0.2810 - p5: 0.0402 - p10: 0.0281 - val_loss: 0.0168 - val_r1: 0.0943 - val_r5: 0.2638 - val_r10: 0.3372 - val_p5: 0.0528 - val_p10: 0.0337 - lr: 4.9703e-04 - 2s/epoch - 103ms/step
Epoch 7/1000
16/16 - 2s - loss: 0.0174 - r1: 0.0985 - r5: 0.2206 - r10: 0.2992 - p5: 0.0441 - p10: 0.0299 - val_loss: 0.0164 - val_r1: 0.1215 - val_r5: 0.2897 - val_r10: 0.3588 - val_p5: 0.0579 - val_p10: 0.0358 - lr: 4.9654e-04 - 2s/epoch - 103ms/step
Epoch 8/1000
16/16 - 2s - loss: 0.0169 - r1: 0.1201 - r5: 0.2481 - r10: 0.3256 - p5: 0.0496 - p10: 0.0326 - val_loss: 0.0159 - val_r1: 0.1593 - val_r5: 0.3156 - val_r10: 0.3942 - val_p5: 0.0631 - val_p10: 0.0394 - lr: 4.9604e-04 - 2s/epoch - 104ms/step
Epoch 9/1000
16/16 - 2s - loss: 0.0164 - r1: 0.1393 - r5: 0.2763 - r10: 0.3575 - p5: 0.0552 - p10: 0.0357 - val_loss: 0.0154 - val_r1: 0.1891 - val_r5: 0.3476 - val_r10: 0.4363 - val_p5: 0.0694 - val_p10: 0.0436 - lr: 4.9555e-04 - 2s/epoch - 104ms/step
Epoch 10/1000
16/16 - 2s - loss: 0.0159 - r1: 0.1581 - r5: 0.3052 - r10: 0.3906 - p5: 0.0610 - p10: 0.0390 - val_loss: 0.0149 - val_r1: 0.2140 - val_r5: 0.3853 - val_r10: 0.4788 - val_p5: 0.0771 - val_p10: 0.0479 - lr: 4.9505e-04 - 2s/epoch - 103ms/step
Epoch 11/1000
16/16 - 2s - loss: 0.0153 - r1: 0.1754 - r5: 0.3339 - r10: 0.4226 - p5: 0.0668 - p10: 0.0423 - val_loss: 0.0144 - val_r1: 0.2351 - val_r5: 0.4234 - val_r10: 0.5202 - val_p5: 0.0846 - val_p10: 0.0520 - lr: 4.9456e-04 - 2s/epoch - 103ms/step
Epoch 12/1000
16/16 - 2s - loss: 0.0148 - r1: 0.1942 - r5: 0.3609 - r10: 0.4579 - p5: 0.0722 - p10: 0.0458 - val_loss: 0.0139 - val_r1: 0.2559 - val_r5: 0.4513 - val_r10: 0.5565 - val_p5: 0.0903 - val_p10: 0.0557 - lr: 4.9406e-04 - 2s/epoch - 104ms/step
Epoch 13/1000
16/16 - 2s - loss: 0.0144 - r1: 0.2087 - r5: 0.3880 - r10: 0.4900 - p5: 0.0776 - p10: 0.0490 - val_loss: 0.0135 - val_r1: 0.2737 - val_r5: 0.4795 - val_r10: 0.5909 - val_p5: 0.0959 - val_p10: 0.0591 - lr: 4.9357e-04 - 2s/epoch - 103ms/step
Epoch 14/1000
16/16 - 2s - loss: 0.0139 - r1: 0.2266 - r5: 0.4149 - r10: 0.5179 - p5: 0.0830 - p10: 0.0518 - val_loss: 0.0131 - val_r1: 0.2889 - val_r5: 0.5052 - val_r10: 0.6132 - val_p5: 0.1010 - val_p10: 0.0614 - lr: 4.9307e-04 - 2s/epoch - 103ms/step
Epoch 15/1000
16/16 - 2s - loss: 0.0135 - r1: 0.2381 - r5: 0.4352 - r10: 0.5416 - p5: 0.0870 - p10: 0.0542 - val_loss: 0.0128 - val_r1: 0.3052 - val_r5: 0.5278 - val_r10: 0.6343 - val_p5: 0.1056 - val_p10: 0.0634 - lr: 4.9258e-04 - 2s/epoch - 103ms/step
Epoch 16/1000
16/16 - 2s - loss: 0.0132 - r1: 0.2561 - r5: 0.4551 - r10: 0.5626 - p5: 0.0910 - p10: 0.0563 - val_loss: 0.0126 - val_r1: 0.3118 - val_r5: 0.5418 - val_r10: 0.6526 - val_p5: 0.1084 - val_p10: 0.0653 - lr: 4.9208e-04 - 2s/epoch - 105ms/step
Epoch 17/1000
16/16 - 2s - loss: 0.0129 - r1: 0.2684 - r5: 0.4760 - r10: 0.5850 - p5: 0.0952 - p10: 0.0585 - val_loss: 0.0123 - val_r1: 0.3238 - val_r5: 0.5593 - val_r10: 0.6668 - val_p5: 0.1119 - val_p10: 0.0667 - lr: 4.9159e-04 - 2s/epoch - 103ms/step
Epoch 18/1000
16/16 - 2s - loss: 0.0127 - r1: 0.2768 - r5: 0.4891 - r10: 0.5985 - p5: 0.0978 - p10: 0.0599 - val_loss: 0.0122 - val_r1: 0.3314 - val_r5: 0.5667 - val_r10: 0.6811 - val_p5: 0.1134 - val_p10: 0.0681 - lr: 4.9109e-04 - 2s/epoch - 103ms/step
Epoch 19/1000
16/16 - 2s - loss: 0.0124 - r1: 0.2866 - r5: 0.5074 - r10: 0.6176 - p5: 0.1015 - p10: 0.0618 - val_loss: 0.0120 - val_r1: 0.3405 - val_r5: 0.5781 - val_r10: 0.6915 - val_p5: 0.1156 - val_p10: 0.0692 - lr: 4.9060e-04 - 2s/epoch - 103ms/step
Epoch 20/1000
16/16 - 2s - loss: 0.0122 - r1: 0.2953 - r5: 0.5164 - r10: 0.6256 - p5: 0.1033 - p10: 0.0626 - val_loss: 0.0119 - val_r1: 0.3464 - val_r5: 0.5845 - val_r10: 0.7009 - val_p5: 0.1168 - val_p10: 0.0701 - lr: 4.9010e-04 - 2s/epoch - 104ms/step
Epoch 21/1000
16/16 - 2s - loss: 0.0120 - r1: 0.3068 - r5: 0.5317 - r10: 0.6410 - p5: 0.1063 - p10: 0.0641 - val_loss: 0.0118 - val_r1: 0.3560 - val_r5: 0.5980 - val_r10: 0.7075 - val_p5: 0.1196 - val_p10: 0.0707 - lr: 4.8961e-04 - 2s/epoch - 97ms/step
Epoch 22/1000
16/16 - 1s - loss: 0.0118 - r1: 0.3113 - r5: 0.5419 - r10: 0.6495 - p5: 0.1084 - p10: 0.0649 - val_loss: 0.0117 - val_r1: 0.3604 - val_r5: 0.6046 - val_r10: 0.7095 - val_p5: 0.1209 - val_p10: 0.0710 - lr: 4.8911e-04 - 884ms/epoch - 55ms/step
Epoch 23/1000
16/16 - 1s - loss: 0.0117 - r1: 0.3231 - r5: 0.5487 - r10: 0.6587 - p5: 0.1097 - p10: 0.0659 - val_loss: 0.0117 - val_r1: 0.3624 - val_r5: 0.6053 - val_r10: 0.7103 - val_p5: 0.1211 - val_p10: 0.0710 - lr: 4.8862e-04 - 883ms/epoch - 55ms/step
Epoch 24/1000
16/16 - 1s - loss: 0.0115 - r1: 0.3276 - r5: 0.5564 - r10: 0.6631 - p5: 0.1113 - p10: 0.0663 - val_loss: 0.0116 - val_r1: 0.3672 - val_r5: 0.6137 - val_r10: 0.7151 - val_p5: 0.1227 - val_p10: 0.0715 - lr: 4.8812e-04 - 883ms/epoch - 55ms/step
Epoch 25/1000
16/16 - 1s - loss: 0.0114 - r1: 0.3332 - r5: 0.5632 - r10: 0.6751 - p5: 0.1127 - p10: 0.0675 - val_loss: 0.0116 - val_r1: 0.3662 - val_r5: 0.6140 - val_r10: 0.7164 - val_p5: 0.1227 - val_p10: 0.0716 - lr: 4.8763e-04 - 884ms/epoch - 55ms/step
Epoch 26/1000
16/16 - 1s - loss: 0.0113 - r1: 0.3385 - r5: 0.5717 - r10: 0.6795 - p5: 0.1143 - p10: 0.0679 - val_loss: 0.0116 - val_r1: 0.3698 - val_r5: 0.6168 - val_r10: 0.7253 - val_p5: 0.1233 - val_p10: 0.0725 - lr: 4.8713e-04 - 721ms/epoch - 45ms/step
Epoch 27/1000
16/16 - 1s - loss: 0.0111 - r1: 0.3444 - r5: 0.5801 - r10: 0.6869 - p5: 0.1160 - p10: 0.0687 - val_loss: 0.0116 - val_r1: 0.3764 - val_r5: 0.6198 - val_r10: 0.7238 - val_p5: 0.1240 - val_p10: 0.0724 - lr: 4.8664e-04 - 725ms/epoch - 45ms/step
Epoch 28/1000
16/16 - 1s - loss: 0.0110 - r1: 0.3475 - r5: 0.5838 - r10: 0.6925 - p5: 0.1168 - p10: 0.0693 - val_loss: 0.0115 - val_r1: 0.3753 - val_r5: 0.6196 - val_r10: 0.7263 - val_p5: 0.1240 - val_p10: 0.0727 - lr: 4.8614e-04 - 889ms/epoch - 56ms/step
Epoch 29/1000
16/16 - 1s - loss: 0.0109 - r1: 0.3523 - r5: 0.5928 - r10: 0.7000 - p5: 0.1185 - p10: 0.0700 - val_loss: 0.0115 - val_r1: 0.3781 - val_r5: 0.6201 - val_r10: 0.7258 - val_p5: 0.1240 - val_p10: 0.0726 - lr: 4.8565e-04 - 884ms/epoch - 55ms/step
Epoch 30/1000
16/16 - 1s - loss: 0.0108 - r1: 0.3622 - r5: 0.6003 - r10: 0.7045 - p5: 0.1201 - p10: 0.0705 - val_loss: 0.0114 - val_r1: 0.3799 - val_r5: 0.6186 - val_r10: 0.7253 - val_p5: 0.1237 - val_p10: 0.0726 - lr: 4.8515e-04 - 882ms/epoch - 55ms/step
Epoch 31/1000
16/16 - 1s - loss: 0.0107 - r1: 0.3628 - r5: 0.6043 - r10: 0.7110 - p5: 0.1209 - p10: 0.0711 - val_loss: 0.0114 - val_r1: 0.3827 - val_r5: 0.6229 - val_r10: 0.7266 - val_p5: 0.1246 - val_p10: 0.0727 - lr: 4.8466e-04 - 720ms/epoch - 45ms/step
Epoch 32/1000
16/16 - 1s - loss: 0.0107 - r1: 0.3706 - r5: 0.6073 - r10: 0.7115 - p5: 0.1215 - p10: 0.0712 - val_loss: 0.0115 - val_r1: 0.3855 - val_r5: 0.6249 - val_r10: 0.7278 - val_p5: 0.1250 - val_p10: 0.0728 - lr: 4.8416e-04 - 721ms/epoch - 45ms/step
Epoch 33/1000
16/16 - 1s - loss: 0.0106 - r1: 0.3736 - r5: 0.6176 - r10: 0.7187 - p5: 0.1235 - p10: 0.0719 - val_loss: 0.0114 - val_r1: 0.3842 - val_r5: 0.6226 - val_r10: 0.7250 - val_p5: 0.1246 - val_p10: 0.0726 - lr: 4.8367e-04 - 898ms/epoch - 56ms/step
Epoch 34/1000
16/16 - 1s - loss: 0.0105 - r1: 0.3755 - r5: 0.6193 - r10: 0.7220 - p5: 0.1239 - p10: 0.0722 - val_loss: 0.0115 - val_r1: 0.3870 - val_r5: 0.6264 - val_r10: 0.7278 - val_p5: 0.1252 - val_p10: 0.0728 - lr: 4.8317e-04 - 718ms/epoch - 45ms/step
Epoch 35/1000
16/16 - 1s - loss: 0.0104 - r1: 0.3794 - r5: 0.6233 - r10: 0.7268 - p5: 0.1247 - p10: 0.0727 - val_loss: 0.0115 - val_r1: 0.3883 - val_r5: 0.6277 - val_r10: 0.7283 - val_p5: 0.1255 - val_p10: 0.0728 - lr: 4.8268e-04 - 722ms/epoch - 45ms/step
Epoch 36/1000
16/16 - 1s - loss: 0.0103 - r1: 0.3847 - r5: 0.6277 - r10: 0.7317 - p5: 0.1255 - p10: 0.0732 - val_loss: 0.0115 - val_r1: 0.3850 - val_r5: 0.6226 - val_r10: 0.7266 - val_p5: 0.1245 - val_p10: 0.0727 - lr: 4.8218e-04 - 720ms/epoch - 45ms/step
Epoch 37/1000
16/16 - 1s - loss: 0.0102 - r1: 0.3881 - r5: 0.6323 - r10: 0.7365 - p5: 0.1265 - p10: 0.0736 - val_loss: 0.0115 - val_r1: 0.3898 - val_r5: 0.6244 - val_r10: 0.7311 - val_p5: 0.1248 - val_p10: 0.0731 - lr: 4.8169e-04 - 719ms/epoch - 45ms/step
Epoch 38/1000
16/16 - 1s - loss: 0.0102 - r1: 0.3913 - r5: 0.6353 - r10: 0.7393 - p5: 0.1270 - p10: 0.0739 - val_loss: 0.0116 - val_r1: 0.3840 - val_r5: 0.6234 - val_r10: 0.7309 - val_p5: 0.1246 - val_p10: 0.0731 - lr: 4.8119e-04 - 719ms/epoch - 45ms/step
Epoch 39/1000
16/16 - 1s - loss: 0.0100 - r1: 0.3971 - r5: 0.6409 - r10: 0.7402 - p5: 0.1282 - p10: 0.0740 - val_loss: 0.0116 - val_r1: 0.3916 - val_r5: 0.6252 - val_r10: 0.7266 - val_p5: 0.1251 - val_p10: 0.0727 - lr: 4.8070e-04 - 720ms/epoch - 45ms/step
Epoch 40/1000
16/16 - 1s - loss: 0.0100 - r1: 0.3991 - r5: 0.6432 - r10: 0.7467 - p5: 0.1286 - p10: 0.0747 - val_loss: 0.0117 - val_r1: 0.3886 - val_r5: 0.6216 - val_r10: 0.7281 - val_p5: 0.1244 - val_p10: 0.0728 - lr: 4.8020e-04 - 717ms/epoch - 45ms/step
Epoch 41/1000
16/16 - 1s - loss: 0.0099 - r1: 0.4001 - r5: 0.6468 - r10: 0.7468 - p5: 0.1293 - p10: 0.0747 - val_loss: 0.0116 - val_r1: 0.3883 - val_r5: 0.6231 - val_r10: 0.7276 - val_p5: 0.1246 - val_p10: 0.0728 - lr: 4.7971e-04 - 714ms/epoch - 45ms/step
Epoch 42/1000
16/16 - 1s - loss: 0.0099 - r1: 0.4030 - r5: 0.6525 - r10: 0.7544 - p5: 0.1305 - p10: 0.0754 - val_loss: 0.0117 - val_r1: 0.3893 - val_r5: 0.6226 - val_r10: 0.7311 - val_p5: 0.1245 - val_p10: 0.0732 - lr: 4.7921e-04 - 715ms/epoch - 45ms/step
Epoch 43/1000
16/16 - 1s - loss: 0.0098 - r1: 0.4077 - r5: 0.6538 - r10: 0.7539 - p5: 0.1308 - p10: 0.0754 - val_loss: 0.0116 - val_r1: 0.3926 - val_r5: 0.6247 - val_r10: 0.7294 - val_p5: 0.1249 - val_p10: 0.0730 - lr: 4.7872e-04 - 711ms/epoch - 44ms/step
Epoch 44/1000
16/16 - 1s - loss: 0.0098 - r1: 0.4127 - r5: 0.6610 - r10: 0.7570 - p5: 0.1322 - p10: 0.0757 - val_loss: 0.0116 - val_r1: 0.3888 - val_r5: 0.6287 - val_r10: 0.7306 - val_p5: 0.1257 - val_p10: 0.0731 - lr: 4.7822e-04 - 710ms/epoch - 44ms/step
Epoch 45/1000
16/16 - 1s - loss: 0.0097 - r1: 0.4131 - r5: 0.6609 - r10: 0.7581 - p5: 0.1322 - p10: 0.0758 - val_loss: 0.0116 - val_r1: 0.3901 - val_r5: 0.6282 - val_r10: 0.7311 - val_p5: 0.1257 - val_p10: 0.0731 - lr: 4.7773e-04 - 707ms/epoch - 44ms/step
Epoch 46/1000
16/16 - 1s - loss: 0.0096 - r1: 0.4206 - r5: 0.6660 - r10: 0.7648 - p5: 0.1332 - p10: 0.0765 - val_loss: 0.0117 - val_r1: 0.4003 - val_r5: 0.6302 - val_r10: 0.7301 - val_p5: 0.1260 - val_p10: 0.0730 - lr: 4.7723e-04 - 712ms/epoch - 45ms/step
Epoch 47/1000
16/16 - 1s - loss: 0.0095 - r1: 0.4224 - r5: 0.6701 - r10: 0.7671 - p5: 0.1340 - p10: 0.0767 - val_loss: 0.0116 - val_r1: 0.3936 - val_r5: 0.6269 - val_r10: 0.7319 - val_p5: 0.1254 - val_p10: 0.0732 - lr: 4.7674e-04 - 723ms/epoch - 45ms/step
Epoch 48/1000
16/16 - 1s - loss: 0.0095 - r1: 0.4224 - r5: 0.6698 - r10: 0.7684 - p5: 0.1340 - p10: 0.0768 - val_loss: 0.0117 - val_r1: 0.3939 - val_r5: 0.6269 - val_r10: 0.7255 - val_p5: 0.1254 - val_p10: 0.0726 - lr: 4.7624e-04 - 712ms/epoch - 45ms/step
Epoch 49/1000
16/16 - 1s - loss: 0.0094 - r1: 0.4260 - r5: 0.6740 - r10: 0.7726 - p5: 0.1348 - p10: 0.0773 - val_loss: 0.0117 - val_r1: 0.3865 - val_r5: 0.6231 - val_r10: 0.7245 - val_p5: 0.1246 - val_p10: 0.0725 - lr: 4.7575e-04 - 711ms/epoch - 44ms/step
Epoch 50/1000
16/16 - 1s - loss: 0.0094 - r1: 0.4281 - r5: 0.6793 - r10: 0.7771 - p5: 0.1359 - p10: 0.0777 - val_loss: 0.0117 - val_r1: 0.3919 - val_r5: 0.6272 - val_r10: 0.7260 - val_p5: 0.1255 - val_p10: 0.0726 - lr: 4.7525e-04 - 714ms/epoch - 45ms/step
Epoch 51/1000
16/16 - 1s - loss: 0.0093 - r1: 0.4297 - r5: 0.6781 - r10: 0.7767 - p5: 0.1356 - p10: 0.0777 - val_loss: 0.0117 - val_r1: 0.3980 - val_r5: 0.6318 - val_r10: 0.7227 - val_p5: 0.1264 - val_p10: 0.0723 - lr: 4.7476e-04 - 712ms/epoch - 45ms/step
Epoch 52/1000
16/16 - 1s - loss: 0.0093 - r1: 0.4386 - r5: 0.6808 - r10: 0.7778 - p5: 0.1361 - p10: 0.0778 - val_loss: 0.0118 - val_r1: 0.3921 - val_r5: 0.6267 - val_r10: 0.7225 - val_p5: 0.1253 - val_p10: 0.0722 - lr: 4.7426e-04 - 715ms/epoch - 45ms/step
Epoch 53/1000
16/16 - 1s - loss: 0.0092 - r1: 0.4398 - r5: 0.6831 - r10: 0.7781 - p5: 0.1366 - p10: 0.0778 - val_loss: 0.0118 - val_r1: 0.4008 - val_r5: 0.6269 - val_r10: 0.7215 - val_p5: 0.1253 - val_p10: 0.0721 - lr: 4.7377e-04 - 718ms/epoch - 45ms/step
Epoch 54/1000
16/16 - 1s - loss: 0.0092 - r1: 0.4363 - r5: 0.6861 - r10: 0.7852 - p5: 0.1372 - p10: 0.0785 - val_loss: 0.0118 - val_r1: 0.3967 - val_r5: 0.6269 - val_r10: 0.7243 - val_p5: 0.1254 - val_p10: 0.0725 - lr: 4.7327e-04 - 718ms/epoch - 45ms/step
Epoch 55/1000
16/16 - 1s - loss: 0.0092 - r1: 0.4382 - r5: 0.6895 - r10: 0.7857 - p5: 0.1379 - p10: 0.0786 - val_loss: 0.0118 - val_r1: 0.3944 - val_r5: 0.6236 - val_r10: 0.7238 - val_p5: 0.1247 - val_p10: 0.0724 - lr: 4.7278e-04 - 719ms/epoch - 45ms/step
Epoch 56/1000
16/16 - 1s - loss: 0.0091 - r1: 0.4400 - r5: 0.6894 - r10: 0.7858 - p5: 0.1379 - p10: 0.0786 - val_loss: 0.0119 - val_r1: 0.4013 - val_r5: 0.6277 - val_r10: 0.7258 - val_p5: 0.1255 - val_p10: 0.0726 - lr: 4.7228e-04 - 718ms/epoch - 45ms/step
Epoch 57/1000
16/16 - 1s - loss: 0.0091 - r1: 0.4409 - r5: 0.6960 - r10: 0.7898 - p5: 0.1392 - p10: 0.0790 - val_loss: 0.0118 - val_r1: 0.3985 - val_r5: 0.6252 - val_r10: 0.7281 - val_p5: 0.1250 - val_p10: 0.0728 - lr: 4.7179e-04 - 720ms/epoch - 45ms/step
Epoch 58/1000
16/16 - 1s - loss: 0.0090 - r1: 0.4437 - r5: 0.6965 - r10: 0.7895 - p5: 0.1393 - p10: 0.0789 - val_loss: 0.0120 - val_r1: 0.3959 - val_r5: 0.6247 - val_r10: 0.7248 - val_p5: 0.1249 - val_p10: 0.0725 - lr: 4.7129e-04 - 717ms/epoch - 45ms/step
Epoch 59/1000
16/16 - 1s - loss: 0.0090 - r1: 0.4476 - r5: 0.6938 - r10: 0.7906 - p5: 0.1388 - p10: 0.0791 - val_loss: 0.0121 - val_r1: 0.3949 - val_r5: 0.6226 - val_r10: 0.7281 - val_p5: 0.1245 - val_p10: 0.0728 - lr: 4.7080e-04 - 716ms/epoch - 45ms/step
Epoch 60/1000
16/16 - 1s - loss: 0.0089 - r1: 0.4490 - r5: 0.6987 - r10: 0.7923 - p5: 0.1397 - p10: 0.0792 - val_loss: 0.0120 - val_r1: 0.4010 - val_r5: 0.6219 - val_r10: 0.7281 - val_p5: 0.1244 - val_p10: 0.0728 - lr: 4.7030e-04 - 715ms/epoch - 45ms/step
Epoch 61/1000
16/16 - 1s - loss: 0.0089 - r1: 0.4499 - r5: 0.6979 - r10: 0.7949 - p5: 0.1396 - p10: 0.0795 - val_loss: 0.0122 - val_r1: 0.3980 - val_r5: 0.6285 - val_r10: 0.7301 - val_p5: 0.1257 - val_p10: 0.0730 - lr: 4.6981e-04 - 715ms/epoch - 45ms/step
Epoch 62/1000
16/16 - 1s - loss: 0.0089 - r1: 0.4546 - r5: 0.7026 - r10: 0.7967 - p5: 0.1405 - p10: 0.0797 - val_loss: 0.0121 - val_r1: 0.3891 - val_r5: 0.6274 - val_r10: 0.7240 - val_p5: 0.1256 - val_p10: 0.0724 - lr: 4.6931e-04 - 712ms/epoch - 45ms/step
Epoch 63/1000
16/16 - 1s - loss: 0.0088 - r1: 0.4568 - r5: 0.7049 - r10: 0.7996 - p5: 0.1410 - p10: 0.0800 - val_loss: 0.0121 - val_r1: 0.4000 - val_r5: 0.6231 - val_r10: 0.7271 - val_p5: 0.1247 - val_p10: 0.0727 - lr: 4.6882e-04 - 715ms/epoch - 45ms/step
Epoch 64/1000
16/16 - 1s - loss: 0.0088 - r1: 0.4578 - r5: 0.7084 - r10: 0.8017 - p5: 0.1417 - p10: 0.0802 - val_loss: 0.0121 - val_r1: 0.3972 - val_r5: 0.6285 - val_r10: 0.7243 - val_p5: 0.1257 - val_p10: 0.0724 - lr: 4.6832e-04 - 714ms/epoch - 45ms/step
Epoch 65/1000
16/16 - 1s - loss: 0.0088 - r1: 0.4607 - r5: 0.7107 - r10: 0.8050 - p5: 0.1421 - p10: 0.0805 - val_loss: 0.0119 - val_r1: 0.3942 - val_r5: 0.6236 - val_r10: 0.7260 - val_p5: 0.1247 - val_p10: 0.0726 - lr: 4.6783e-04 - 716ms/epoch - 45ms/step
Epoch 66/1000
16/16 - 1s - loss: 0.0087 - r1: 0.4622 - r5: 0.7122 - r10: 0.8035 - p5: 0.1425 - p10: 0.0804 - val_loss: 0.0119 - val_r1: 0.3939 - val_r5: 0.6267 - val_r10: 0.7235 - val_p5: 0.1253 - val_p10: 0.0724 - lr: 4.6733e-04 - 718ms/epoch - 45ms/step
Epoch 67/1000
16/16 - 1s - loss: 0.0087 - r1: 0.4628 - r5: 0.7145 - r10: 0.8082 - p5: 0.1429 - p10: 0.0808 - val_loss: 0.0120 - val_r1: 0.3873 - val_r5: 0.6201 - val_r10: 0.7202 - val_p5: 0.1241 - val_p10: 0.0720 - lr: 4.6684e-04 - 717ms/epoch - 45ms/step
Epoch 68/1000
16/16 - 1s - loss: 0.0087 - r1: 0.4653 - r5: 0.7130 - r10: 0.8070 - p5: 0.1426 - p10: 0.0807 - val_loss: 0.0121 - val_r1: 0.3906 - val_r5: 0.6168 - val_r10: 0.7207 - val_p5: 0.1234 - val_p10: 0.0721 - lr: 4.6634e-04 - 717ms/epoch - 45ms/step
Epoch 69/1000
16/16 - 1s - loss: 0.0086 - r1: 0.4671 - r5: 0.7162 - r10: 0.8096 - p5: 0.1433 - p10: 0.0810 - val_loss: 0.0124 - val_r1: 0.3911 - val_r5: 0.6165 - val_r10: 0.7172 - val_p5: 0.1233 - val_p10: 0.0717 - lr: 4.6585e-04 - 720ms/epoch - 45ms/step
Epoch 70/1000
16/16 - 1s - loss: 0.0086 - r1: 0.4656 - r5: 0.7175 - r10: 0.8091 - p5: 0.1435 - p10: 0.0809 - val_loss: 0.0125 - val_r1: 0.3911 - val_r5: 0.6191 - val_r10: 0.7169 - val_p5: 0.1238 - val_p10: 0.0716 - lr: 4.6535e-04 - 720ms/epoch - 45ms/step
Epoch 71/1000
16/16 - 1s - loss: 0.0086 - r1: 0.4703 - r5: 0.7204 - r10: 0.8126 - p5: 0.1441 - p10: 0.0813 - val_loss: 0.0125 - val_r1: 0.3919 - val_r5: 0.6158 - val_r10: 0.7199 - val_p5: 0.1232 - val_p10: 0.0720 - lr: 4.6486e-04 - 718ms/epoch - 45ms/step
Epoch 72/1000
16/16 - 1s - loss: 0.0085 - r1: 0.4728 - r5: 0.7220 - r10: 0.8143 - p5: 0.1444 - p10: 0.0814 - val_loss: 0.0124 - val_r1: 0.3957 - val_r5: 0.6193 - val_r10: 0.7220 - val_p5: 0.1239 - val_p10: 0.0722 - lr: 4.6436e-04 - 715ms/epoch - 45ms/step
Epoch 73/1000
16/16 - 1s - loss: 0.0085 - r1: 0.4746 - r5: 0.7207 - r10: 0.8134 - p5: 0.1441 - p10: 0.0813 - val_loss: 0.0123 - val_r1: 0.3949 - val_r5: 0.6203 - val_r10: 0.7189 - val_p5: 0.1241 - val_p10: 0.0719 - lr: 4.6387e-04 - 718ms/epoch - 45ms/step
Epoch 74/1000
16/16 - 1s - loss: 0.0085 - r1: 0.4733 - r5: 0.7242 - r10: 0.8164 - p5: 0.1449 - p10: 0.0816 - val_loss: 0.0124 - val_r1: 0.3977 - val_r5: 0.6183 - val_r10: 0.7207 - val_p5: 0.1237 - val_p10: 0.0721 - lr: 4.6337e-04 - 716ms/epoch - 45ms/step
Epoch 75/1000
16/16 - 1s - loss: 0.0085 - r1: 0.4767 - r5: 0.7267 - r10: 0.8168 - p5: 0.1453 - p10: 0.0817 - val_loss: 0.0125 - val_r1: 0.3934 - val_r5: 0.6198 - val_r10: 0.7194 - val_p5: 0.1241 - val_p10: 0.0719 - lr: 4.6288e-04 - 713ms/epoch - 45ms/step
Epoch 76/1000
16/16 - 1s - loss: 0.0084 - r1: 0.4772 - r5: 0.7245 - r10: 0.8175 - p5: 0.1449 - p10: 0.0817 - val_loss: 0.0126 - val_r1: 0.3952 - val_r5: 0.6196 - val_r10: 0.7248 - val_p5: 0.1239 - val_p10: 0.0725 - lr: 4.6238e-04 - 720ms/epoch - 45ms/step
Epoch 77/1000
16/16 - 1s - loss: 0.0084 - r1: 0.4814 - r5: 0.7304 - r10: 0.8214 - p5: 0.1460 - p10: 0.0821 - val_loss: 0.0126 - val_r1: 0.3936 - val_r5: 0.6188 - val_r10: 0.7217 - val_p5: 0.1238 - val_p10: 0.0722 - lr: 4.6189e-04 - 712ms/epoch - 44ms/step
Epoch 78/1000
16/16 - 1s - loss: 0.0083 - r1: 0.4853 - r5: 0.7304 - r10: 0.8229 - p5: 0.1461 - p10: 0.0823 - val_loss: 0.0126 - val_r1: 0.3901 - val_r5: 0.6170 - val_r10: 0.7192 - val_p5: 0.1234 - val_p10: 0.0719 - lr: 4.6139e-04 - 716ms/epoch - 45ms/step
Epoch 79/1000
16/16 - 1s - loss: 0.0083 - r1: 0.4824 - r5: 0.7321 - r10: 0.8203 - p5: 0.1464 - p10: 0.0820 - val_loss: 0.0127 - val_r1: 0.3949 - val_r5: 0.6147 - val_r10: 0.7199 - val_p5: 0.1229 - val_p10: 0.0720 - lr: 4.6090e-04 - 714ms/epoch - 45ms/step
Epoch 80/1000
16/16 - 1s - loss: 0.0083 - r1: 0.4799 - r5: 0.7304 - r10: 0.8227 - p5: 0.1461 - p10: 0.0823 - val_loss: 0.0124 - val_r1: 0.3891 - val_r5: 0.6170 - val_r10: 0.7227 - val_p5: 0.1234 - val_p10: 0.0723 - lr: 4.6040e-04 - 721ms/epoch - 45ms/step
Epoch 81/1000
16/16 - 1s - loss: 0.0083 - r1: 0.4810 - r5: 0.7329 - r10: 0.8232 - p5: 0.1466 - p10: 0.0823 - val_loss: 0.0125 - val_r1: 0.3893 - val_r5: 0.6173 - val_r10: 0.7243 - val_p5: 0.1235 - val_p10: 0.0724 - lr: 4.5991e-04 - 721ms/epoch - 45ms/step
Epoch 82/1000
16/16 - 1s - loss: 0.0083 - r1: 0.4855 - r5: 0.7376 - r10: 0.8268 - p5: 0.1475 - p10: 0.0827 - val_loss: 0.0123 - val_r1: 0.3888 - val_r5: 0.6160 - val_r10: 0.7217 - val_p5: 0.1233 - val_p10: 0.0722 - lr: 4.5941e-04 - 711ms/epoch - 44ms/step
Epoch 83/1000
16/16 - 1s - loss: 0.0082 - r1: 0.4896 - r5: 0.7375 - r10: 0.8258 - p5: 0.1475 - p10: 0.0826 - val_loss: 0.0125 - val_r1: 0.3875 - val_r5: 0.6152 - val_r10: 0.7243 - val_p5: 0.1230 - val_p10: 0.0724 - lr: 4.5892e-04 - 717ms/epoch - 45ms/step
Epoch 83: early stopping
[92m[INFO] Loading best model...[0m
[93m[WARNING] Model folder already exists...[0m
Model: "ATT2ITM_1"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 162)]        0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 149)]        0           []                               
                                                                                                  
 embedding (Embedding)          (None, 162, 384)     926976      ['input_1[0][0]']                
                                                                                                  
 in_rsts (Embedding)            (None, 149, 384)     57216       ['input_2[0][0]']                
                                                                                                  
 dense (Dense)                  (None, 162, 256)     98560       ['embedding[0][0]']              
                                                                                                  
 dense_2 (Dense)                (None, 149, 256)     98560       ['in_rsts[0][0]']                
                                                                                                  
 tf.math.not_equal (TFOpLambda)  (None, 162)         0           ['input_1[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 162, 128)     32896       ['dense[0][0]']                  
                                                                                                  
 dense_3 (Dense)                (None, 149, 128)     32896       ['dense_2[0][0]']                
                                                                                                  
 tf.cast (TFOpLambda)           (None, 162)          0           ['tf.math.not_equal[0][0]']      
                                                                                                  
 word_emb (Lambda)              (None, 162, 128)     0           ['dense_1[0][0]']                
                                                                                                  
 rest_emb (Lambda)              (None, 149, 128)     0           ['dense_3[0][0]']                
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 162, 1)       0           ['tf.cast[0][0]']                
                                                                                                  
 lambda (Lambda)                (None, 162, 149)     0           ['word_emb[0][0]',               
                                                                  'rest_emb[0][0]']               
                                                                                                  
 tf.tile (TFOpLambda)           (None, 162, 149)     0           ['tf.expand_dims[0][0]']         
                                                                                                  
 lambda_1 (Lambda)              (None, 162, 149)     0           ['lambda[0][0]',                 
                                                                  'tf.tile[0][0]']                
                                                                                                  
 dotprod (Activation)           (None, 162, 149)     0           ['lambda_1[0][0]']               
                                                                                                  
 dropout (Dropout)              (None, 162, 149)     0           ['dotprod[0][0]']                
                                                                                                  
 sum (Lambda)                   (None, 149)          0           ['dropout[0][0]']                
                                                                                                  
 out (Activation)               (None, 149)          0           ['sum[0][0]']                    
                                                                                                  
==================================================================================================
Total params: 1,247,104
Trainable params: 1,247,104
Non-trainable params: 0
__________________________________________________________________________________________________
None
[92m[INFO] Model already trained. Loading weights...[0m
[93m[WARNING] Model folder already exists...[0m
Model: "ATT2ITM_1"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 162)]        0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 149)]        0           []                               
                                                                                                  
 embedding (Embedding)          (None, 162, 384)     926976      ['input_1[0][0]']                
                                                                                                  
 in_rsts (Embedding)            (None, 149, 384)     57216       ['input_2[0][0]']                
                                                                                                  
 dense (Dense)                  (None, 162, 256)     98560       ['embedding[0][0]']              
                                                                                                  
 dense_2 (Dense)                (None, 149, 256)     98560       ['in_rsts[0][0]']                
                                                                                                  
 tf.math.not_equal (TFOpLambda)  (None, 162)         0           ['input_1[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 162, 128)     32896       ['dense[0][0]']                  
                                                                                                  
 dense_3 (Dense)                (None, 149, 128)     32896       ['dense_2[0][0]']                
                                                                                                  
 tf.cast (TFOpLambda)           (None, 162)          0           ['tf.math.not_equal[0][0]']      
                                                                                                  
 word_emb (Lambda)              (None, 162, 128)     0           ['dense_1[0][0]']                
                                                                                                  
 rest_emb (Lambda)              (None, 149, 128)     0           ['dense_3[0][0]']                
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 162, 1)       0           ['tf.cast[0][0]']                
                                                                                                  
 lambda (Lambda)                (None, 162, 149)     0           ['word_emb[0][0]',               
                                                                  'rest_emb[0][0]']               
                                                                                                  
 tf.tile (TFOpLambda)           (None, 162, 149)     0           ['tf.expand_dims[0][0]']         
                                                                                                  
 lambda_1 (Lambda)              (None, 162, 149)     0           ['lambda[0][0]',                 
                                                                  'tf.tile[0][0]']                
                                                                                                  
 dotprod (Activation)           (None, 162, 149)     0           ['lambda_1[0][0]']               
                                                                                                  
 dropout (Dropout)              (None, 162, 149)     0           ['dotprod[0][0]']                
                                                                                                  
 sum (Lambda)                   (None, 149)          0           ['dropout[0][0]']                
                                                                                                  
 out (Activation)               (None, 149)          0           ['sum[0][0]']                    
                                                                                                  
==================================================================================================
Total params: 1,247,104
Trainable params: 1,247,104
Non-trainable params: 0
__________________________________________________________________________________________________
None
[92m[INFO] Model already trained. Loading weights...[0m
[93m[WARNING] Model folder already exists...[0m
Model: "ATT2ITM_1"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 162)]        0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 149)]        0           []                               
                                                                                                  
 embedding (Embedding)          (None, 162, 384)     926976      ['input_1[0][0]']                
                                                                                                  
 in_rsts (Embedding)            (None, 149, 384)     57216       ['input_2[0][0]']                
                                                                                                  
 dense (Dense)                  (None, 162, 256)     98560       ['embedding[0][0]']              
                                                                                                  
 dense_2 (Dense)                (None, 149, 256)     98560       ['in_rsts[0][0]']                
                                                                                                  
 tf.math.not_equal (TFOpLambda)  (None, 162)         0           ['input_1[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 162, 128)     32896       ['dense[0][0]']                  
                                                                                                  
 dense_3 (Dense)                (None, 149, 128)     32896       ['dense_2[0][0]']                
                                                                                                  
 tf.cast (TFOpLambda)           (None, 162)          0           ['tf.math.not_equal[0][0]']      
                                                                                                  
 word_emb (Lambda)              (None, 162, 128)     0           ['dense_1[0][0]']                
                                                                                                  
 rest_emb (Lambda)              (None, 149, 128)     0           ['dense_3[0][0]']                
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 162, 1)       0           ['tf.cast[0][0]']                
                                                                                                  
 lambda (Lambda)                (None, 162, 149)     0           ['word_emb[0][0]',               
                                                                  'rest_emb[0][0]']               
                                                                                                  
 tf.tile (TFOpLambda)           (None, 162, 149)     0           ['tf.expand_dims[0][0]']         
                                                                                                  
 lambda_1 (Lambda)              (None, 162, 149)     0           ['lambda[0][0]',                 
                                                                  'tf.tile[0][0]']                
                                                                                                  
 dotprod (Activation)           (None, 162, 149)     0           ['lambda_1[0][0]']               
                                                                                                  
 dropout (Dropout)              (None, 162, 149)     0           ['dotprod[0][0]']                
                                                                                                  
 sum (Lambda)                   (None, 149)          0           ['dropout[0][0]']                
                                                                                                  
 out (Activation)               (None, 149)          0           ['sum[0][0]']                    
                                                                                                  
==================================================================================================
Total params: 1,247,104
Trainable params: 1,247,104
Non-trainable params: 0
__________________________________________________________________________________________________
None
[92m[INFO] Model already trained. Loading weights...[0m
