Model: "ATT2ITM_0"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 172)]        0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 1322)]       0           []                               
                                                                                                  
 embedding (Embedding)          (None, 172, 384)     3389952     ['input_1[0][0]']                
                                                                                                  
 in_rsts (Embedding)            (None, 1322, 384)    507648      ['input_2[0][0]']                
                                                                                                  
 dense (Dense)                  (None, 172, 256)     98560       ['embedding[0][0]']              
                                                                                                  
 dense_2 (Dense)                (None, 1322, 256)    98560       ['in_rsts[0][0]']                
                                                                                                  
 tf.math.not_equal (TFOpLambda)  (None, 172)         0           ['input_1[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 172, 128)     32896       ['dense[0][0]']                  
                                                                                                  
 dense_3 (Dense)                (None, 1322, 128)    32896       ['dense_2[0][0]']                
                                                                                                  
 tf.cast (TFOpLambda)           (None, 172)          0           ['tf.math.not_equal[0][0]']      
                                                                                                  
 word_emb (Lambda)              (None, 172, 128)     0           ['dense_1[0][0]']                
                                                                                                  
 rest_emb (Lambda)              (None, 1322, 128)    0           ['dense_3[0][0]']                
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 172, 1)       0           ['tf.cast[0][0]']                
                                                                                                  
 lambda (Lambda)                (None, 172, 1322)    0           ['word_emb[0][0]',               
                                                                  'rest_emb[0][0]']               
                                                                                                  
 tf.tile (TFOpLambda)           (None, 172, 1322)    0           ['tf.expand_dims[0][0]']         
                                                                                                  
 lambda_1 (Lambda)              (None, 172, 1322)    0           ['lambda[0][0]',                 
                                                                  'tf.tile[0][0]']                
                                                                                                  
 dotprod (Activation)           (None, 172, 1322)    0           ['lambda_1[0][0]']               
                                                                                                  
 dropout (Dropout)              (None, 172, 1322)    0           ['dotprod[0][0]']                
                                                                                                  
 sum (Lambda)                   (None, 1322)         0           ['dropout[0][0]']                
                                                                                                  
 out (Activation)               (None, 1322)         0           ['sum[0][0]']                    
                                                                                                  
==================================================================================================
Total params: 4,160,512
Trainable params: 4,160,512
Non-trainable params: 0
__________________________________________________________________________________________________
None
Epoch 1/1000
502/502 - 27s - loss: 6.7033 - r1: 0.0232 - r5: 0.0649 - r10: 0.0971 - p5: 0.0130 - p10: 0.0097 - val_loss: 6.0140 - val_r1: 0.0771 - val_r5: 0.1746 - val_r10: 0.2394 - val_p5: 0.0349 - val_p10: 0.0239 - lr: 9.9901e-05 - 27s/epoch - 53ms/step
Epoch 2/1000
502/502 - 24s - loss: 5.7160 - r1: 0.0739 - r5: 0.1773 - r10: 0.2430 - p5: 0.0354 - p10: 0.0243 - val_loss: 5.2532 - val_r1: 0.1375 - val_r5: 0.2890 - val_r10: 0.3767 - val_p5: 0.0578 - val_p10: 0.0377 - lr: 9.9802e-05 - 24s/epoch - 48ms/step
Epoch 3/1000
502/502 - 24s - loss: 5.2352 - r1: 0.1112 - r5: 0.2474 - r10: 0.3275 - p5: 0.0495 - p10: 0.0328 - val_loss: 4.9048 - val_r1: 0.1766 - val_r5: 0.3512 - val_r10: 0.4411 - val_p5: 0.0702 - val_p10: 0.0441 - lr: 9.9703e-05 - 24s/epoch - 48ms/step
Epoch 4/1000
502/502 - 24s - loss: 5.0043 - r1: 0.1349 - r5: 0.2869 - r10: 0.3714 - p5: 0.0574 - p10: 0.0371 - val_loss: 4.7265 - val_r1: 0.1993 - val_r5: 0.3808 - val_r10: 0.4712 - val_p5: 0.0762 - val_p10: 0.0471 - lr: 9.9604e-05 - 24s/epoch - 49ms/step
Epoch 5/1000
502/502 - 24s - loss: 4.8598 - r1: 0.1512 - r5: 0.3112 - r10: 0.3984 - p5: 0.0622 - p10: 0.0398 - val_loss: 4.5257 - val_r1: 0.2250 - val_r5: 0.4148 - val_r10: 0.5034 - val_p5: 0.0830 - val_p10: 0.0503 - lr: 9.9505e-05 - 24s/epoch - 49ms/step
Epoch 6/1000
502/502 - 24s - loss: 4.7523 - r1: 0.1637 - r5: 0.3296 - r10: 0.4171 - p5: 0.0659 - p10: 0.0417 - val_loss: 4.5279 - val_r1: 0.2280 - val_r5: 0.4155 - val_r10: 0.5022 - val_p5: 0.0831 - val_p10: 0.0502 - lr: 9.9406e-05 - 24s/epoch - 48ms/step
Epoch 7/1000
502/502 - 24s - loss: 4.6715 - r1: 0.1739 - r5: 0.3438 - r10: 0.4329 - p5: 0.0688 - p10: 0.0433 - val_loss: 4.4542 - val_r1: 0.2367 - val_r5: 0.4267 - val_r10: 0.5138 - val_p5: 0.0854 - val_p10: 0.0514 - lr: 9.9307e-05 - 24s/epoch - 49ms/step
Epoch 8/1000
502/502 - 24s - loss: 4.6072 - r1: 0.1806 - r5: 0.3543 - r10: 0.4433 - p5: 0.0709 - p10: 0.0443 - val_loss: 4.4020 - val_r1: 0.2443 - val_r5: 0.4356 - val_r10: 0.5239 - val_p5: 0.0871 - val_p10: 0.0524 - lr: 9.9208e-05 - 24s/epoch - 49ms/step
Epoch 9/1000
502/502 - 25s - loss: 4.5443 - r1: 0.1906 - r5: 0.3656 - r10: 0.4545 - p5: 0.0731 - p10: 0.0455 - val_loss: 4.3013 - val_r1: 0.2594 - val_r5: 0.4520 - val_r10: 0.5391 - val_p5: 0.0904 - val_p10: 0.0539 - lr: 9.9109e-05 - 25s/epoch - 49ms/step
Epoch 10/1000
502/502 - 24s - loss: 4.4947 - r1: 0.1951 - r5: 0.3745 - r10: 0.4641 - p5: 0.0749 - p10: 0.0464 - val_loss: 4.3475 - val_r1: 0.2530 - val_r5: 0.4457 - val_r10: 0.5303 - val_p5: 0.0891 - val_p10: 0.0530 - lr: 9.9010e-05 - 24s/epoch - 48ms/step
Epoch 11/1000
502/502 - 24s - loss: 4.4501 - r1: 0.2007 - r5: 0.3811 - r10: 0.4706 - p5: 0.0762 - p10: 0.0471 - val_loss: 4.2898 - val_r1: 0.2615 - val_r5: 0.4533 - val_r10: 0.5379 - val_p5: 0.0907 - val_p10: 0.0538 - lr: 9.8911e-05 - 24s/epoch - 49ms/step
Epoch 12/1000
502/502 - 24s - loss: 4.4074 - r1: 0.2078 - r5: 0.3906 - r10: 0.4785 - p5: 0.0781 - p10: 0.0478 - val_loss: 4.2643 - val_r1: 0.2637 - val_r5: 0.4547 - val_r10: 0.5426 - val_p5: 0.0909 - val_p10: 0.0543 - lr: 9.8812e-05 - 24s/epoch - 49ms/step
Epoch 13/1000
502/502 - 24s - loss: 4.3731 - r1: 0.2113 - r5: 0.3960 - r10: 0.4851 - p5: 0.0792 - p10: 0.0485 - val_loss: 4.2443 - val_r1: 0.2666 - val_r5: 0.4573 - val_r10: 0.5424 - val_p5: 0.0915 - val_p10: 0.0542 - lr: 9.8713e-05 - 24s/epoch - 49ms/step
Epoch 14/1000
502/502 - 24s - loss: 4.3355 - r1: 0.2163 - r5: 0.4018 - r10: 0.4911 - p5: 0.0804 - p10: 0.0491 - val_loss: 4.1490 - val_r1: 0.2814 - val_r5: 0.4748 - val_r10: 0.5594 - val_p5: 0.0950 - val_p10: 0.0559 - lr: 9.8614e-05 - 24s/epoch - 49ms/step
Epoch 15/1000
502/502 - 24s - loss: 4.2934 - r1: 0.2222 - r5: 0.4091 - r10: 0.4984 - p5: 0.0818 - p10: 0.0498 - val_loss: 4.1972 - val_r1: 0.2710 - val_r5: 0.4648 - val_r10: 0.5493 - val_p5: 0.0930 - val_p10: 0.0549 - lr: 9.8515e-05 - 24s/epoch - 48ms/step
Epoch 16/1000
502/502 - 24s - loss: 4.2695 - r1: 0.2241 - r5: 0.4130 - r10: 0.5032 - p5: 0.0826 - p10: 0.0503 - val_loss: 4.1844 - val_r1: 0.2744 - val_r5: 0.4664 - val_r10: 0.5509 - val_p5: 0.0933 - val_p10: 0.0551 - lr: 9.8416e-05 - 24s/epoch - 48ms/step
Epoch 17/1000
502/502 - 24s - loss: 4.2423 - r1: 0.2284 - r5: 0.4176 - r10: 0.5075 - p5: 0.0835 - p10: 0.0508 - val_loss: 4.1586 - val_r1: 0.2784 - val_r5: 0.4715 - val_r10: 0.5550 - val_p5: 0.0943 - val_p10: 0.0555 - lr: 9.8317e-05 - 24s/epoch - 48ms/step
Epoch 18/1000
502/502 - 24s - loss: 4.2169 - r1: 0.2317 - r5: 0.4221 - r10: 0.5112 - p5: 0.0844 - p10: 0.0511 - val_loss: 4.0791 - val_r1: 0.2905 - val_r5: 0.4832 - val_r10: 0.5682 - val_p5: 0.0967 - val_p10: 0.0568 - lr: 9.8218e-05 - 24s/epoch - 49ms/step
Epoch 19/1000
502/502 - 24s - loss: 4.1893 - r1: 0.2360 - r5: 0.4270 - r10: 0.5157 - p5: 0.0854 - p10: 0.0516 - val_loss: 4.1324 - val_r1: 0.2822 - val_r5: 0.4748 - val_r10: 0.5574 - val_p5: 0.0950 - val_p10: 0.0557 - lr: 9.8119e-05 - 24s/epoch - 48ms/step
Epoch 20/1000
502/502 - 24s - loss: 4.1637 - r1: 0.2383 - r5: 0.4308 - r10: 0.5207 - p5: 0.0862 - p10: 0.0521 - val_loss: 4.1234 - val_r1: 0.2816 - val_r5: 0.4751 - val_r10: 0.5594 - val_p5: 0.0950 - val_p10: 0.0559 - lr: 9.8020e-05 - 24s/epoch - 48ms/step
Epoch 21/1000
502/502 - 24s - loss: 4.1453 - r1: 0.2412 - r5: 0.4333 - r10: 0.5227 - p5: 0.0867 - p10: 0.0523 - val_loss: 4.1025 - val_r1: 0.2865 - val_r5: 0.4761 - val_r10: 0.5612 - val_p5: 0.0952 - val_p10: 0.0561 - lr: 9.7921e-05 - 24s/epoch - 48ms/step
Epoch 22/1000
502/502 - 24s - loss: 4.1213 - r1: 0.2447 - r5: 0.4380 - r10: 0.5270 - p5: 0.0876 - p10: 0.0527 - val_loss: 4.0326 - val_r1: 0.2961 - val_r5: 0.4910 - val_r10: 0.5722 - val_p5: 0.0982 - val_p10: 0.0572 - lr: 9.7822e-05 - 24s/epoch - 49ms/step
Epoch 23/1000
502/502 - 24s - loss: 4.0976 - r1: 0.2474 - r5: 0.4420 - r10: 0.5314 - p5: 0.0884 - p10: 0.0531 - val_loss: 4.0794 - val_r1: 0.2897 - val_r5: 0.4814 - val_r10: 0.5650 - val_p5: 0.0963 - val_p10: 0.0565 - lr: 9.7723e-05 - 24s/epoch - 48ms/step
Epoch 24/1000
502/502 - 24s - loss: 4.0774 - r1: 0.2500 - r5: 0.4459 - r10: 0.5341 - p5: 0.0892 - p10: 0.0534 - val_loss: 4.0660 - val_r1: 0.2918 - val_r5: 0.4839 - val_r10: 0.5659 - val_p5: 0.0968 - val_p10: 0.0566 - lr: 9.7624e-05 - 24s/epoch - 48ms/step
Epoch 25/1000
502/502 - 24s - loss: 4.0555 - r1: 0.2525 - r5: 0.4490 - r10: 0.5379 - p5: 0.0898 - p10: 0.0538 - val_loss: 4.0714 - val_r1: 0.2896 - val_r5: 0.4814 - val_r10: 0.5640 - val_p5: 0.0963 - val_p10: 0.0564 - lr: 9.7525e-05 - 24s/epoch - 48ms/step
Epoch 26/1000
502/502 - 24s - loss: 4.0431 - r1: 0.2544 - r5: 0.4514 - r10: 0.5395 - p5: 0.0903 - p10: 0.0539 - val_loss: 4.0020 - val_r1: 0.2995 - val_r5: 0.4934 - val_r10: 0.5750 - val_p5: 0.0987 - val_p10: 0.0575 - lr: 9.7426e-05 - 24s/epoch - 49ms/step
Epoch 27/1000
502/502 - 24s - loss: 4.0209 - r1: 0.2578 - r5: 0.4548 - r10: 0.5434 - p5: 0.0910 - p10: 0.0543 - val_loss: 4.0439 - val_r1: 0.2915 - val_r5: 0.4854 - val_r10: 0.5684 - val_p5: 0.0971 - val_p10: 0.0568 - lr: 9.7327e-05 - 24s/epoch - 48ms/step
Epoch 28/1000
502/502 - 24s - loss: 4.0085 - r1: 0.2588 - r5: 0.4565 - r10: 0.5451 - p5: 0.0913 - p10: 0.0545 - val_loss: 4.0427 - val_r1: 0.2929 - val_r5: 0.4841 - val_r10: 0.5671 - val_p5: 0.0969 - val_p10: 0.0567 - lr: 9.7228e-05 - 24s/epoch - 48ms/step
Epoch 29/1000
502/502 - 24s - loss: 3.9861 - r1: 0.2626 - r5: 0.4609 - r10: 0.5492 - p5: 0.0922 - p10: 0.0549 - val_loss: 4.0444 - val_r1: 0.2919 - val_r5: 0.4851 - val_r10: 0.5670 - val_p5: 0.0970 - val_p10: 0.0567 - lr: 9.7129e-05 - 24s/epoch - 48ms/step
Epoch 30/1000
502/502 - 24s - loss: 3.9704 - r1: 0.2642 - r5: 0.4631 - r10: 0.5521 - p5: 0.0926 - p10: 0.0552 - val_loss: 3.9860 - val_r1: 0.3001 - val_r5: 0.4942 - val_r10: 0.5754 - val_p5: 0.0988 - val_p10: 0.0575 - lr: 9.7030e-05 - 24s/epoch - 49ms/step
Epoch 31/1000
502/502 - 24s - loss: 3.9525 - r1: 0.2651 - r5: 0.4659 - r10: 0.5540 - p5: 0.0932 - p10: 0.0554 - val_loss: 4.0348 - val_r1: 0.2914 - val_r5: 0.4859 - val_r10: 0.5671 - val_p5: 0.0972 - val_p10: 0.0567 - lr: 9.6931e-05 - 24s/epoch - 48ms/step
Epoch 32/1000
502/502 - 24s - loss: 3.9359 - r1: 0.2682 - r5: 0.4685 - r10: 0.5565 - p5: 0.0937 - p10: 0.0556 - val_loss: 4.0234 - val_r1: 0.2941 - val_r5: 0.4862 - val_r10: 0.5691 - val_p5: 0.0972 - val_p10: 0.0569 - lr: 9.6832e-05 - 24s/epoch - 48ms/step
Epoch 33/1000
502/502 - 24s - loss: 3.9263 - r1: 0.2694 - r5: 0.4701 - r10: 0.5580 - p5: 0.0940 - p10: 0.0558 - val_loss: 4.0271 - val_r1: 0.2945 - val_r5: 0.4829 - val_r10: 0.5663 - val_p5: 0.0966 - val_p10: 0.0566 - lr: 9.6733e-05 - 24s/epoch - 48ms/step
Epoch 34/1000
502/502 - 24s - loss: 3.9065 - r1: 0.2724 - r5: 0.4737 - r10: 0.5623 - p5: 0.0947 - p10: 0.0562 - val_loss: 3.9696 - val_r1: 0.3026 - val_r5: 0.4937 - val_r10: 0.5772 - val_p5: 0.0987 - val_p10: 0.0577 - lr: 9.6634e-05 - 24s/epoch - 49ms/step
Epoch 35/1000
502/502 - 24s - loss: 3.8900 - r1: 0.2746 - r5: 0.4756 - r10: 0.5639 - p5: 0.0951 - p10: 0.0564 - val_loss: 4.0102 - val_r1: 0.2965 - val_r5: 0.4862 - val_r10: 0.5701 - val_p5: 0.0972 - val_p10: 0.0570 - lr: 9.6535e-05 - 24s/epoch - 48ms/step
Epoch 36/1000
502/502 - 24s - loss: 3.8763 - r1: 0.2762 - r5: 0.4793 - r10: 0.5667 - p5: 0.0959 - p10: 0.0567 - val_loss: 4.0123 - val_r1: 0.2956 - val_r5: 0.4866 - val_r10: 0.5673 - val_p5: 0.0973 - val_p10: 0.0567 - lr: 9.6436e-05 - 24s/epoch - 48ms/step
Epoch 37/1000
502/502 - 24s - loss: 3.8616 - r1: 0.2790 - r5: 0.4807 - r10: 0.5691 - p5: 0.0961 - p10: 0.0569 - val_loss: 4.0021 - val_r1: 0.2970 - val_r5: 0.4887 - val_r10: 0.5707 - val_p5: 0.0978 - val_p10: 0.0571 - lr: 9.6337e-05 - 24s/epoch - 48ms/step
Epoch 38/1000
502/502 - 24s - loss: 3.8522 - r1: 0.2802 - r5: 0.4828 - r10: 0.5701 - p5: 0.0966 - p10: 0.0570 - val_loss: 3.9468 - val_r1: 0.3040 - val_r5: 0.4957 - val_r10: 0.5796 - val_p5: 0.0991 - val_p10: 0.0580 - lr: 9.6238e-05 - 24s/epoch - 49ms/step
Epoch 39/1000
502/502 - 24s - loss: 3.8348 - r1: 0.2814 - r5: 0.4842 - r10: 0.5730 - p5: 0.0968 - p10: 0.0573 - val_loss: 4.0001 - val_r1: 0.2975 - val_r5: 0.4882 - val_r10: 0.5700 - val_p5: 0.0976 - val_p10: 0.0570 - lr: 9.6139e-05 - 24s/epoch - 48ms/step
Epoch 40/1000
502/502 - 24s - loss: 3.8250 - r1: 0.2829 - r5: 0.4869 - r10: 0.5746 - p5: 0.0974 - p10: 0.0575 - val_loss: 3.9881 - val_r1: 0.2995 - val_r5: 0.4898 - val_r10: 0.5735 - val_p5: 0.0980 - val_p10: 0.0574 - lr: 9.6040e-05 - 24s/epoch - 48ms/step
Epoch 41/1000
502/502 - 24s - loss: 3.8104 - r1: 0.2850 - r5: 0.4889 - r10: 0.5770 - p5: 0.0978 - p10: 0.0577 - val_loss: 3.9898 - val_r1: 0.2985 - val_r5: 0.4888 - val_r10: 0.5707 - val_p5: 0.0978 - val_p10: 0.0571 - lr: 9.5941e-05 - 24s/epoch - 48ms/step
Epoch 42/1000
502/502 - 24s - loss: 3.7974 - r1: 0.2871 - r5: 0.4907 - r10: 0.5793 - p5: 0.0982 - p10: 0.0579 - val_loss: 3.9813 - val_r1: 0.2985 - val_r5: 0.4899 - val_r10: 0.5721 - val_p5: 0.0980 - val_p10: 0.0572 - lr: 9.5842e-05 - 24s/epoch - 48ms/step
Epoch 43/1000
502/502 - 24s - loss: 3.7860 - r1: 0.2886 - r5: 0.4927 - r10: 0.5804 - p5: 0.0985 - p10: 0.0580 - val_loss: 3.9503 - val_r1: 0.3042 - val_r5: 0.4941 - val_r10: 0.5766 - val_p5: 0.0988 - val_p10: 0.0577 - lr: 9.5743e-05 - 24s/epoch - 48ms/step
Epoch 44/1000
502/502 - 24s - loss: 3.7667 - r1: 0.2901 - r5: 0.4959 - r10: 0.5840 - p5: 0.0992 - p10: 0.0584 - val_loss: 3.9695 - val_r1: 0.3013 - val_r5: 0.4926 - val_r10: 0.5728 - val_p5: 0.0985 - val_p10: 0.0573 - lr: 9.5644e-05 - 24s/epoch - 48ms/step
Epoch 45/1000
502/502 - 24s - loss: 3.7577 - r1: 0.2917 - r5: 0.4978 - r10: 0.5851 - p5: 0.0996 - p10: 0.0585 - val_loss: 3.9650 - val_r1: 0.3005 - val_r5: 0.4945 - val_r10: 0.5733 - val_p5: 0.0989 - val_p10: 0.0573 - lr: 9.5545e-05 - 24s/epoch - 48ms/step
Epoch 46/1000
502/502 - 24s - loss: 3.7506 - r1: 0.2939 - r5: 0.4990 - r10: 0.5868 - p5: 0.0998 - p10: 0.0587 - val_loss: 3.9595 - val_r1: 0.3014 - val_r5: 0.4936 - val_r10: 0.5736 - val_p5: 0.0987 - val_p10: 0.0574 - lr: 9.5446e-05 - 24s/epoch - 48ms/step
Epoch 47/1000
502/502 - 24s - loss: 3.7345 - r1: 0.2959 - r5: 0.5015 - r10: 0.5884 - p5: 0.1003 - p10: 0.0588 - val_loss: 3.9649 - val_r1: 0.3024 - val_r5: 0.4929 - val_r10: 0.5730 - val_p5: 0.0986 - val_p10: 0.0573 - lr: 9.5347e-05 - 24s/epoch - 48ms/step
Epoch 48/1000
502/502 - 25s - loss: 3.7241 - r1: 0.2964 - r5: 0.5038 - r10: 0.5912 - p5: 0.1008 - p10: 0.0591 - val_loss: 3.9292 - val_r1: 0.3066 - val_r5: 0.4979 - val_r10: 0.5780 - val_p5: 0.0996 - val_p10: 0.0578 - lr: 9.5248e-05 - 25s/epoch - 49ms/step
Epoch 49/1000
502/502 - 24s - loss: 3.7164 - r1: 0.2972 - r5: 0.5041 - r10: 0.5923 - p5: 0.1008 - p10: 0.0592 - val_loss: 3.9725 - val_r1: 0.3004 - val_r5: 0.4910 - val_r10: 0.5720 - val_p5: 0.0982 - val_p10: 0.0572 - lr: 9.5149e-05 - 24s/epoch - 48ms/step
Epoch 50/1000
502/502 - 24s - loss: 3.7044 - r1: 0.2989 - r5: 0.5075 - r10: 0.5936 - p5: 0.1015 - p10: 0.0594 - val_loss: 3.9688 - val_r1: 0.3005 - val_r5: 0.4915 - val_r10: 0.5718 - val_p5: 0.0983 - val_p10: 0.0572 - lr: 9.5050e-05 - 24s/epoch - 48ms/step
Epoch 51/1000
502/502 - 24s - loss: 3.6903 - r1: 0.3010 - r5: 0.5087 - r10: 0.5960 - p5: 0.1017 - p10: 0.0596 - val_loss: 3.9531 - val_r1: 0.3032 - val_r5: 0.4944 - val_r10: 0.5744 - val_p5: 0.0989 - val_p10: 0.0574 - lr: 9.4951e-05 - 24s/epoch - 48ms/step
Epoch 52/1000
502/502 - 24s - loss: 3.6881 - r1: 0.3005 - r5: 0.5089 - r10: 0.5963 - p5: 0.1018 - p10: 0.0596 - val_loss: 3.9226 - val_r1: 0.3076 - val_r5: 0.4991 - val_r10: 0.5780 - val_p5: 0.0998 - val_p10: 0.0578 - lr: 9.4852e-05 - 24s/epoch - 49ms/step
Epoch 53/1000
502/502 - 24s - loss: 3.6737 - r1: 0.3026 - r5: 0.5122 - r10: 0.5991 - p5: 0.1024 - p10: 0.0599 - val_loss: 3.9604 - val_r1: 0.3008 - val_r5: 0.4932 - val_r10: 0.5739 - val_p5: 0.0986 - val_p10: 0.0574 - lr: 9.4753e-05 - 24s/epoch - 48ms/step
Epoch 54/1000
502/502 - 24s - loss: 3.6637 - r1: 0.3045 - r5: 0.5126 - r10: 0.6004 - p5: 0.1025 - p10: 0.0600 - val_loss: 3.9609 - val_r1: 0.2998 - val_r5: 0.4937 - val_r10: 0.5736 - val_p5: 0.0987 - val_p10: 0.0574 - lr: 9.4654e-05 - 24s/epoch - 48ms/step
Epoch 55/1000
502/502 - 24s - loss: 3.6512 - r1: 0.3058 - r5: 0.5150 - r10: 0.6009 - p5: 0.1030 - p10: 0.0601 - val_loss: 3.9615 - val_r1: 0.3016 - val_r5: 0.4936 - val_r10: 0.5716 - val_p5: 0.0987 - val_p10: 0.0572 - lr: 9.4555e-05 - 24s/epoch - 48ms/step
Epoch 56/1000
502/502 - 24s - loss: 3.6409 - r1: 0.3067 - r5: 0.5162 - r10: 0.6032 - p5: 0.1032 - p10: 0.0603 - val_loss: 3.9225 - val_r1: 0.3071 - val_r5: 0.4960 - val_r10: 0.5770 - val_p5: 0.0992 - val_p10: 0.0577 - lr: 9.4456e-05 - 24s/epoch - 49ms/step
Epoch 57/1000
502/502 - 24s - loss: 3.6343 - r1: 0.3081 - r5: 0.5175 - r10: 0.6053 - p5: 0.1035 - p10: 0.0605 - val_loss: 3.9611 - val_r1: 0.3004 - val_r5: 0.4913 - val_r10: 0.5704 - val_p5: 0.0983 - val_p10: 0.0570 - lr: 9.4357e-05 - 24s/epoch - 48ms/step
Epoch 58/1000
502/502 - 24s - loss: 3.6313 - r1: 0.3088 - r5: 0.5173 - r10: 0.6046 - p5: 0.1035 - p10: 0.0605 - val_loss: 3.9529 - val_r1: 0.3016 - val_r5: 0.4916 - val_r10: 0.5729 - val_p5: 0.0983 - val_p10: 0.0573 - lr: 9.4258e-05 - 24s/epoch - 48ms/step
Epoch 59/1000
502/502 - 24s - loss: 3.6151 - r1: 0.3113 - r5: 0.5203 - r10: 0.6074 - p5: 0.1041 - p10: 0.0607 - val_loss: 3.9524 - val_r1: 0.3017 - val_r5: 0.4939 - val_r10: 0.5726 - val_p5: 0.0988 - val_p10: 0.0573 - lr: 9.4159e-05 - 24s/epoch - 48ms/step
Epoch 60/1000
502/502 - 24s - loss: 3.6053 - r1: 0.3127 - r5: 0.5224 - r10: 0.6089 - p5: 0.1045 - p10: 0.0609 - val_loss: 3.9119 - val_r1: 0.3082 - val_r5: 0.5008 - val_r10: 0.5784 - val_p5: 0.1001 - val_p10: 0.0579 - lr: 9.4060e-05 - 24s/epoch - 49ms/step
Epoch 61/1000
502/502 - 24s - loss: 3.5927 - r1: 0.3149 - r5: 0.5241 - r10: 0.6105 - p5: 0.1048 - p10: 0.0610 - val_loss: 3.9477 - val_r1: 0.3037 - val_r5: 0.4947 - val_r10: 0.5748 - val_p5: 0.0989 - val_p10: 0.0575 - lr: 9.3961e-05 - 24s/epoch - 48ms/step
Epoch 62/1000
502/502 - 24s - loss: 3.5818 - r1: 0.3162 - r5: 0.5263 - r10: 0.6129 - p5: 0.1053 - p10: 0.0613 - val_loss: 3.9412 - val_r1: 0.3021 - val_r5: 0.4953 - val_r10: 0.5754 - val_p5: 0.0991 - val_p10: 0.0575 - lr: 9.3862e-05 - 24s/epoch - 48ms/step
Epoch 63/1000
502/502 - 24s - loss: 3.5743 - r1: 0.3172 - r5: 0.5280 - r10: 0.6148 - p5: 0.1056 - p10: 0.0615 - val_loss: 3.9487 - val_r1: 0.3020 - val_r5: 0.4938 - val_r10: 0.5742 - val_p5: 0.0988 - val_p10: 0.0574 - lr: 9.3763e-05 - 24s/epoch - 48ms/step
Epoch 64/1000
502/502 - 24s - loss: 3.5737 - r1: 0.3155 - r5: 0.5274 - r10: 0.6139 - p5: 0.1055 - p10: 0.0614 - val_loss: 3.9116 - val_r1: 0.3070 - val_r5: 0.5004 - val_r10: 0.5806 - val_p5: 0.1001 - val_p10: 0.0581 - lr: 9.3664e-05 - 24s/epoch - 49ms/step
Epoch 65/1000
502/502 - 24s - loss: 3.5586 - r1: 0.3190 - r5: 0.5296 - r10: 0.6162 - p5: 0.1059 - p10: 0.0616 - val_loss: 3.9433 - val_r1: 0.3027 - val_r5: 0.4936 - val_r10: 0.5740 - val_p5: 0.0987 - val_p10: 0.0574 - lr: 9.3565e-05 - 24s/epoch - 48ms/step
Epoch 66/1000
502/502 - 24s - loss: 3.5549 - r1: 0.3181 - r5: 0.5308 - r10: 0.6168 - p5: 0.1062 - p10: 0.0617 - val_loss: 3.9468 - val_r1: 0.3005 - val_r5: 0.4924 - val_r10: 0.5737 - val_p5: 0.0985 - val_p10: 0.0574 - lr: 9.3466e-05 - 24s/epoch - 48ms/step
Epoch 67/1000
502/502 - 24s - loss: 3.5466 - r1: 0.3203 - r5: 0.5327 - r10: 0.6184 - p5: 0.1065 - p10: 0.0618 - val_loss: 3.9405 - val_r1: 0.3027 - val_r5: 0.4948 - val_r10: 0.5720 - val_p5: 0.0990 - val_p10: 0.0572 - lr: 9.3367e-05 - 24s/epoch - 48ms/step
Epoch 68/1000
502/502 - 24s - loss: 3.5409 - r1: 0.3213 - r5: 0.5323 - r10: 0.6188 - p5: 0.1065 - p10: 0.0619 - val_loss: 3.9108 - val_r1: 0.3073 - val_r5: 0.5001 - val_r10: 0.5782 - val_p5: 0.1000 - val_p10: 0.0578 - lr: 9.3268e-05 - 24s/epoch - 49ms/step
Epoch 69/1000
502/502 - 24s - loss: 3.5310 - r1: 0.3225 - r5: 0.5345 - r10: 0.6200 - p5: 0.1069 - p10: 0.0620 - val_loss: 3.9493 - val_r1: 0.3008 - val_r5: 0.4928 - val_r10: 0.5730 - val_p5: 0.0985 - val_p10: 0.0573 - lr: 9.3169e-05 - 24s/epoch - 48ms/step
Epoch 70/1000
502/502 - 24s - loss: 3.5234 - r1: 0.3236 - r5: 0.5352 - r10: 0.6215 - p5: 0.1070 - p10: 0.0622 - val_loss: 3.9475 - val_r1: 0.3019 - val_r5: 0.4935 - val_r10: 0.5739 - val_p5: 0.0987 - val_p10: 0.0574 - lr: 9.3070e-05 - 24s/epoch - 48ms/step
Epoch 71/1000
502/502 - 24s - loss: 3.5116 - r1: 0.3244 - r5: 0.5368 - r10: 0.6235 - p5: 0.1074 - p10: 0.0624 - val_loss: 3.9459 - val_r1: 0.3035 - val_r5: 0.4925 - val_r10: 0.5731 - val_p5: 0.0985 - val_p10: 0.0573 - lr: 9.2971e-05 - 24s/epoch - 48ms/step
Epoch 72/1000
502/502 - 24s - loss: 3.5066 - r1: 0.3261 - r5: 0.5389 - r10: 0.6240 - p5: 0.1078 - p10: 0.0624 - val_loss: 3.9445 - val_r1: 0.3017 - val_r5: 0.4936 - val_r10: 0.5730 - val_p5: 0.0987 - val_p10: 0.0573 - lr: 9.2872e-05 - 24s/epoch - 48ms/step
Epoch 73/1000
502/502 - 24s - loss: 3.4918 - r1: 0.3282 - r5: 0.5402 - r10: 0.6266 - p5: 0.1080 - p10: 0.0627 - val_loss: 3.9111 - val_r1: 0.3067 - val_r5: 0.4976 - val_r10: 0.5775 - val_p5: 0.0995 - val_p10: 0.0577 - lr: 9.2773e-05 - 24s/epoch - 48ms/step
Epoch 74/1000
502/502 - 24s - loss: 3.4892 - r1: 0.3276 - r5: 0.5408 - r10: 0.6257 - p5: 0.1082 - p10: 0.0626 - val_loss: 3.9371 - val_r1: 0.3024 - val_r5: 0.4936 - val_r10: 0.5729 - val_p5: 0.0987 - val_p10: 0.0573 - lr: 9.2674e-05 - 24s/epoch - 48ms/step
Epoch 75/1000
502/502 - 24s - loss: 3.4822 - r1: 0.3289 - r5: 0.5419 - r10: 0.6278 - p5: 0.1084 - p10: 0.0628 - val_loss: 3.9448 - val_r1: 0.3046 - val_r5: 0.4931 - val_r10: 0.5717 - val_p5: 0.0986 - val_p10: 0.0572 - lr: 9.2575e-05 - 24s/epoch - 48ms/step
Epoch 76/1000
502/502 - 24s - loss: 3.4759 - r1: 0.3305 - r5: 0.5421 - r10: 0.6283 - p5: 0.1084 - p10: 0.0628 - val_loss: 3.9413 - val_r1: 0.3041 - val_r5: 0.4935 - val_r10: 0.5735 - val_p5: 0.0987 - val_p10: 0.0573 - lr: 9.2476e-05 - 24s/epoch - 48ms/step
Epoch 77/1000
502/502 - 24s - loss: 3.4719 - r1: 0.3307 - r5: 0.5432 - r10: 0.6293 - p5: 0.1086 - p10: 0.0629 - val_loss: 3.9132 - val_r1: 0.3073 - val_r5: 0.4968 - val_r10: 0.5770 - val_p5: 0.0994 - val_p10: 0.0577 - lr: 9.2377e-05 - 24s/epoch - 48ms/step
Epoch 78/1000
502/502 - 24s - loss: 3.4572 - r1: 0.3325 - r5: 0.5459 - r10: 0.6314 - p5: 0.1092 - p10: 0.0631 - val_loss: 3.9459 - val_r1: 0.3021 - val_r5: 0.4914 - val_r10: 0.5722 - val_p5: 0.0983 - val_p10: 0.0572 - lr: 9.2278e-05 - 24s/epoch - 48ms/step
Epoch 79/1000
502/502 - 24s - loss: 3.4576 - r1: 0.3329 - r5: 0.5451 - r10: 0.6308 - p5: 0.1090 - p10: 0.0631 - val_loss: 3.9411 - val_r1: 0.3022 - val_r5: 0.4937 - val_r10: 0.5738 - val_p5: 0.0987 - val_p10: 0.0574 - lr: 9.2179e-05 - 24s/epoch - 48ms/step
Epoch 80/1000
502/502 - 24s - loss: 3.4497 - r1: 0.3340 - r5: 0.5465 - r10: 0.6325 - p5: 0.1093 - p10: 0.0632 - val_loss: 3.9486 - val_r1: 0.3034 - val_r5: 0.4913 - val_r10: 0.5712 - val_p5: 0.0983 - val_p10: 0.0571 - lr: 9.2080e-05 - 24s/epoch - 48ms/step
Epoch 81/1000
502/502 - 24s - loss: 3.4373 - r1: 0.3356 - r5: 0.5491 - r10: 0.6343 - p5: 0.1098 - p10: 0.0634 - val_loss: 3.9145 - val_r1: 0.3083 - val_r5: 0.4968 - val_r10: 0.5762 - val_p5: 0.0994 - val_p10: 0.0576 - lr: 9.1981e-05 - 24s/epoch - 48ms/step
Epoch 82/1000
502/502 - 24s - loss: 3.4358 - r1: 0.3354 - r5: 0.5501 - r10: 0.6352 - p5: 0.1100 - p10: 0.0635 - val_loss: 3.9403 - val_r1: 0.3043 - val_r5: 0.4933 - val_r10: 0.5737 - val_p5: 0.0987 - val_p10: 0.0574 - lr: 9.1882e-05 - 24s/epoch - 48ms/step
Epoch 83/1000
502/502 - 24s - loss: 3.4258 - r1: 0.3367 - r5: 0.5508 - r10: 0.6358 - p5: 0.1102 - p10: 0.0636 - val_loss: 3.9338 - val_r1: 0.3039 - val_r5: 0.4939 - val_r10: 0.5736 - val_p5: 0.0988 - val_p10: 0.0574 - lr: 9.1783e-05 - 24s/epoch - 48ms/step
Epoch 84/1000
502/502 - 24s - loss: 3.4197 - r1: 0.3371 - r5: 0.5526 - r10: 0.6378 - p5: 0.1105 - p10: 0.0638 - val_loss: 3.9491 - val_r1: 0.3018 - val_r5: 0.4904 - val_r10: 0.5722 - val_p5: 0.0981 - val_p10: 0.0572 - lr: 9.1684e-05 - 24s/epoch - 48ms/step
Epoch 85/1000
502/502 - 24s - loss: 3.4148 - r1: 0.3377 - r5: 0.5531 - r10: 0.6391 - p5: 0.1106 - p10: 0.0639 - val_loss: 3.9241 - val_r1: 0.3059 - val_r5: 0.4937 - val_r10: 0.5754 - val_p5: 0.0987 - val_p10: 0.0575 - lr: 9.1585e-05 - 24s/epoch - 48ms/step
Epoch 86/1000
502/502 - 24s - loss: 3.4089 - r1: 0.3394 - r5: 0.5538 - r10: 0.6387 - p5: 0.1107 - p10: 0.0639 - val_loss: 3.9544 - val_r1: 0.3005 - val_r5: 0.4919 - val_r10: 0.5708 - val_p5: 0.0984 - val_p10: 0.0571 - lr: 9.1486e-05 - 24s/epoch - 48ms/step
Epoch 87/1000
502/502 - 24s - loss: 3.3992 - r1: 0.3413 - r5: 0.5556 - r10: 0.6399 - p5: 0.1111 - p10: 0.0640 - val_loss: 3.9531 - val_r1: 0.3004 - val_r5: 0.4913 - val_r10: 0.5714 - val_p5: 0.0983 - val_p10: 0.0572 - lr: 9.1387e-05 - 24s/epoch - 48ms/step
Epoch 88/1000
502/502 - 24s - loss: 3.3959 - r1: 0.3410 - r5: 0.5560 - r10: 0.6414 - p5: 0.1112 - p10: 0.0641 - val_loss: 3.9521 - val_r1: 0.3015 - val_r5: 0.4917 - val_r10: 0.5721 - val_p5: 0.0983 - val_p10: 0.0572 - lr: 9.1288e-05 - 24s/epoch - 48ms/step
Epoch 89/1000
502/502 - 24s - loss: 3.3883 - r1: 0.3412 - r5: 0.5568 - r10: 0.6425 - p5: 0.1114 - p10: 0.0643 - val_loss: 3.9247 - val_r1: 0.3046 - val_r5: 0.4963 - val_r10: 0.5745 - val_p5: 0.0993 - val_p10: 0.0574 - lr: 9.1189e-05 - 24s/epoch - 48ms/step
Epoch 90/1000
502/502 - 24s - loss: 3.3824 - r1: 0.3423 - r5: 0.5572 - r10: 0.6429 - p5: 0.1114 - p10: 0.0643 - val_loss: 3.9536 - val_r1: 0.3018 - val_r5: 0.4895 - val_r10: 0.5701 - val_p5: 0.0979 - val_p10: 0.0570 - lr: 9.1090e-05 - 24s/epoch - 48ms/step
Epoch 91/1000
502/502 - 24s - loss: 3.3741 - r1: 0.3436 - r5: 0.5594 - r10: 0.6442 - p5: 0.1119 - p10: 0.0644 - val_loss: 3.9567 - val_r1: 0.3017 - val_r5: 0.4891 - val_r10: 0.5706 - val_p5: 0.0978 - val_p10: 0.0571 - lr: 9.0991e-05 - 24s/epoch - 48ms/step
Epoch 92/1000
502/502 - 24s - loss: 3.3734 - r1: 0.3442 - r5: 0.5600 - r10: 0.6443 - p5: 0.1120 - p10: 0.0644 - val_loss: 3.9503 - val_r1: 0.3018 - val_r5: 0.4911 - val_r10: 0.5715 - val_p5: 0.0982 - val_p10: 0.0572 - lr: 9.0892e-05 - 24s/epoch - 48ms/step
Epoch 93/1000
502/502 - 24s - loss: 3.3646 - r1: 0.3445 - r5: 0.5609 - r10: 0.6457 - p5: 0.1122 - p10: 0.0646 - val_loss: 3.9261 - val_r1: 0.3059 - val_r5: 0.4940 - val_r10: 0.5750 - val_p5: 0.0988 - val_p10: 0.0575 - lr: 9.0793e-05 - 24s/epoch - 48ms/step
Epoch 94/1000
502/502 - 24s - loss: 3.3557 - r1: 0.3466 - r5: 0.5627 - r10: 0.6468 - p5: 0.1126 - p10: 0.0647 - val_loss: 3.9536 - val_r1: 0.3007 - val_r5: 0.4890 - val_r10: 0.5683 - val_p5: 0.0978 - val_p10: 0.0568 - lr: 9.0694e-05 - 24s/epoch - 48ms/step
Epoch 95/1000
502/502 - 24s - loss: 3.3545 - r1: 0.3475 - r5: 0.5625 - r10: 0.6465 - p5: 0.1125 - p10: 0.0647 - val_loss: 3.9544 - val_r1: 0.3019 - val_r5: 0.4901 - val_r10: 0.5700 - val_p5: 0.0980 - val_p10: 0.0570 - lr: 9.0595e-05 - 24s/epoch - 48ms/step
Epoch 96/1000
502/502 - 24s - loss: 3.3491 - r1: 0.3473 - r5: 0.5641 - r10: 0.6479 - p5: 0.1128 - p10: 0.0648 - val_loss: 3.9597 - val_r1: 0.3011 - val_r5: 0.4882 - val_r10: 0.5692 - val_p5: 0.0977 - val_p10: 0.0569 - lr: 9.0496e-05 - 24s/epoch - 48ms/step
Epoch 97/1000
502/502 - 24s - loss: 3.3469 - r1: 0.3485 - r5: 0.5634 - r10: 0.6476 - p5: 0.1127 - p10: 0.0648 - val_loss: 3.9294 - val_r1: 0.3057 - val_r5: 0.4937 - val_r10: 0.5726 - val_p5: 0.0988 - val_p10: 0.0573 - lr: 9.0397e-05 - 24s/epoch - 48ms/step
Epoch 98/1000
502/502 - 24s - loss: 3.3368 - r1: 0.3488 - r5: 0.5651 - r10: 0.6499 - p5: 0.1130 - p10: 0.0650 - val_loss: 3.9692 - val_r1: 0.3011 - val_r5: 0.4870 - val_r10: 0.5661 - val_p5: 0.0974 - val_p10: 0.0566 - lr: 9.0298e-05 - 24s/epoch - 48ms/step
Epoch 99/1000
502/502 - 24s - loss: 3.3318 - r1: 0.3503 - r5: 0.5663 - r10: 0.6506 - p5: 0.1133 - p10: 0.0651 - val_loss: 3.9646 - val_r1: 0.3010 - val_r5: 0.4883 - val_r10: 0.5671 - val_p5: 0.0977 - val_p10: 0.0567 - lr: 9.0199e-05 - 24s/epoch - 48ms/step
Epoch 100/1000
502/502 - 24s - loss: 3.3258 - r1: 0.3511 - r5: 0.5672 - r10: 0.6514 - p5: 0.1134 - p10: 0.0651 - val_loss: 3.9645 - val_r1: 0.3020 - val_r5: 0.4877 - val_r10: 0.5683 - val_p5: 0.0975 - val_p10: 0.0568 - lr: 9.0100e-05 - 24s/epoch - 48ms/step
Epoch 101/1000
502/502 - 24s - loss: 3.3161 - r1: 0.3522 - r5: 0.5686 - r10: 0.6522 - p5: 0.1137 - p10: 0.0652 - val_loss: 3.9393 - val_r1: 0.3037 - val_r5: 0.4914 - val_r10: 0.5718 - val_p5: 0.0983 - val_p10: 0.0572 - lr: 9.0001e-05 - 24s/epoch - 48ms/step
Epoch 102/1000
502/502 - 24s - loss: 3.3117 - r1: 0.3537 - r5: 0.5686 - r10: 0.6537 - p5: 0.1137 - p10: 0.0654 - val_loss: 3.9683 - val_r1: 0.3003 - val_r5: 0.4887 - val_r10: 0.5670 - val_p5: 0.0977 - val_p10: 0.0567 - lr: 8.9902e-05 - 24s/epoch - 48ms/step
Epoch 103/1000
502/502 - 24s - loss: 3.3145 - r1: 0.3530 - r5: 0.5688 - r10: 0.6530 - p5: 0.1138 - p10: 0.0653 - val_loss: 3.9700 - val_r1: 0.3004 - val_r5: 0.4872 - val_r10: 0.5670 - val_p5: 0.0974 - val_p10: 0.0567 - lr: 8.9803e-05 - 24s/epoch - 48ms/step
Epoch 104/1000
502/502 - 24s - loss: 3.3037 - r1: 0.3549 - r5: 0.5707 - r10: 0.6542 - p5: 0.1141 - p10: 0.0654 - val_loss: 3.9557 - val_r1: 0.3028 - val_r5: 0.4891 - val_r10: 0.5704 - val_p5: 0.0978 - val_p10: 0.0570 - lr: 8.9704e-05 - 24s/epoch - 48ms/step
Epoch 105/1000
502/502 - 24s - loss: 3.2977 - r1: 0.3555 - r5: 0.5714 - r10: 0.6555 - p5: 0.1143 - p10: 0.0655 - val_loss: 3.9361 - val_r1: 0.3032 - val_r5: 0.4921 - val_r10: 0.5731 - val_p5: 0.0984 - val_p10: 0.0573 - lr: 8.9605e-05 - 24s/epoch - 48ms/step
Epoch 106/1000
502/502 - 24s - loss: 3.2958 - r1: 0.3546 - r5: 0.5719 - r10: 0.6560 - p5: 0.1144 - p10: 0.0656 - val_loss: 3.9727 - val_r1: 0.2988 - val_r5: 0.4876 - val_r10: 0.5673 - val_p5: 0.0975 - val_p10: 0.0567 - lr: 8.9506e-05 - 24s/epoch - 48ms/step
Epoch 107/1000
502/502 - 24s - loss: 3.2957 - r1: 0.3547 - r5: 0.5719 - r10: 0.6560 - p5: 0.1144 - p10: 0.0656 - val_loss: 3.9686 - val_r1: 0.2987 - val_r5: 0.4883 - val_r10: 0.5676 - val_p5: 0.0977 - val_p10: 0.0568 - lr: 8.9407e-05 - 24s/epoch - 48ms/step
Epoch 108/1000
502/502 - 24s - loss: 3.2835 - r1: 0.3577 - r5: 0.5730 - r10: 0.6572 - p5: 0.1146 - p10: 0.0657 - val_loss: 3.9645 - val_r1: 0.3004 - val_r5: 0.4878 - val_r10: 0.5673 - val_p5: 0.0975 - val_p10: 0.0567 - lr: 8.9308e-05 - 24s/epoch - 48ms/step
Epoch 109/1000
502/502 - 24s - loss: 3.2790 - r1: 0.3585 - r5: 0.5753 - r10: 0.6585 - p5: 0.1151 - p10: 0.0658 - val_loss: 3.9494 - val_r1: 0.3020 - val_r5: 0.4914 - val_r10: 0.5696 - val_p5: 0.0983 - val_p10: 0.0570 - lr: 8.9209e-05 - 24s/epoch - 48ms/step
Epoch 110/1000
502/502 - 24s - loss: 3.2770 - r1: 0.3590 - r5: 0.5749 - r10: 0.6588 - p5: 0.1150 - p10: 0.0659 - val_loss: 3.9689 - val_r1: 0.2999 - val_r5: 0.4868 - val_r10: 0.5666 - val_p5: 0.0974 - val_p10: 0.0567 - lr: 8.9110e-05 - 24s/epoch - 48ms/step
Epoch 111/1000
502/502 - 24s - loss: 3.2720 - r1: 0.3585 - r5: 0.5760 - r10: 0.6598 - p5: 0.1152 - p10: 0.0660 - val_loss: 3.9803 - val_r1: 0.2973 - val_r5: 0.4855 - val_r10: 0.5666 - val_p5: 0.0971 - val_p10: 0.0567 - lr: 8.9011e-05 - 24s/epoch - 48ms/step
Epoch 112/1000
502/502 - 24s - loss: 3.2668 - r1: 0.3587 - r5: 0.5771 - r10: 0.6600 - p5: 0.1154 - p10: 0.0660 - val_loss: 3.9706 - val_r1: 0.3013 - val_r5: 0.4882 - val_r10: 0.5678 - val_p5: 0.0977 - val_p10: 0.0568 - lr: 8.8912e-05 - 24s/epoch - 48ms/step
Epoch 113/1000
502/502 - 24s - loss: 3.2607 - r1: 0.3595 - r5: 0.5778 - r10: 0.6624 - p5: 0.1156 - p10: 0.0662 - val_loss: 3.9416 - val_r1: 0.3042 - val_r5: 0.4920 - val_r10: 0.5720 - val_p5: 0.0984 - val_p10: 0.0572 - lr: 8.8813e-05 - 24s/epoch - 48ms/step
Epoch 114/1000
502/502 - 24s - loss: 3.2576 - r1: 0.3612 - r5: 0.5782 - r10: 0.6616 - p5: 0.1157 - p10: 0.0662 - val_loss: 3.9768 - val_r1: 0.2993 - val_r5: 0.4869 - val_r10: 0.5666 - val_p5: 0.0974 - val_p10: 0.0567 - lr: 8.8714e-05 - 24s/epoch - 48ms/step
Epoch 115/1000
502/502 - 24s - loss: 3.2484 - r1: 0.3618 - r5: 0.5796 - r10: 0.6627 - p5: 0.1159 - p10: 0.0663 - val_loss: 3.9859 - val_r1: 0.2984 - val_r5: 0.4850 - val_r10: 0.5661 - val_p5: 0.0970 - val_p10: 0.0566 - lr: 8.8615e-05 - 24s/epoch - 48ms/step
Epoch 116/1000
502/502 - 24s - loss: 3.2488 - r1: 0.3616 - r5: 0.5798 - r10: 0.6626 - p5: 0.1160 - p10: 0.0663 - val_loss: 3.9920 - val_r1: 0.2975 - val_r5: 0.4848 - val_r10: 0.5653 - val_p5: 0.0970 - val_p10: 0.0565 - lr: 8.8516e-05 - 24s/epoch - 48ms/step
Epoch 117/1000
502/502 - 24s - loss: 3.2421 - r1: 0.3639 - r5: 0.5807 - r10: 0.6643 - p5: 0.1161 - p10: 0.0664 - val_loss: 3.9559 - val_r1: 0.3035 - val_r5: 0.4892 - val_r10: 0.5701 - val_p5: 0.0978 - val_p10: 0.0570 - lr: 8.8417e-05 - 24s/epoch - 48ms/step
Epoch 118/1000
502/502 - 24s - loss: 3.2397 - r1: 0.3632 - r5: 0.5809 - r10: 0.6638 - p5: 0.1162 - p10: 0.0664 - val_loss: 3.9875 - val_r1: 0.2986 - val_r5: 0.4856 - val_r10: 0.5648 - val_p5: 0.0971 - val_p10: 0.0565 - lr: 8.8318e-05 - 24s/epoch - 48ms/step
Epoch 118: early stopping
[92m[INFO] Loading best model...[0m
[93m[WARNING] Model folder already exists...[0m
Model: "ATT2ITM_0"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 172)]        0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 1322)]       0           []                               
                                                                                                  
 embedding (Embedding)          (None, 172, 384)     3389952     ['input_1[0][0]']                
                                                                                                  
 in_rsts (Embedding)            (None, 1322, 384)    507648      ['input_2[0][0]']                
                                                                                                  
 dense (Dense)                  (None, 172, 256)     98560       ['embedding[0][0]']              
                                                                                                  
 dense_2 (Dense)                (None, 1322, 256)    98560       ['in_rsts[0][0]']                
                                                                                                  
 tf.math.not_equal (TFOpLambda)  (None, 172)         0           ['input_1[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 172, 128)     32896       ['dense[0][0]']                  
                                                                                                  
 dense_3 (Dense)                (None, 1322, 128)    32896       ['dense_2[0][0]']                
                                                                                                  
 tf.cast (TFOpLambda)           (None, 172)          0           ['tf.math.not_equal[0][0]']      
                                                                                                  
 word_emb (Lambda)              (None, 172, 128)     0           ['dense_1[0][0]']                
                                                                                                  
 rest_emb (Lambda)              (None, 1322, 128)    0           ['dense_3[0][0]']                
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 172, 1)       0           ['tf.cast[0][0]']                
                                                                                                  
 lambda (Lambda)                (None, 172, 1322)    0           ['word_emb[0][0]',               
                                                                  'rest_emb[0][0]']               
                                                                                                  
 tf.tile (TFOpLambda)           (None, 172, 1322)    0           ['tf.expand_dims[0][0]']         
                                                                                                  
 lambda_1 (Lambda)              (None, 172, 1322)    0           ['lambda[0][0]',                 
                                                                  'tf.tile[0][0]']                
                                                                                                  
 dotprod (Activation)           (None, 172, 1322)    0           ['lambda_1[0][0]']               
                                                                                                  
 dropout (Dropout)              (None, 172, 1322)    0           ['dotprod[0][0]']                
                                                                                                  
 sum (Lambda)                   (None, 1322)         0           ['dropout[0][0]']                
                                                                                                  
 out (Activation)               (None, 1322)         0           ['sum[0][0]']                    
                                                                                                  
==================================================================================================
Total params: 4,160,512
Trainable params: 4,160,512
Non-trainable params: 0
__________________________________________________________________________________________________
None
[92m[INFO] Model already trained. Loading weights...[0m
[93m[WARNING] Model folder already exists...[0m
Model: "ATT2ITM_0"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 172)]        0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 1322)]       0           []                               
                                                                                                  
 embedding (Embedding)          (None, 172, 384)     3389952     ['input_1[0][0]']                
                                                                                                  
 in_rsts (Embedding)            (None, 1322, 384)    507648      ['input_2[0][0]']                
                                                                                                  
 dense (Dense)                  (None, 172, 256)     98560       ['embedding[0][0]']              
                                                                                                  
 dense_2 (Dense)                (None, 1322, 256)    98560       ['in_rsts[0][0]']                
                                                                                                  
 tf.math.not_equal (TFOpLambda)  (None, 172)         0           ['input_1[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 172, 128)     32896       ['dense[0][0]']                  
                                                                                                  
 dense_3 (Dense)                (None, 1322, 128)    32896       ['dense_2[0][0]']                
                                                                                                  
 tf.cast (TFOpLambda)           (None, 172)          0           ['tf.math.not_equal[0][0]']      
                                                                                                  
 word_emb (Lambda)              (None, 172, 128)     0           ['dense_1[0][0]']                
                                                                                                  
 rest_emb (Lambda)              (None, 1322, 128)    0           ['dense_3[0][0]']                
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 172, 1)       0           ['tf.cast[0][0]']                
                                                                                                  
 lambda (Lambda)                (None, 172, 1322)    0           ['word_emb[0][0]',               
                                                                  'rest_emb[0][0]']               
                                                                                                  
 tf.tile (TFOpLambda)           (None, 172, 1322)    0           ['tf.expand_dims[0][0]']         
                                                                                                  
 lambda_1 (Lambda)              (None, 172, 1322)    0           ['lambda[0][0]',                 
                                                                  'tf.tile[0][0]']                
                                                                                                  
 dotprod (Activation)           (None, 172, 1322)    0           ['lambda_1[0][0]']               
                                                                                                  
 dropout (Dropout)              (None, 172, 1322)    0           ['dotprod[0][0]']                
                                                                                                  
 sum (Lambda)                   (None, 1322)         0           ['dropout[0][0]']                
                                                                                                  
 out (Activation)               (None, 1322)         0           ['sum[0][0]']                    
                                                                                                  
==================================================================================================
Total params: 4,160,512
Trainable params: 4,160,512
Non-trainable params: 0
__________________________________________________________________________________________________
None
[92m[INFO] Model already trained. Loading weights...[0m
[93m[WARNING] Model folder already exists...[0m
Model: "ATT2ITM_0"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 172)]        0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 1322)]       0           []                               
                                                                                                  
 embedding (Embedding)          (None, 172, 384)     3389952     ['input_1[0][0]']                
                                                                                                  
 in_rsts (Embedding)            (None, 1322, 384)    507648      ['input_2[0][0]']                
                                                                                                  
 dense (Dense)                  (None, 172, 256)     98560       ['embedding[0][0]']              
                                                                                                  
 dense_2 (Dense)                (None, 1322, 256)    98560       ['in_rsts[0][0]']                
                                                                                                  
 tf.math.not_equal (TFOpLambda)  (None, 172)         0           ['input_1[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 172, 128)     32896       ['dense[0][0]']                  
                                                                                                  
 dense_3 (Dense)                (None, 1322, 128)    32896       ['dense_2[0][0]']                
                                                                                                  
 tf.cast (TFOpLambda)           (None, 172)          0           ['tf.math.not_equal[0][0]']      
                                                                                                  
 word_emb (Lambda)              (None, 172, 128)     0           ['dense_1[0][0]']                
                                                                                                  
 rest_emb (Lambda)              (None, 1322, 128)    0           ['dense_3[0][0]']                
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 172, 1)       0           ['tf.cast[0][0]']                
                                                                                                  
 lambda (Lambda)                (None, 172, 1322)    0           ['word_emb[0][0]',               
                                                                  'rest_emb[0][0]']               
                                                                                                  
 tf.tile (TFOpLambda)           (None, 172, 1322)    0           ['tf.expand_dims[0][0]']         
                                                                                                  
 lambda_1 (Lambda)              (None, 172, 1322)    0           ['lambda[0][0]',                 
                                                                  'tf.tile[0][0]']                
                                                                                                  
 dotprod (Activation)           (None, 172, 1322)    0           ['lambda_1[0][0]']               
                                                                                                  
 dropout (Dropout)              (None, 172, 1322)    0           ['dotprod[0][0]']                
                                                                                                  
 sum (Lambda)                   (None, 1322)         0           ['dropout[0][0]']                
                                                                                                  
 out (Activation)               (None, 1322)         0           ['sum[0][0]']                    
                                                                                                  
==================================================================================================
Total params: 4,160,512
Trainable params: 4,160,512
Non-trainable params: 0
__________________________________________________________________________________________________
None
[92m[INFO] Model already trained. Loading weights...[0m
[93m[WARNING] Model folder already exists...[0m
Model: "ATT2ITM_0"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 172)]        0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 1322)]       0           []                               
                                                                                                  
 embedding (Embedding)          (None, 172, 384)     3389952     ['input_1[0][0]']                
                                                                                                  
 in_rsts (Embedding)            (None, 1322, 384)    507648      ['input_2[0][0]']                
                                                                                                  
 dense (Dense)                  (None, 172, 256)     98560       ['embedding[0][0]']              
                                                                                                  
 dense_2 (Dense)                (None, 1322, 256)    98560       ['in_rsts[0][0]']                
                                                                                                  
 tf.math.not_equal (TFOpLambda)  (None, 172)         0           ['input_1[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 172, 128)     32896       ['dense[0][0]']                  
                                                                                                  
 dense_3 (Dense)                (None, 1322, 128)    32896       ['dense_2[0][0]']                
                                                                                                  
 tf.cast (TFOpLambda)           (None, 172)          0           ['tf.math.not_equal[0][0]']      
                                                                                                  
 word_emb (Lambda)              (None, 172, 128)     0           ['dense_1[0][0]']                
                                                                                                  
 rest_emb (Lambda)              (None, 1322, 128)    0           ['dense_3[0][0]']                
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 172, 1)       0           ['tf.cast[0][0]']                
                                                                                                  
 lambda (Lambda)                (None, 172, 1322)    0           ['word_emb[0][0]',               
                                                                  'rest_emb[0][0]']               
                                                                                                  
 tf.tile (TFOpLambda)           (None, 172, 1322)    0           ['tf.expand_dims[0][0]']         
                                                                                                  
 lambda_1 (Lambda)              (None, 172, 1322)    0           ['lambda[0][0]',                 
                                                                  'tf.tile[0][0]']                
                                                                                                  
 dotprod (Activation)           (None, 172, 1322)    0           ['lambda_1[0][0]']               
                                                                                                  
 dropout (Dropout)              (None, 172, 1322)    0           ['dotprod[0][0]']                
                                                                                                  
 sum (Lambda)                   (None, 1322)         0           ['dropout[0][0]']                
                                                                                                  
 out (Activation)               (None, 1322)         0           ['sum[0][0]']                    
                                                                                                  
==================================================================================================
Total params: 4,160,512
Trainable params: 4,160,512
Non-trainable params: 0
__________________________________________________________________________________________________
None
[92m[INFO] Model already trained. Loading weights...[0m
