Model: "ATT2ITM_0"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 172)]        0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 1322)]       0           []                               
                                                                                                  
 embedding (Embedding)          (None, 172, 384)     3389952     ['input_1[0][0]']                
                                                                                                  
 in_rsts (Embedding)            (None, 1322, 384)    507648      ['input_2[0][0]']                
                                                                                                  
 dense (Dense)                  (None, 172, 256)     98560       ['embedding[0][0]']              
                                                                                                  
 dense_2 (Dense)                (None, 1322, 256)    98560       ['in_rsts[0][0]']                
                                                                                                  
 tf.math.not_equal (TFOpLambda)  (None, 172)         0           ['input_1[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 172, 128)     32896       ['dense[0][0]']                  
                                                                                                  
 dense_3 (Dense)                (None, 1322, 128)    32896       ['dense_2[0][0]']                
                                                                                                  
 tf.cast (TFOpLambda)           (None, 172)          0           ['tf.math.not_equal[0][0]']      
                                                                                                  
 word_emb (Lambda)              (None, 172, 128)     0           ['dense_1[0][0]']                
                                                                                                  
 rest_emb (Lambda)              (None, 1322, 128)    0           ['dense_3[0][0]']                
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 172, 1)       0           ['tf.cast[0][0]']                
                                                                                                  
 lambda (Lambda)                (None, 172, 1322)    0           ['word_emb[0][0]',               
                                                                  'rest_emb[0][0]']               
                                                                                                  
 tf.tile (TFOpLambda)           (None, 172, 1322)    0           ['tf.expand_dims[0][0]']         
                                                                                                  
 lambda_1 (Lambda)              (None, 172, 1322)    0           ['lambda[0][0]',                 
                                                                  'tf.tile[0][0]']                
                                                                                                  
 dotprod (Activation)           (None, 172, 1322)    0           ['lambda_1[0][0]']               
                                                                                                  
 dropout (Dropout)              (None, 172, 1322)    0           ['dotprod[0][0]']                
                                                                                                  
 sum (Lambda)                   (None, 1322)         0           ['dropout[0][0]']                
                                                                                                  
 out (Activation)               (None, 1322)         0           ['sum[0][0]']                    
                                                                                                  
==================================================================================================
Total params: 4,160,512
Trainable params: 4,160,512
Non-trainable params: 0
__________________________________________________________________________________________________
None
Epoch 1/1000
502/502 - 54s - loss: 5.8142 - r1: 0.0772 - r5: 0.1772 - r10: 0.2389 - p5: 0.0354 - p10: 0.0239 - val_loss: 4.9480 - val_r1: 0.1656 - val_r5: 0.3340 - val_r10: 0.4205 - val_p5: 0.0668 - val_p10: 0.0421 - lr: 4.9951e-04 - 54s/epoch - 107ms/step
Epoch 2/1000
502/502 - 50s - loss: 4.8933 - r1: 0.1539 - r5: 0.3113 - r10: 0.3957 - p5: 0.0623 - p10: 0.0396 - val_loss: 4.9107 - val_r1: 0.1648 - val_r5: 0.3314 - val_r10: 0.4172 - val_p5: 0.0663 - val_p10: 0.0417 - lr: 4.9901e-04 - 50s/epoch - 100ms/step
Epoch 3/1000
502/502 - 50s - loss: 4.6197 - r1: 0.1849 - r5: 0.3587 - r10: 0.4451 - p5: 0.0717 - p10: 0.0445 - val_loss: 4.7943 - val_r1: 0.1836 - val_r5: 0.3502 - val_r10: 0.4380 - val_p5: 0.0700 - val_p10: 0.0438 - lr: 4.9852e-04 - 50s/epoch - 100ms/step
Epoch 4/1000
502/502 - 50s - loss: 4.4428 - r1: 0.2070 - r5: 0.3872 - r10: 0.4758 - p5: 0.0774 - p10: 0.0476 - val_loss: 4.5746 - val_r1: 0.2121 - val_r5: 0.3890 - val_r10: 0.4784 - val_p5: 0.0778 - val_p10: 0.0478 - lr: 4.9802e-04 - 50s/epoch - 100ms/step
Epoch 5/1000
502/502 - 50s - loss: 4.3131 - r1: 0.2225 - r5: 0.4093 - r10: 0.4967 - p5: 0.0819 - p10: 0.0497 - val_loss: 4.4861 - val_r1: 0.2260 - val_r5: 0.4078 - val_r10: 0.4940 - val_p5: 0.0816 - val_p10: 0.0494 - lr: 4.9753e-04 - 50s/epoch - 100ms/step
Epoch 6/1000
502/502 - 50s - loss: 4.2104 - r1: 0.2354 - r5: 0.4246 - r10: 0.5122 - p5: 0.0849 - p10: 0.0512 - val_loss: 4.4156 - val_r1: 0.2388 - val_r5: 0.4190 - val_r10: 0.5059 - val_p5: 0.0838 - val_p10: 0.0506 - lr: 4.9703e-04 - 50s/epoch - 100ms/step
Epoch 7/1000
502/502 - 50s - loss: 4.1237 - r1: 0.2459 - r5: 0.4389 - r10: 0.5264 - p5: 0.0878 - p10: 0.0526 - val_loss: 4.4076 - val_r1: 0.2396 - val_r5: 0.4208 - val_r10: 0.5047 - val_p5: 0.0842 - val_p10: 0.0505 - lr: 4.9654e-04 - 50s/epoch - 100ms/step
Epoch 8/1000
502/502 - 50s - loss: 4.0574 - r1: 0.2529 - r5: 0.4490 - r10: 0.5380 - p5: 0.0898 - p10: 0.0538 - val_loss: 4.3370 - val_r1: 0.2493 - val_r5: 0.4335 - val_r10: 0.5168 - val_p5: 0.0867 - val_p10: 0.0517 - lr: 4.9604e-04 - 50s/epoch - 99ms/step
Epoch 9/1000
502/502 - 50s - loss: 3.9832 - r1: 0.2638 - r5: 0.4621 - r10: 0.5498 - p5: 0.0924 - p10: 0.0550 - val_loss: 4.2977 - val_r1: 0.2559 - val_r5: 0.4369 - val_r10: 0.5208 - val_p5: 0.0874 - val_p10: 0.0521 - lr: 4.9555e-04 - 50s/epoch - 100ms/step
Epoch 10/1000
502/502 - 50s - loss: 3.9292 - r1: 0.2706 - r5: 0.4700 - r10: 0.5575 - p5: 0.0940 - p10: 0.0558 - val_loss: 4.1314 - val_r1: 0.2781 - val_r5: 0.4643 - val_r10: 0.5452 - val_p5: 0.0928 - val_p10: 0.0545 - lr: 4.9505e-04 - 50s/epoch - 100ms/step
Epoch 11/1000
502/502 - 50s - loss: 3.8740 - r1: 0.2773 - r5: 0.4789 - r10: 0.5672 - p5: 0.0958 - p10: 0.0567 - val_loss: 4.3017 - val_r1: 0.2563 - val_r5: 0.4381 - val_r10: 0.5182 - val_p5: 0.0876 - val_p10: 0.0518 - lr: 4.9456e-04 - 50s/epoch - 99ms/step
Epoch 12/1000
502/502 - 49s - loss: 3.8286 - r1: 0.2830 - r5: 0.4863 - r10: 0.5740 - p5: 0.0973 - p10: 0.0574 - val_loss: 4.3012 - val_r1: 0.2568 - val_r5: 0.4389 - val_r10: 0.5183 - val_p5: 0.0878 - val_p10: 0.0518 - lr: 4.9406e-04 - 49s/epoch - 98ms/step
Epoch 13/1000
502/502 - 50s - loss: 3.7890 - r1: 0.2887 - r5: 0.4933 - r10: 0.5815 - p5: 0.0987 - p10: 0.0581 - val_loss: 4.2189 - val_r1: 0.2657 - val_r5: 0.4500 - val_r10: 0.5330 - val_p5: 0.0900 - val_p10: 0.0533 - lr: 4.9357e-04 - 50s/epoch - 99ms/step
Epoch 14/1000
502/502 - 50s - loss: 3.7436 - r1: 0.2941 - r5: 0.4996 - r10: 0.5877 - p5: 0.0999 - p10: 0.0588 - val_loss: 4.1266 - val_r1: 0.2822 - val_r5: 0.4650 - val_r10: 0.5470 - val_p5: 0.0930 - val_p10: 0.0547 - lr: 4.9307e-04 - 50s/epoch - 100ms/step
Epoch 15/1000
502/502 - 50s - loss: 3.6975 - r1: 0.3014 - r5: 0.5076 - r10: 0.5945 - p5: 0.1015 - p10: 0.0595 - val_loss: 4.2988 - val_r1: 0.2571 - val_r5: 0.4368 - val_r10: 0.5216 - val_p5: 0.0874 - val_p10: 0.0522 - lr: 4.9258e-04 - 50s/epoch - 99ms/step
Epoch 16/1000
502/502 - 49s - loss: 3.6683 - r1: 0.3047 - r5: 0.5128 - r10: 0.5995 - p5: 0.1026 - p10: 0.0600 - val_loss: 4.2840 - val_r1: 0.2609 - val_r5: 0.4407 - val_r10: 0.5235 - val_p5: 0.0881 - val_p10: 0.0524 - lr: 4.9208e-04 - 49s/epoch - 98ms/step
Epoch 17/1000
502/502 - 50s - loss: 3.6427 - r1: 0.3075 - r5: 0.5169 - r10: 0.6033 - p5: 0.1034 - p10: 0.0603 - val_loss: 4.2430 - val_r1: 0.2647 - val_r5: 0.4463 - val_r10: 0.5311 - val_p5: 0.0893 - val_p10: 0.0531 - lr: 4.9159e-04 - 50s/epoch - 99ms/step
Epoch 18/1000
502/502 - 50s - loss: 3.6099 - r1: 0.3119 - r5: 0.5225 - r10: 0.6085 - p5: 0.1045 - p10: 0.0609 - val_loss: 4.1187 - val_r1: 0.2837 - val_r5: 0.4680 - val_r10: 0.5475 - val_p5: 0.0936 - val_p10: 0.0547 - lr: 4.9109e-04 - 50s/epoch - 100ms/step
Epoch 19/1000
502/502 - 50s - loss: 3.5825 - r1: 0.3155 - r5: 0.5258 - r10: 0.6127 - p5: 0.1052 - p10: 0.0613 - val_loss: 4.2603 - val_r1: 0.2601 - val_r5: 0.4434 - val_r10: 0.5246 - val_p5: 0.0887 - val_p10: 0.0525 - lr: 4.9060e-04 - 50s/epoch - 99ms/step
Epoch 20/1000
502/502 - 50s - loss: 3.5539 - r1: 0.3191 - r5: 0.5304 - r10: 0.6170 - p5: 0.1061 - p10: 0.0617 - val_loss: 4.2833 - val_r1: 0.2593 - val_r5: 0.4418 - val_r10: 0.5215 - val_p5: 0.0883 - val_p10: 0.0521 - lr: 4.9010e-04 - 50s/epoch - 99ms/step
Epoch 21/1000
502/502 - 50s - loss: 3.5373 - r1: 0.3206 - r5: 0.5338 - r10: 0.6203 - p5: 0.1068 - p10: 0.0620 - val_loss: 4.2773 - val_r1: 0.2577 - val_r5: 0.4386 - val_r10: 0.5224 - val_p5: 0.0877 - val_p10: 0.0522 - lr: 4.8961e-04 - 50s/epoch - 99ms/step
Epoch 22/1000
502/502 - 50s - loss: 3.5133 - r1: 0.3250 - r5: 0.5372 - r10: 0.6232 - p5: 0.1074 - p10: 0.0623 - val_loss: 4.1425 - val_r1: 0.2784 - val_r5: 0.4609 - val_r10: 0.5426 - val_p5: 0.0922 - val_p10: 0.0543 - lr: 4.8911e-04 - 50s/epoch - 99ms/step
Epoch 23/1000
502/502 - 50s - loss: 3.4863 - r1: 0.3276 - r5: 0.5421 - r10: 0.6276 - p5: 0.1084 - p10: 0.0628 - val_loss: 4.2411 - val_r1: 0.2653 - val_r5: 0.4467 - val_r10: 0.5287 - val_p5: 0.0893 - val_p10: 0.0529 - lr: 4.8862e-04 - 50s/epoch - 99ms/step
Epoch 24/1000
502/502 - 50s - loss: 3.4676 - r1: 0.3308 - r5: 0.5440 - r10: 0.6290 - p5: 0.1088 - p10: 0.0629 - val_loss: 4.2215 - val_r1: 0.2675 - val_r5: 0.4487 - val_r10: 0.5307 - val_p5: 0.0897 - val_p10: 0.0531 - lr: 4.8812e-04 - 50s/epoch - 99ms/step
Epoch 25/1000
502/502 - 50s - loss: 3.4452 - r1: 0.3342 - r5: 0.5471 - r10: 0.6329 - p5: 0.1094 - p10: 0.0633 - val_loss: 4.2141 - val_r1: 0.2676 - val_r5: 0.4495 - val_r10: 0.5311 - val_p5: 0.0899 - val_p10: 0.0531 - lr: 4.8763e-04 - 50s/epoch - 99ms/step
Epoch 26/1000
502/502 - 50s - loss: 3.4299 - r1: 0.3348 - r5: 0.5497 - r10: 0.6360 - p5: 0.1099 - p10: 0.0636 - val_loss: 4.1332 - val_r1: 0.2811 - val_r5: 0.4637 - val_r10: 0.5436 - val_p5: 0.0927 - val_p10: 0.0544 - lr: 4.8713e-04 - 50s/epoch - 99ms/step
Epoch 27/1000
502/502 - 50s - loss: 3.4096 - r1: 0.3393 - r5: 0.5534 - r10: 0.6387 - p5: 0.1107 - p10: 0.0639 - val_loss: 4.2850 - val_r1: 0.2603 - val_r5: 0.4400 - val_r10: 0.5206 - val_p5: 0.0880 - val_p10: 0.0521 - lr: 4.8664e-04 - 50s/epoch - 99ms/step
Epoch 28/1000
502/502 - 50s - loss: 3.4013 - r1: 0.3391 - r5: 0.5552 - r10: 0.6401 - p5: 0.1110 - p10: 0.0640 - val_loss: 4.2286 - val_r1: 0.2666 - val_r5: 0.4480 - val_r10: 0.5279 - val_p5: 0.0896 - val_p10: 0.0528 - lr: 4.8614e-04 - 50s/epoch - 99ms/step
Epoch 29/1000
502/502 - 50s - loss: 3.3782 - r1: 0.3435 - r5: 0.5587 - r10: 0.6437 - p5: 0.1117 - p10: 0.0644 - val_loss: 4.2344 - val_r1: 0.2658 - val_r5: 0.4475 - val_r10: 0.5288 - val_p5: 0.0895 - val_p10: 0.0529 - lr: 4.8565e-04 - 50s/epoch - 99ms/step
Epoch 30/1000
502/502 - 50s - loss: 3.3662 - r1: 0.3455 - r5: 0.5602 - r10: 0.6450 - p5: 0.1120 - p10: 0.0645 - val_loss: 4.1614 - val_r1: 0.2757 - val_r5: 0.4594 - val_r10: 0.5397 - val_p5: 0.0919 - val_p10: 0.0540 - lr: 4.8515e-04 - 50s/epoch - 99ms/step
Epoch 31/1000
502/502 - 50s - loss: 3.3469 - r1: 0.3485 - r5: 0.5638 - r10: 0.6478 - p5: 0.1128 - p10: 0.0648 - val_loss: 4.2575 - val_r1: 0.2662 - val_r5: 0.4444 - val_r10: 0.5243 - val_p5: 0.0889 - val_p10: 0.0524 - lr: 4.8466e-04 - 50s/epoch - 99ms/step
Epoch 32/1000
502/502 - 50s - loss: 3.3344 - r1: 0.3483 - r5: 0.5659 - r10: 0.6508 - p5: 0.1132 - p10: 0.0651 - val_loss: 4.2822 - val_r1: 0.2627 - val_r5: 0.4425 - val_r10: 0.5251 - val_p5: 0.0885 - val_p10: 0.0525 - lr: 4.8416e-04 - 50s/epoch - 99ms/step
Epoch 33/1000
502/502 - 50s - loss: 3.3268 - r1: 0.3500 - r5: 0.5673 - r10: 0.6509 - p5: 0.1135 - p10: 0.0651 - val_loss: 4.2331 - val_r1: 0.2685 - val_r5: 0.4471 - val_r10: 0.5266 - val_p5: 0.0894 - val_p10: 0.0527 - lr: 4.8367e-04 - 50s/epoch - 99ms/step
Epoch 34/1000
502/502 - 50s - loss: 3.3094 - r1: 0.3530 - r5: 0.5700 - r10: 0.6546 - p5: 0.1140 - p10: 0.0655 - val_loss: 4.1585 - val_r1: 0.2772 - val_r5: 0.4607 - val_r10: 0.5414 - val_p5: 0.0921 - val_p10: 0.0541 - lr: 4.8317e-04 - 50s/epoch - 99ms/step
Epoch 35/1000
502/502 - 50s - loss: 3.2968 - r1: 0.3546 - r5: 0.5724 - r10: 0.6562 - p5: 0.1145 - p10: 0.0656 - val_loss: 4.2289 - val_r1: 0.2686 - val_r5: 0.4505 - val_r10: 0.5301 - val_p5: 0.0901 - val_p10: 0.0530 - lr: 4.8268e-04 - 50s/epoch - 99ms/step
Epoch 36/1000
502/502 - 50s - loss: 3.2808 - r1: 0.3570 - r5: 0.5748 - r10: 0.6582 - p5: 0.1150 - p10: 0.0658 - val_loss: 4.2425 - val_r1: 0.2671 - val_r5: 0.4498 - val_r10: 0.5299 - val_p5: 0.0899 - val_p10: 0.0530 - lr: 4.8218e-04 - 50s/epoch - 99ms/step
Epoch 37/1000
502/502 - 50s - loss: 3.2728 - r1: 0.3576 - r5: 0.5756 - r10: 0.6601 - p5: 0.1151 - p10: 0.0660 - val_loss: 4.2333 - val_r1: 0.2672 - val_r5: 0.4491 - val_r10: 0.5303 - val_p5: 0.0898 - val_p10: 0.0530 - lr: 4.8169e-04 - 50s/epoch - 99ms/step
Epoch 38/1000
502/502 - 50s - loss: 3.2643 - r1: 0.3589 - r5: 0.5766 - r10: 0.6603 - p5: 0.1153 - p10: 0.0660 - val_loss: 4.1483 - val_r1: 0.2811 - val_r5: 0.4626 - val_r10: 0.5423 - val_p5: 0.0925 - val_p10: 0.0542 - lr: 4.8119e-04 - 50s/epoch - 99ms/step
Epoch 39/1000
502/502 - 50s - loss: 3.2473 - r1: 0.3611 - r5: 0.5797 - r10: 0.6638 - p5: 0.1159 - p10: 0.0664 - val_loss: 4.2594 - val_r1: 0.2656 - val_r5: 0.4455 - val_r10: 0.5246 - val_p5: 0.0891 - val_p10: 0.0525 - lr: 4.8070e-04 - 50s/epoch - 99ms/step
Epoch 40/1000
502/502 - 50s - loss: 3.2387 - r1: 0.3616 - r5: 0.5806 - r10: 0.6645 - p5: 0.1161 - p10: 0.0665 - val_loss: 4.2308 - val_r1: 0.2707 - val_r5: 0.4502 - val_r10: 0.5311 - val_p5: 0.0900 - val_p10: 0.0531 - lr: 4.8020e-04 - 50s/epoch - 99ms/step
Epoch 41/1000
502/502 - 50s - loss: 3.2305 - r1: 0.3638 - r5: 0.5813 - r10: 0.6647 - p5: 0.1163 - p10: 0.0665 - val_loss: 4.2287 - val_r1: 0.2674 - val_r5: 0.4512 - val_r10: 0.5311 - val_p5: 0.0903 - val_p10: 0.0531 - lr: 4.7971e-04 - 50s/epoch - 99ms/step
Epoch 42/1000
502/502 - 50s - loss: 3.2209 - r1: 0.3647 - r5: 0.5844 - r10: 0.6677 - p5: 0.1169 - p10: 0.0668 - val_loss: 4.2523 - val_r1: 0.2666 - val_r5: 0.4502 - val_r10: 0.5303 - val_p5: 0.0900 - val_p10: 0.0530 - lr: 4.7921e-04 - 50s/epoch - 99ms/step
Epoch 43/1000
502/502 - 50s - loss: 3.2146 - r1: 0.3659 - r5: 0.5842 - r10: 0.6676 - p5: 0.1168 - p10: 0.0668 - val_loss: 4.2433 - val_r1: 0.2686 - val_r5: 0.4505 - val_r10: 0.5312 - val_p5: 0.0901 - val_p10: 0.0531 - lr: 4.7872e-04 - 50s/epoch - 99ms/step
Epoch 44/1000
502/502 - 50s - loss: 3.2011 - r1: 0.3683 - r5: 0.5872 - r10: 0.6706 - p5: 0.1174 - p10: 0.0671 - val_loss: 4.2716 - val_r1: 0.2640 - val_r5: 0.4465 - val_r10: 0.5261 - val_p5: 0.0893 - val_p10: 0.0526 - lr: 4.7822e-04 - 50s/epoch - 99ms/step
Epoch 45/1000
502/502 - 50s - loss: 3.1937 - r1: 0.3695 - r5: 0.5870 - r10: 0.6703 - p5: 0.1174 - p10: 0.0670 - val_loss: 4.2553 - val_r1: 0.2657 - val_r5: 0.4492 - val_r10: 0.5303 - val_p5: 0.0898 - val_p10: 0.0530 - lr: 4.7773e-04 - 50s/epoch - 99ms/step
Epoch 46/1000
502/502 - 50s - loss: 3.1857 - r1: 0.3698 - r5: 0.5887 - r10: 0.6724 - p5: 0.1177 - p10: 0.0672 - val_loss: 4.1849 - val_r1: 0.2754 - val_r5: 0.4601 - val_r10: 0.5400 - val_p5: 0.0920 - val_p10: 0.0540 - lr: 4.7723e-04 - 50s/epoch - 99ms/step
Epoch 47/1000
502/502 - 50s - loss: 3.1776 - r1: 0.3716 - r5: 0.5906 - r10: 0.6728 - p5: 0.1181 - p10: 0.0673 - val_loss: 4.2512 - val_r1: 0.2679 - val_r5: 0.4491 - val_r10: 0.5289 - val_p5: 0.0898 - val_p10: 0.0529 - lr: 4.7674e-04 - 50s/epoch - 99ms/step
Epoch 48/1000
502/502 - 50s - loss: 3.1683 - r1: 0.3734 - r5: 0.5921 - r10: 0.6748 - p5: 0.1184 - p10: 0.0675 - val_loss: 4.2591 - val_r1: 0.2688 - val_r5: 0.4507 - val_r10: 0.5311 - val_p5: 0.0901 - val_p10: 0.0531 - lr: 4.7624e-04 - 50s/epoch - 99ms/step
Epoch 49/1000
502/502 - 50s - loss: 3.1649 - r1: 0.3731 - r5: 0.5933 - r10: 0.6754 - p5: 0.1187 - p10: 0.0675 - val_loss: 4.2483 - val_r1: 0.2679 - val_r5: 0.4498 - val_r10: 0.5298 - val_p5: 0.0900 - val_p10: 0.0530 - lr: 4.7575e-04 - 50s/epoch - 99ms/step
Epoch 50/1000
502/502 - 50s - loss: 3.1555 - r1: 0.3744 - r5: 0.5931 - r10: 0.6762 - p5: 0.1186 - p10: 0.0676 - val_loss: 4.2165 - val_r1: 0.2695 - val_r5: 0.4532 - val_r10: 0.5341 - val_p5: 0.0906 - val_p10: 0.0534 - lr: 4.7525e-04 - 50s/epoch - 99ms/step
Epoch 51/1000
502/502 - 50s - loss: 3.1468 - r1: 0.3755 - r5: 0.5944 - r10: 0.6775 - p5: 0.1189 - p10: 0.0677 - val_loss: 4.2493 - val_r1: 0.2686 - val_r5: 0.4510 - val_r10: 0.5311 - val_p5: 0.0902 - val_p10: 0.0531 - lr: 4.7476e-04 - 50s/epoch - 99ms/step
Epoch 52/1000
502/502 - 50s - loss: 3.1444 - r1: 0.3760 - r5: 0.5958 - r10: 0.6774 - p5: 0.1192 - p10: 0.0677 - val_loss: 4.2567 - val_r1: 0.2684 - val_r5: 0.4488 - val_r10: 0.5269 - val_p5: 0.0898 - val_p10: 0.0527 - lr: 4.7426e-04 - 50s/epoch - 99ms/step
Epoch 53/1000
502/502 - 50s - loss: 3.1358 - r1: 0.3777 - r5: 0.5981 - r10: 0.6802 - p5: 0.1196 - p10: 0.0680 - val_loss: 4.2640 - val_r1: 0.2647 - val_r5: 0.4497 - val_r10: 0.5262 - val_p5: 0.0899 - val_p10: 0.0526 - lr: 4.7377e-04 - 50s/epoch - 99ms/step
Epoch 54/1000
502/502 - 50s - loss: 3.1290 - r1: 0.3777 - r5: 0.5991 - r10: 0.6810 - p5: 0.1198 - p10: 0.0681 - val_loss: 4.2201 - val_r1: 0.2712 - val_r5: 0.4560 - val_r10: 0.5369 - val_p5: 0.0912 - val_p10: 0.0537 - lr: 4.7327e-04 - 50s/epoch - 99ms/step
Epoch 55/1000
502/502 - 50s - loss: 3.1182 - r1: 0.3802 - r5: 0.5991 - r10: 0.6820 - p5: 0.1198 - p10: 0.0682 - val_loss: 4.2634 - val_r1: 0.2653 - val_r5: 0.4485 - val_r10: 0.5294 - val_p5: 0.0897 - val_p10: 0.0529 - lr: 4.7278e-04 - 50s/epoch - 99ms/step
Epoch 56/1000
502/502 - 50s - loss: 3.1143 - r1: 0.3799 - r5: 0.6006 - r10: 0.6831 - p5: 0.1201 - p10: 0.0683 - val_loss: 4.2727 - val_r1: 0.2652 - val_r5: 0.4449 - val_r10: 0.5273 - val_p5: 0.0890 - val_p10: 0.0527 - lr: 4.7228e-04 - 50s/epoch - 99ms/step
Epoch 57/1000
502/502 - 50s - loss: 3.1086 - r1: 0.3813 - r5: 0.6017 - r10: 0.6836 - p5: 0.1203 - p10: 0.0684 - val_loss: 4.2675 - val_r1: 0.2633 - val_r5: 0.4482 - val_r10: 0.5272 - val_p5: 0.0896 - val_p10: 0.0527 - lr: 4.7179e-04 - 50s/epoch - 99ms/step
Epoch 58/1000
502/502 - 50s - loss: 3.1086 - r1: 0.3815 - r5: 0.6004 - r10: 0.6834 - p5: 0.1201 - p10: 0.0683 - val_loss: 4.2283 - val_r1: 0.2710 - val_r5: 0.4538 - val_r10: 0.5320 - val_p5: 0.0908 - val_p10: 0.0532 - lr: 4.7129e-04 - 50s/epoch - 99ms/step
Epoch 59/1000
502/502 - 50s - loss: 3.0949 - r1: 0.3843 - r5: 0.6027 - r10: 0.6848 - p5: 0.1205 - p10: 0.0685 - val_loss: 4.2685 - val_r1: 0.2663 - val_r5: 0.4489 - val_r10: 0.5279 - val_p5: 0.0898 - val_p10: 0.0528 - lr: 4.7080e-04 - 50s/epoch - 99ms/step
Epoch 60/1000
502/502 - 50s - loss: 3.0894 - r1: 0.3846 - r5: 0.6045 - r10: 0.6869 - p5: 0.1209 - p10: 0.0687 - val_loss: 4.2629 - val_r1: 0.2681 - val_r5: 0.4514 - val_r10: 0.5280 - val_p5: 0.0903 - val_p10: 0.0528 - lr: 4.7030e-04 - 50s/epoch - 99ms/step
Epoch 61/1000
502/502 - 50s - loss: 3.0831 - r1: 0.3867 - r5: 0.6059 - r10: 0.6867 - p5: 0.1212 - p10: 0.0687 - val_loss: 4.2716 - val_r1: 0.2655 - val_r5: 0.4478 - val_r10: 0.5274 - val_p5: 0.0895 - val_p10: 0.0527 - lr: 4.6981e-04 - 50s/epoch - 99ms/step
Epoch 62/1000
502/502 - 50s - loss: 3.0733 - r1: 0.3881 - r5: 0.6064 - r10: 0.6877 - p5: 0.1213 - p10: 0.0688 - val_loss: 4.2730 - val_r1: 0.2664 - val_r5: 0.4494 - val_r10: 0.5285 - val_p5: 0.0899 - val_p10: 0.0529 - lr: 4.6931e-04 - 50s/epoch - 99ms/step
Epoch 63/1000
502/502 - 50s - loss: 3.0716 - r1: 0.3872 - r5: 0.6071 - r10: 0.6892 - p5: 0.1214 - p10: 0.0689 - val_loss: 4.2122 - val_r1: 0.2711 - val_r5: 0.4566 - val_r10: 0.5344 - val_p5: 0.0913 - val_p10: 0.0534 - lr: 4.6882e-04 - 50s/epoch - 99ms/step
Epoch 64/1000
502/502 - 50s - loss: 3.0719 - r1: 0.3862 - r5: 0.6069 - r10: 0.6886 - p5: 0.1214 - p10: 0.0689 - val_loss: 4.2457 - val_r1: 0.2690 - val_r5: 0.4501 - val_r10: 0.5296 - val_p5: 0.0900 - val_p10: 0.0530 - lr: 4.6832e-04 - 50s/epoch - 99ms/step
Epoch 65/1000
502/502 - 48s - loss: 3.0660 - r1: 0.3880 - r5: 0.6076 - r10: 0.6896 - p5: 0.1215 - p10: 0.0690 - val_loss: 4.2489 - val_r1: 0.2689 - val_r5: 0.4517 - val_r10: 0.5312 - val_p5: 0.0904 - val_p10: 0.0531 - lr: 4.6783e-04 - 48s/epoch - 96ms/step
Epoch 66/1000
502/502 - 24s - loss: 3.0611 - r1: 0.3886 - r5: 0.6099 - r10: 0.6906 - p5: 0.1220 - p10: 0.0691 - val_loss: 4.2724 - val_r1: 0.2662 - val_r5: 0.4481 - val_r10: 0.5265 - val_p5: 0.0896 - val_p10: 0.0526 - lr: 4.6733e-04 - 24s/epoch - 47ms/step
Epoch 67/1000
502/502 - 24s - loss: 3.0575 - r1: 0.3886 - r5: 0.6089 - r10: 0.6904 - p5: 0.1218 - p10: 0.0690 - val_loss: 4.2078 - val_r1: 0.2739 - val_r5: 0.4570 - val_r10: 0.5371 - val_p5: 0.0914 - val_p10: 0.0537 - lr: 4.6684e-04 - 24s/epoch - 47ms/step
Epoch 68/1000
502/502 - 24s - loss: 3.0511 - r1: 0.3905 - r5: 0.6105 - r10: 0.6916 - p5: 0.1221 - p10: 0.0692 - val_loss: 4.2924 - val_r1: 0.2631 - val_r5: 0.4453 - val_r10: 0.5249 - val_p5: 0.0890 - val_p10: 0.0525 - lr: 4.6634e-04 - 24s/epoch - 47ms/step
Epoch 68: early stopping
[92m[INFO] Loading best model...[0m
[93m[WARNING] Model folder already exists...[0m
Model: "ATT2ITM_0"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 172)]        0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 1322)]       0           []                               
                                                                                                  
 embedding (Embedding)          (None, 172, 384)     3389952     ['input_1[0][0]']                
                                                                                                  
 in_rsts (Embedding)            (None, 1322, 384)    507648      ['input_2[0][0]']                
                                                                                                  
 dense (Dense)                  (None, 172, 256)     98560       ['embedding[0][0]']              
                                                                                                  
 dense_2 (Dense)                (None, 1322, 256)    98560       ['in_rsts[0][0]']                
                                                                                                  
 tf.math.not_equal (TFOpLambda)  (None, 172)         0           ['input_1[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 172, 128)     32896       ['dense[0][0]']                  
                                                                                                  
 dense_3 (Dense)                (None, 1322, 128)    32896       ['dense_2[0][0]']                
                                                                                                  
 tf.cast (TFOpLambda)           (None, 172)          0           ['tf.math.not_equal[0][0]']      
                                                                                                  
 word_emb (Lambda)              (None, 172, 128)     0           ['dense_1[0][0]']                
                                                                                                  
 rest_emb (Lambda)              (None, 1322, 128)    0           ['dense_3[0][0]']                
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 172, 1)       0           ['tf.cast[0][0]']                
                                                                                                  
 lambda (Lambda)                (None, 172, 1322)    0           ['word_emb[0][0]',               
                                                                  'rest_emb[0][0]']               
                                                                                                  
 tf.tile (TFOpLambda)           (None, 172, 1322)    0           ['tf.expand_dims[0][0]']         
                                                                                                  
 lambda_1 (Lambda)              (None, 172, 1322)    0           ['lambda[0][0]',                 
                                                                  'tf.tile[0][0]']                
                                                                                                  
 dotprod (Activation)           (None, 172, 1322)    0           ['lambda_1[0][0]']               
                                                                                                  
 dropout (Dropout)              (None, 172, 1322)    0           ['dotprod[0][0]']                
                                                                                                  
 sum (Lambda)                   (None, 1322)         0           ['dropout[0][0]']                
                                                                                                  
 out (Activation)               (None, 1322)         0           ['sum[0][0]']                    
                                                                                                  
==================================================================================================
Total params: 4,160,512
Trainable params: 4,160,512
Non-trainable params: 0
__________________________________________________________________________________________________
None
[92m[INFO] Model already trained. Loading weights...[0m
[93m[WARNING] Model folder already exists...[0m
Model: "ATT2ITM_0"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 172)]        0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 1322)]       0           []                               
                                                                                                  
 embedding (Embedding)          (None, 172, 384)     3389952     ['input_1[0][0]']                
                                                                                                  
 in_rsts (Embedding)            (None, 1322, 384)    507648      ['input_2[0][0]']                
                                                                                                  
 dense (Dense)                  (None, 172, 256)     98560       ['embedding[0][0]']              
                                                                                                  
 dense_2 (Dense)                (None, 1322, 256)    98560       ['in_rsts[0][0]']                
                                                                                                  
 tf.math.not_equal (TFOpLambda)  (None, 172)         0           ['input_1[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 172, 128)     32896       ['dense[0][0]']                  
                                                                                                  
 dense_3 (Dense)                (None, 1322, 128)    32896       ['dense_2[0][0]']                
                                                                                                  
 tf.cast (TFOpLambda)           (None, 172)          0           ['tf.math.not_equal[0][0]']      
                                                                                                  
 word_emb (Lambda)              (None, 172, 128)     0           ['dense_1[0][0]']                
                                                                                                  
 rest_emb (Lambda)              (None, 1322, 128)    0           ['dense_3[0][0]']                
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 172, 1)       0           ['tf.cast[0][0]']                
                                                                                                  
 lambda (Lambda)                (None, 172, 1322)    0           ['word_emb[0][0]',               
                                                                  'rest_emb[0][0]']               
                                                                                                  
 tf.tile (TFOpLambda)           (None, 172, 1322)    0           ['tf.expand_dims[0][0]']         
                                                                                                  
 lambda_1 (Lambda)              (None, 172, 1322)    0           ['lambda[0][0]',                 
                                                                  'tf.tile[0][0]']                
                                                                                                  
 dotprod (Activation)           (None, 172, 1322)    0           ['lambda_1[0][0]']               
                                                                                                  
 dropout (Dropout)              (None, 172, 1322)    0           ['dotprod[0][0]']                
                                                                                                  
 sum (Lambda)                   (None, 1322)         0           ['dropout[0][0]']                
                                                                                                  
 out (Activation)               (None, 1322)         0           ['sum[0][0]']                    
                                                                                                  
==================================================================================================
Total params: 4,160,512
Trainable params: 4,160,512
Non-trainable params: 0
__________________________________________________________________________________________________
None
[92m[INFO] Model already trained. Loading weights...[0m
[93m[WARNING] Model folder already exists...[0m
Model: "ATT2ITM_0"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 172)]        0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 1322)]       0           []                               
                                                                                                  
 embedding (Embedding)          (None, 172, 384)     3389952     ['input_1[0][0]']                
                                                                                                  
 in_rsts (Embedding)            (None, 1322, 384)    507648      ['input_2[0][0]']                
                                                                                                  
 dense (Dense)                  (None, 172, 256)     98560       ['embedding[0][0]']              
                                                                                                  
 dense_2 (Dense)                (None, 1322, 256)    98560       ['in_rsts[0][0]']                
                                                                                                  
 tf.math.not_equal (TFOpLambda)  (None, 172)         0           ['input_1[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 172, 128)     32896       ['dense[0][0]']                  
                                                                                                  
 dense_3 (Dense)                (None, 1322, 128)    32896       ['dense_2[0][0]']                
                                                                                                  
 tf.cast (TFOpLambda)           (None, 172)          0           ['tf.math.not_equal[0][0]']      
                                                                                                  
 word_emb (Lambda)              (None, 172, 128)     0           ['dense_1[0][0]']                
                                                                                                  
 rest_emb (Lambda)              (None, 1322, 128)    0           ['dense_3[0][0]']                
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 172, 1)       0           ['tf.cast[0][0]']                
                                                                                                  
 lambda (Lambda)                (None, 172, 1322)    0           ['word_emb[0][0]',               
                                                                  'rest_emb[0][0]']               
                                                                                                  
 tf.tile (TFOpLambda)           (None, 172, 1322)    0           ['tf.expand_dims[0][0]']         
                                                                                                  
 lambda_1 (Lambda)              (None, 172, 1322)    0           ['lambda[0][0]',                 
                                                                  'tf.tile[0][0]']                
                                                                                                  
 dotprod (Activation)           (None, 172, 1322)    0           ['lambda_1[0][0]']               
                                                                                                  
 dropout (Dropout)              (None, 172, 1322)    0           ['dotprod[0][0]']                
                                                                                                  
 sum (Lambda)                   (None, 1322)         0           ['dropout[0][0]']                
                                                                                                  
 out (Activation)               (None, 1322)         0           ['sum[0][0]']                    
                                                                                                  
==================================================================================================
Total params: 4,160,512
Trainable params: 4,160,512
Non-trainable params: 0
__________________________________________________________________________________________________
None
[92m[INFO] Model already trained. Loading weights...[0m
[93m[WARNING] Model folder already exists...[0m
Model: "ATT2ITM_0"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 172)]        0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 1322)]       0           []                               
                                                                                                  
 embedding (Embedding)          (None, 172, 384)     3389952     ['input_1[0][0]']                
                                                                                                  
 in_rsts (Embedding)            (None, 1322, 384)    507648      ['input_2[0][0]']                
                                                                                                  
 dense (Dense)                  (None, 172, 256)     98560       ['embedding[0][0]']              
                                                                                                  
 dense_2 (Dense)                (None, 1322, 256)    98560       ['in_rsts[0][0]']                
                                                                                                  
 tf.math.not_equal (TFOpLambda)  (None, 172)         0           ['input_1[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 172, 128)     32896       ['dense[0][0]']                  
                                                                                                  
 dense_3 (Dense)                (None, 1322, 128)    32896       ['dense_2[0][0]']                
                                                                                                  
 tf.cast (TFOpLambda)           (None, 172)          0           ['tf.math.not_equal[0][0]']      
                                                                                                  
 word_emb (Lambda)              (None, 172, 128)     0           ['dense_1[0][0]']                
                                                                                                  
 rest_emb (Lambda)              (None, 1322, 128)    0           ['dense_3[0][0]']                
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 172, 1)       0           ['tf.cast[0][0]']                
                                                                                                  
 lambda (Lambda)                (None, 172, 1322)    0           ['word_emb[0][0]',               
                                                                  'rest_emb[0][0]']               
                                                                                                  
 tf.tile (TFOpLambda)           (None, 172, 1322)    0           ['tf.expand_dims[0][0]']         
                                                                                                  
 lambda_1 (Lambda)              (None, 172, 1322)    0           ['lambda[0][0]',                 
                                                                  'tf.tile[0][0]']                
                                                                                                  
 dotprod (Activation)           (None, 172, 1322)    0           ['lambda_1[0][0]']               
                                                                                                  
 dropout (Dropout)              (None, 172, 1322)    0           ['dotprod[0][0]']                
                                                                                                  
 sum (Lambda)                   (None, 1322)         0           ['dropout[0][0]']                
                                                                                                  
 out (Activation)               (None, 1322)         0           ['sum[0][0]']                    
                                                                                                  
==================================================================================================
Total params: 4,160,512
Trainable params: 4,160,512
Non-trainable params: 0
__________________________________________________________________________________________________
None
[92m[INFO] Model already trained. Loading weights...[0m
