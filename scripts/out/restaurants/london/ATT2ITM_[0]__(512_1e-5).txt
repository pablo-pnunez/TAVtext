Model: "ATT2ITM_0"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 232)]        0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 4882)]       0           []                               
                                                                                                  
 embedding (Embedding)          (None, 232, 384)     7757952     ['input_1[0][0]']                
                                                                                                  
 in_rsts (Embedding)            (None, 4882, 384)    1874688     ['input_2[0][0]']                
                                                                                                  
 dense (Dense)                  (None, 232, 256)     98560       ['embedding[0][0]']              
                                                                                                  
 dense_2 (Dense)                (None, 4882, 256)    98560       ['in_rsts[0][0]']                
                                                                                                  
 tf.math.not_equal (TFOpLambda)  (None, 232)         0           ['input_1[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 232, 128)     32896       ['dense[0][0]']                  
                                                                                                  
 dense_3 (Dense)                (None, 4882, 128)    32896       ['dense_2[0][0]']                
                                                                                                  
 tf.cast (TFOpLambda)           (None, 232)          0           ['tf.math.not_equal[0][0]']      
                                                                                                  
 word_emb (Lambda)              (None, 232, 128)     0           ['dense_1[0][0]']                
                                                                                                  
 rest_emb (Lambda)              (None, 4882, 128)    0           ['dense_3[0][0]']                
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 232, 1)       0           ['tf.cast[0][0]']                
                                                                                                  
 lambda (Lambda)                (None, 232, 4882)    0           ['word_emb[0][0]',               
                                                                  'rest_emb[0][0]']               
                                                                                                  
 tf.tile (TFOpLambda)           (None, 232, 4882)    0           ['tf.expand_dims[0][0]']         
                                                                                                  
 lambda_1 (Lambda)              (None, 232, 4882)    0           ['lambda[0][0]',                 
                                                                  'tf.tile[0][0]']                
                                                                                                  
 dotprod (Activation)           (None, 232, 4882)    0           ['lambda_1[0][0]']               
                                                                                                  
 dropout (Dropout)              (None, 232, 4882)    0           ['dotprod[0][0]']                
                                                                                                  
 sum (Lambda)                   (None, 4882)         0           ['dropout[0][0]']                
                                                                                                  
 out (Activation)               (None, 4882)         0           ['sum[0][0]']                    
                                                                                                  
==================================================================================================
Total params: 9,895,552
Trainable params: 9,895,552
Non-trainable params: 0
__________________________________________________________________________________________________
None
Epoch 1/1000
Model: "ATT2ITM_0"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 232)]        0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 4882)]       0           []                               
                                                                                                  
 embedding (Embedding)          (None, 232, 384)     7757952     ['input_1[0][0]']                
                                                                                                  
 in_rsts (Embedding)            (None, 4882, 384)    1874688     ['input_2[0][0]']                
                                                                                                  
 dense (Dense)                  (None, 232, 256)     98560       ['embedding[0][0]']              
                                                                                                  
 dense_2 (Dense)                (None, 4882, 256)    98560       ['in_rsts[0][0]']                
                                                                                                  
 tf.math.not_equal (TFOpLambda)  (None, 232)         0           ['input_1[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 232, 128)     32896       ['dense[0][0]']                  
                                                                                                  
 dense_3 (Dense)                (None, 4882, 128)    32896       ['dense_2[0][0]']                
                                                                                                  
 tf.cast (TFOpLambda)           (None, 232)          0           ['tf.math.not_equal[0][0]']      
                                                                                                  
 word_emb (Lambda)              (None, 232, 128)     0           ['dense_1[0][0]']                
                                                                                                  
 rest_emb (Lambda)              (None, 4882, 128)    0           ['dense_3[0][0]']                
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 232, 1)       0           ['tf.cast[0][0]']                
                                                                                                  
 lambda (Lambda)                (None, 232, 4882)    0           ['word_emb[0][0]',               
                                                                  'rest_emb[0][0]']               
                                                                                                  
 tf.tile (TFOpLambda)           (None, 232, 4882)    0           ['tf.expand_dims[0][0]']         
                                                                                                  
 lambda_1 (Lambda)              (None, 232, 4882)    0           ['lambda[0][0]',                 
                                                                  'tf.tile[0][0]']                
                                                                                                  
 dotprod (Activation)           (None, 232, 4882)    0           ['lambda_1[0][0]']               
                                                                                                  
 dropout (Dropout)              (None, 232, 4882)    0           ['dotprod[0][0]']                
                                                                                                  
 sum (Lambda)                   (None, 4882)         0           ['dropout[0][0]']                
                                                                                                  
 out (Activation)               (None, 4882)         0           ['sum[0][0]']                    
                                                                                                  
==================================================================================================
Total params: 9,895,552
Trainable params: 9,895,552
Non-trainable params: 0
__________________________________________________________________________________________________
None
Epoch 1/1000
3012/3012 - 545s - loss: 8.1359 - r1: 0.0067 - r5: 0.0215 - r10: 0.0342 - p5: 0.0043 - p10: 0.0034 - val_loss: 8.0497 - val_r1: 0.0235 - val_r5: 0.0564 - val_r10: 0.0771 - val_p5: 0.0113 - val_p10: 0.0077 - lr: 9.9901e-06 - 545s/epoch - 181ms/step
Epoch 2/1000
3012/3012 - 662s - loss: 7.6831 - r1: 0.0190 - r5: 0.0509 - r10: 0.0738 - p5: 0.0102 - p10: 0.0074 - val_loss: 7.5559 - val_r1: 0.0450 - val_r5: 0.1022 - val_r10: 0.1362 - val_p5: 0.0204 - val_p10: 0.0136 - lr: 9.9802e-06 - 662s/epoch - 220ms/step
Epoch 3/1000
3012/3012 - 675s - loss: 7.2223 - r1: 0.0366 - r5: 0.0900 - r10: 0.1250 - p5: 0.0180 - p10: 0.0125 - val_loss: 7.0538 - val_r1: 0.0662 - val_r5: 0.1457 - val_r10: 0.1928 - val_p5: 0.0291 - val_p10: 0.0193 - lr: 9.9703e-06 - 675s/epoch - 224ms/step
Epoch 4/1000
3012/3012 - 765s - loss: 6.8276 - r1: 0.0523 - r5: 0.1218 - r10: 0.1658 - p5: 0.0244 - p10: 0.0166 - val_loss: 6.7333 - val_r1: 0.0833 - val_r5: 0.1752 - val_r10: 0.2296 - val_p5: 0.0350 - val_p10: 0.0230 - lr: 9.9604e-06 - 765s/epoch - 254ms/step
Epoch 5/1000
3012/3012 - 662s - loss: 6.5512 - r1: 0.0667 - r5: 0.1482 - r10: 0.1980 - p5: 0.0296 - p10: 0.0198 - val_loss: 6.4322 - val_r1: 0.1055 - val_r5: 0.2123 - val_r10: 0.2725 - val_p5: 0.0425 - val_p10: 0.0272 - lr: 9.9505e-06 - 662s/epoch - 220ms/step
Epoch 6/1000
3012/3012 - 672s - loss: 6.3494 - r1: 0.0792 - r5: 0.1707 - r10: 0.2250 - p5: 0.0341 - p10: 0.0225 - val_loss: 6.2386 - val_r1: 0.1218 - val_r5: 0.2385 - val_r10: 0.3023 - val_p5: 0.0477 - val_p10: 0.0302 - lr: 9.9406e-06 - 672s/epoch - 223ms/step
Epoch 7/1000
3012/3012 - 673s - loss: 6.1922 - r1: 0.0901 - r5: 0.1896 - r10: 0.2474 - p5: 0.0379 - p10: 0.0247 - val_loss: 6.1112 - val_r1: 0.1328 - val_r5: 0.2562 - val_r10: 0.3213 - val_p5: 0.0512 - val_p10: 0.0321 - lr: 9.9307e-06 - 673s/epoch - 224ms/step
Epoch 8/1000
3012/3012 - 680s - loss: 6.0649 - r1: 0.0991 - r5: 0.2055 - r10: 0.2655 - p5: 0.0411 - p10: 0.0265 - val_loss: 5.9996 - val_r1: 0.1433 - val_r5: 0.2724 - val_r10: 0.3397 - val_p5: 0.0545 - val_p10: 0.0340 - lr: 9.9208e-06 - 680s/epoch - 226ms/step
Epoch 9/1000
3012/3012 - 698s - loss: 5.9597 - r1: 0.1074 - r5: 0.2190 - r10: 0.2811 - p5: 0.0438 - p10: 0.0281 - val_loss: 5.9018 - val_r1: 0.1527 - val_r5: 0.2861 - val_r10: 0.3547 - val_p5: 0.0572 - val_p10: 0.0355 - lr: 9.9109e-06 - 698s/epoch - 232ms/step
Epoch 10/1000
3012/3012 - 752s - loss: 5.8708 - r1: 0.1144 - r5: 0.2310 - r10: 0.2952 - p5: 0.0462 - p10: 0.0295 - val_loss: 5.8186 - val_r1: 0.1606 - val_r5: 0.2974 - val_r10: 0.3675 - val_p5: 0.0595 - val_p10: 0.0368 - lr: 9.9010e-06 - 752s/epoch - 250ms/step
Epoch 11/1000
3012/3012 - 864s - loss: 5.7951 - r1: 0.1210 - r5: 0.2412 - r10: 0.3066 - p5: 0.0482 - p10: 0.0307 - val_loss: 5.7554 - val_r1: 0.1668 - val_r5: 0.3057 - val_r10: 0.3758 - val_p5: 0.0611 - val_p10: 0.0376 - lr: 9.8911e-06 - 864s/epoch - 287ms/step
Epoch 12/1000
3012/3012 - 805s - loss: 5.7288 - r1: 0.1271 - r5: 0.2507 - r10: 0.3171 - p5: 0.0501 - p10: 0.0317 - val_loss: 5.7130 - val_r1: 0.1683 - val_r5: 0.3085 - val_r10: 0.3797 - val_p5: 0.0617 - val_p10: 0.0380 - lr: 9.8812e-06 - 805s/epoch - 267ms/step
Epoch 13/1000
3012/3012 - 891s - loss: 5.6738 - r1: 0.1316 - r5: 0.2582 - r10: 0.3256 - p5: 0.0516 - p10: 0.0326 - val_loss: 5.6734 - val_r1: 0.1701 - val_r5: 0.3112 - val_r10: 0.3832 - val_p5: 0.0622 - val_p10: 0.0383 - lr: 9.8713e-06 - 891s/epoch - 296ms/step
Epoch 14/1000
3012/3012 - 977s - loss: 5.6258 - r1: 0.1364 - r5: 0.2654 - r10: 0.3336 - p5: 0.0531 - p10: 0.0334 - val_loss: 5.6352 - val_r1: 0.1729 - val_r5: 0.3155 - val_r10: 0.3872 - val_p5: 0.0631 - val_p10: 0.0387 - lr: 9.8614e-06 - 977s/epoch - 324ms/step
Epoch 15/1000
3012/3012 - 973s - loss: 5.5813 - r1: 0.1405 - r5: 0.2719 - r10: 0.3403 - p5: 0.0544 - p10: 0.0340 - val_loss: 5.6174 - val_r1: 0.1733 - val_r5: 0.3170 - val_r10: 0.3889 - val_p5: 0.0634 - val_p10: 0.0389 - lr: 9.8515e-06 - 973s/epoch - 323ms/step
Epoch 16/1000
3012/3012 - 1044s - loss: 5.5410 - r1: 0.1444 - r5: 0.2777 - r10: 0.3466 - p5: 0.0555 - p10: 0.0347 - val_loss: 5.5636 - val_r1: 0.1797 - val_r5: 0.3259 - val_r10: 0.3984 - val_p5: 0.0652 - val_p10: 0.0398 - lr: 9.8416e-06 - 1044s/epoch - 347ms/step
Epoch 17/1000
3012/3012 - 1116s - loss: 5.5061 - r1: 0.1475 - r5: 0.2825 - r10: 0.3521 - p5: 0.0565 - p10: 0.0352 - val_loss: 5.5656 - val_r1: 0.1798 - val_r5: 0.3260 - val_r10: 0.3985 - val_p5: 0.0652 - val_p10: 0.0398 - lr: 9.8317e-06 - 1116s/epoch - 371ms/step
Epoch 18/1000
3012/3012 - 1132s - loss: 5.4734 - r1: 0.1509 - r5: 0.2876 - r10: 0.3575 - p5: 0.0575 - p10: 0.0358 - val_loss: 5.5355 - val_r1: 0.1842 - val_r5: 0.3319 - val_r10: 0.4044 - val_p5: 0.0664 - val_p10: 0.0404 - lr: 9.8218e-06 - 1132s/epoch - 376ms/step
Epoch 19/1000
3012/3012 - 1183s - loss: 5.4452 - r1: 0.1538 - r5: 0.2921 - r10: 0.3623 - p5: 0.0584 - p10: 0.0362 - val_loss: 5.5239 - val_r1: 0.1857 - val_r5: 0.3331 - val_r10: 0.4060 - val_p5: 0.0666 - val_p10: 0.0406 - lr: 9.8119e-06 - 1183s/epoch - 393ms/step
Epoch 20/1000
3012/3012 - 1134s - loss: 5.4190 - r1: 0.1568 - r5: 0.2955 - r10: 0.3667 - p5: 0.0591 - p10: 0.0367 - val_loss: 5.6142 - val_r1: 0.1696 - val_r5: 0.3136 - val_r10: 0.3857 - val_p5: 0.0627 - val_p10: 0.0386 - lr: 9.8020e-06 - 1134s/epoch - 376ms/step
Epoch 21/1000
3012/3012 - 1160s - loss: 5.3925 - r1: 0.1593 - r5: 0.2998 - r10: 0.3708 - p5: 0.0600 - p10: 0.0371 - val_loss: 5.5903 - val_r1: 0.1704 - val_r5: 0.3139 - val_r10: 0.3871 - val_p5: 0.0628 - val_p10: 0.0387 - lr: 9.7921e-06 - 1160s/epoch - 385ms/step
Epoch 22/1000
3012/3012 - 1167s - loss: 5.3702 - r1: 0.1614 - r5: 0.3030 - r10: 0.3744 - p5: 0.0606 - p10: 0.0374 - val_loss: 5.5527 - val_r1: 0.1740 - val_r5: 0.3198 - val_r10: 0.3926 - val_p5: 0.0640 - val_p10: 0.0393 - lr: 9.7822e-06 - 1167s/epoch - 387ms/step
Epoch 23/1000
3012/3012 - 1221s - loss: 5.3475 - r1: 0.1636 - r5: 0.3065 - r10: 0.3781 - p5: 0.0613 - p10: 0.0378 - val_loss: 5.5189 - val_r1: 0.1782 - val_r5: 0.3257 - val_r10: 0.3990 - val_p5: 0.0651 - val_p10: 0.0399 - lr: 9.7723e-06 - 1221s/epoch - 405ms/step
Epoch 24/1000
3012/3012 - 1248s - loss: 5.3256 - r1: 0.1662 - r5: 0.3096 - r10: 0.3816 - p5: 0.0619 - p10: 0.0382 - val_loss: 5.5087 - val_r1: 0.1792 - val_r5: 0.3272 - val_r10: 0.4006 - val_p5: 0.0654 - val_p10: 0.0401 - lr: 9.7624e-06 - 1248s/epoch - 414ms/step
Epoch 25/1000
3012/3012 - 1262s - loss: 5.3052 - r1: 0.1681 - r5: 0.3128 - r10: 0.3849 - p5: 0.0626 - p10: 0.0385 - val_loss: 5.4964 - val_r1: 0.1797 - val_r5: 0.3292 - val_r10: 0.4032 - val_p5: 0.0658 - val_p10: 0.0403 - lr: 9.7525e-06 - 1262s/epoch - 419ms/step
Epoch 26/1000
3012/3012 - 1287s - loss: 5.2927 - r1: 0.1692 - r5: 0.3151 - r10: 0.3876 - p5: 0.0630 - p10: 0.0388 - val_loss: 5.4789 - val_r1: 0.1810 - val_r5: 0.3320 - val_r10: 0.4055 - val_p5: 0.0664 - val_p10: 0.0406 - lr: 9.7426e-06 - 1287s/epoch - 427ms/step
Epoch 27/1000
3012/3012 - 1315s - loss: 5.2774 - r1: 0.1707 - r5: 0.3173 - r10: 0.3901 - p5: 0.0635 - p10: 0.0390 - val_loss: 5.3013 - val_r1: 0.2065 - val_r5: 0.3640 - val_r10: 0.4392 - val_p5: 0.0728 - val_p10: 0.0439 - lr: 9.7327e-06 - 1315s/epoch - 437ms/step
Epoch 28/1000
3012/3012 - 1310s - loss: 5.2608 - r1: 0.1727 - r5: 0.3196 - r10: 0.3926 - p5: 0.0639 - p10: 0.0393 - val_loss: 5.3696 - val_r1: 0.1935 - val_r5: 0.3472 - val_r10: 0.4225 - val_p5: 0.0694 - val_p10: 0.0422 - lr: 9.7228e-06 - 1310s/epoch - 435ms/step
Epoch 29/1000
3012/3012 - 1318s - loss: 5.2454 - r1: 0.1739 - r5: 0.3221 - r10: 0.3951 - p5: 0.0644 - p10: 0.0395 - val_loss: 5.3432 - val_r1: 0.1947 - val_r5: 0.3490 - val_r10: 0.4242 - val_p5: 0.0698 - val_p10: 0.0424 - lr: 9.7129e-06 - 1318s/epoch - 437ms/step
Epoch 30/1000
3012/3012 - 1338s - loss: 5.2312 - r1: 0.1759 - r5: 0.3246 - r10: 0.3973 - p5: 0.0649 - p10: 0.0397 - val_loss: 5.3274 - val_r1: 0.1953 - val_r5: 0.3503 - val_r10: 0.4258 - val_p5: 0.0701 - val_p10: 0.0426 - lr: 9.7030e-06 - 1338s/epoch - 444ms/step
Epoch 31/1000
3012/3012 - 1332s - loss: 5.2155 - r1: 0.1780 - r5: 0.3265 - r10: 0.3993 - p5: 0.0653 - p10: 0.0399 - val_loss: 5.3372 - val_r1: 0.1935 - val_r5: 0.3471 - val_r10: 0.4238 - val_p5: 0.0694 - val_p10: 0.0424 - lr: 9.6931e-06 - 1332s/epoch - 442ms/step
Epoch 32/1000
3012/3012 - 1330s - loss: 5.1992 - r1: 0.1792 - r5: 0.3290 - r10: 0.4019 - p5: 0.0658 - p10: 0.0402 - val_loss: 5.2910 - val_r1: 0.2011 - val_r5: 0.3573 - val_r10: 0.4334 - val_p5: 0.0715 - val_p10: 0.0433 - lr: 9.6832e-06 - 1330s/epoch - 441ms/step
Epoch 33/1000
3012/3012 - 1308s - loss: 5.1855 - r1: 0.1814 - r5: 0.3312 - r10: 0.4045 - p5: 0.0662 - p10: 0.0405 - val_loss: 5.3560 - val_r1: 0.1899 - val_r5: 0.3428 - val_r10: 0.4182 - val_p5: 0.0686 - val_p10: 0.0418 - lr: 9.6733e-06 - 1308s/epoch - 434ms/step
Epoch 34/1000
3012/3012 - 1331s - loss: 5.1758 - r1: 0.1821 - r5: 0.3326 - r10: 0.4057 - p5: 0.0665 - p10: 0.0406 - val_loss: 5.1743 - val_r1: 0.2148 - val_r5: 0.3773 - val_r10: 0.4530 - val_p5: 0.0755 - val_p10: 0.0453 - lr: 9.6634e-06 - 1331s/epoch - 442ms/step
Epoch 35/1000
3012/3012 - 1353s - loss: 5.1628 - r1: 0.1833 - r5: 0.3345 - r10: 0.4075 - p5: 0.0669 - p10: 0.0408 - val_loss: 5.2356 - val_r1: 0.2067 - val_r5: 0.3652 - val_r10: 0.4409 - val_p5: 0.0730 - val_p10: 0.0441 - lr: 9.6535e-06 - 1353s/epoch - 449ms/step
Epoch 36/1000
3012/3012 - 1382s - loss: 5.1468 - r1: 0.1850 - r5: 0.3366 - r10: 0.4099 - p5: 0.0673 - p10: 0.0410 - val_loss: 5.2098 - val_r1: 0.2113 - val_r5: 0.3705 - val_r10: 0.4450 - val_p5: 0.0741 - val_p10: 0.0445 - lr: 9.6436e-06 - 1382s/epoch - 459ms/step
Epoch 37/1000
3012/3012 - 1383s - loss: 5.1331 - r1: 0.1863 - r5: 0.3390 - r10: 0.4124 - p5: 0.0678 - p10: 0.0412 - val_loss: 5.1860 - val_r1: 0.2124 - val_r5: 0.3730 - val_r10: 0.4478 - val_p5: 0.0746 - val_p10: 0.0448 - lr: 9.6337e-06 - 1383s/epoch - 459ms/step
Epoch 38/1000
3012/3012 - 1371s - loss: 5.1185 - r1: 0.1883 - r5: 0.3409 - r10: 0.4145 - p5: 0.0682 - p10: 0.0414 - val_loss: 5.1639 - val_r1: 0.2146 - val_r5: 0.3747 - val_r10: 0.4499 - val_p5: 0.0749 - val_p10: 0.0450 - lr: 9.6238e-06 - 1371s/epoch - 455ms/step
Epoch 39/1000
3012/3012 - 1372s - loss: 5.1040 - r1: 0.1898 - r5: 0.3429 - r10: 0.4168 - p5: 0.0686 - p10: 0.0417 - val_loss: 5.1395 - val_r1: 0.2162 - val_r5: 0.3795 - val_r10: 0.4541 - val_p5: 0.0759 - val_p10: 0.0454 - lr: 9.6139e-06 - 1372s/epoch - 456ms/step
Epoch 40/1000
3012/3012 - 1421s - loss: 5.0894 - r1: 0.1913 - r5: 0.3451 - r10: 0.4187 - p5: 0.0690 - p10: 0.0419 - val_loss: 5.1259 - val_r1: 0.2188 - val_r5: 0.3801 - val_r10: 0.4558 - val_p5: 0.0760 - val_p10: 0.0456 - lr: 9.6040e-06 - 1421s/epoch - 472ms/step
Epoch 41/1000
3012/3012 - 1413s - loss: 5.0784 - r1: 0.1929 - r5: 0.3471 - r10: 0.4207 - p5: 0.0694 - p10: 0.0421 - val_loss: 5.2045 - val_r1: 0.2065 - val_r5: 0.3648 - val_r10: 0.4404 - val_p5: 0.0730 - val_p10: 0.0440 - lr: 9.5941e-06 - 1413s/epoch - 469ms/step
Epoch 42/1000
3012/3012 - 1435s - loss: 5.0712 - r1: 0.1936 - r5: 0.3479 - r10: 0.4218 - p5: 0.0696 - p10: 0.0422 - val_loss: 5.1000 - val_r1: 0.2243 - val_r5: 0.3857 - val_r10: 0.4605 - val_p5: 0.0771 - val_p10: 0.0461 - lr: 9.5842e-06 - 1435s/epoch - 476ms/step
Epoch 43/1000
3012/3012 - 1421s - loss: 5.0581 - r1: 0.1957 - r5: 0.3503 - r10: 0.4238 - p5: 0.0701 - p10: 0.0424 - val_loss: 5.1683 - val_r1: 0.2119 - val_r5: 0.3713 - val_r10: 0.4468 - val_p5: 0.0742 - val_p10: 0.0447 - lr: 9.5743e-06 - 1421s/epoch - 472ms/step
Epoch 44/1000
3012/3012 - 1398s - loss: 5.0504 - r1: 0.1960 - r5: 0.3515 - r10: 0.4254 - p5: 0.0703 - p10: 0.0425 - val_loss: 5.1938 - val_r1: 0.2045 - val_r5: 0.3623 - val_r10: 0.4380 - val_p5: 0.0725 - val_p10: 0.0438 - lr: 9.5644e-06 - 1398s/epoch - 464ms/step
Epoch 45/1000
3012/3012 - 1386s - loss: 5.0457 - r1: 0.1964 - r5: 0.3519 - r10: 0.4256 - p5: 0.0704 - p10: 0.0426 - val_loss: 5.1930 - val_r1: 0.2058 - val_r5: 0.3639 - val_r10: 0.4391 - val_p5: 0.0728 - val_p10: 0.0439 - lr: 9.5545e-06 - 1386s/epoch - 460ms/step
Epoch 46/1000
3012/3012 - 1425s - loss: 5.0329 - r1: 0.1979 - r5: 0.3539 - r10: 0.4274 - p5: 0.0708 - p10: 0.0427 - val_loss: 5.0779 - val_r1: 0.2248 - val_r5: 0.3865 - val_r10: 0.4618 - val_p5: 0.0773 - val_p10: 0.0462 - lr: 9.5446e-06 - 1425s/epoch - 473ms/step
Epoch 47/1000
3012/3012 - 1457s - loss: 5.0219 - r1: 0.1992 - r5: 0.3559 - r10: 0.4297 - p5: 0.0712 - p10: 0.0430 - val_loss: 5.0325 - val_r1: 0.2330 - val_r5: 0.3950 - val_r10: 0.4701 - val_p5: 0.0790 - val_p10: 0.0470 - lr: 9.5347e-06 - 1457s/epoch - 484ms/step
Epoch 48/1000
3012/3012 - 1448s - loss: 5.0073 - r1: 0.2014 - r5: 0.3576 - r10: 0.4316 - p5: 0.0715 - p10: 0.0432 - val_loss: 4.9924 - val_r1: 0.2389 - val_r5: 0.4024 - val_r10: 0.4769 - val_p5: 0.0805 - val_p10: 0.0477 - lr: 9.5248e-06 - 1448s/epoch - 481ms/step
Epoch 49/1000
3012/3012 - 1403s - loss: 4.9978 - r1: 0.2017 - r5: 0.3591 - r10: 0.4330 - p5: 0.0718 - p10: 0.0433 - val_loss: 5.0442 - val_r1: 0.2301 - val_r5: 0.3918 - val_r10: 0.4667 - val_p5: 0.0784 - val_p10: 0.0467 - lr: 9.5149e-06 - 1403s/epoch - 466ms/step
Epoch 50/1000
3012/3012 - 1441s - loss: 4.9903 - r1: 0.2027 - r5: 0.3603 - r10: 0.4343 - p5: 0.0721 - p10: 0.0434 - val_loss: 4.9697 - val_r1: 0.2435 - val_r5: 0.4067 - val_r10: 0.4821 - val_p5: 0.0813 - val_p10: 0.0482 - lr: 9.5050e-06 - 1441s/epoch - 478ms/step
Epoch 51/1000
3012/3012 - 1434s - loss: 4.9769 - r1: 0.2045 - r5: 0.3623 - r10: 0.4362 - p5: 0.0725 - p10: 0.0436 - val_loss: 4.9446 - val_r1: 0.2474 - val_r5: 0.4124 - val_r10: 0.4877 - val_p5: 0.0825 - val_p10: 0.0488 - lr: 9.4951e-06 - 1434s/epoch - 476ms/step
Epoch 52/1000
3012/3012 - 1441s - loss: 4.9651 - r1: 0.2059 - r5: 0.3642 - r10: 0.4382 - p5: 0.0728 - p10: 0.0438 - val_loss: 4.9161 - val_r1: 0.2521 - val_r5: 0.4176 - val_r10: 0.4928 - val_p5: 0.0835 - val_p10: 0.0493 - lr: 9.4852e-06 - 1441s/epoch - 479ms/step
Epoch 53/1000
3012/3012 - 1422s - loss: 4.9560 - r1: 0.2073 - r5: 0.3653 - r10: 0.4393 - p5: 0.0731 - p10: 0.0439 - val_loss: 4.9389 - val_r1: 0.2498 - val_r5: 0.4150 - val_r10: 0.4899 - val_p5: 0.0830 - val_p10: 0.0490 - lr: 9.4753e-06 - 1422s/epoch - 472ms/step
Epoch 54/1000
3012/3012 - 1372s - loss: 4.9444 - r1: 0.2082 - r5: 0.3673 - r10: 0.4414 - p5: 0.0735 - p10: 0.0441 - val_loss: 4.9420 - val_r1: 0.2517 - val_r5: 0.4160 - val_r10: 0.4899 - val_p5: 0.0832 - val_p10: 0.0490 - lr: 9.4654e-06 - 1372s/epoch - 456ms/step
Epoch 55/1000
3012/3012 - 1394s - loss: 4.9346 - r1: 0.2095 - r5: 0.3688 - r10: 0.4431 - p5: 0.0738 - p10: 0.0443 - val_loss: 5.0266 - val_r1: 0.2376 - val_r5: 0.3995 - val_r10: 0.4740 - val_p5: 0.0799 - val_p10: 0.0474 - lr: 9.4555e-06 - 1394s/epoch - 463ms/step
Epoch 56/1000
3012/3012 - 1408s - loss: 4.9273 - r1: 0.2101 - r5: 0.3703 - r10: 0.4443 - p5: 0.0741 - p10: 0.0444 - val_loss: 5.0048 - val_r1: 0.2378 - val_r5: 0.4019 - val_r10: 0.4766 - val_p5: 0.0804 - val_p10: 0.0477 - lr: 9.4456e-06 - 1408s/epoch - 467ms/step
Epoch 57/1000
3012/3012 - 1413s - loss: 4.9203 - r1: 0.2109 - r5: 0.3711 - r10: 0.4451 - p5: 0.0742 - p10: 0.0445 - val_loss: 4.9214 - val_r1: 0.2494 - val_r5: 0.4160 - val_r10: 0.4914 - val_p5: 0.0832 - val_p10: 0.0491 - lr: 9.4357e-06 - 1413s/epoch - 469ms/step
Epoch 58/1000
3012/3012 - 1415s - loss: 4.9120 - r1: 0.2121 - r5: 0.3719 - r10: 0.4463 - p5: 0.0744 - p10: 0.0446 - val_loss: 5.0059 - val_r1: 0.2374 - val_r5: 0.4007 - val_r10: 0.4754 - val_p5: 0.0801 - val_p10: 0.0475 - lr: 9.4258e-06 - 1415s/epoch - 470ms/step
Epoch 59/1000
3012/3012 - 1418s - loss: 4.9062 - r1: 0.2125 - r5: 0.3732 - r10: 0.4477 - p5: 0.0746 - p10: 0.0448 - val_loss: 5.0213 - val_r1: 0.2334 - val_r5: 0.3968 - val_r10: 0.4716 - val_p5: 0.0794 - val_p10: 0.0472 - lr: 9.4159e-06 - 1418s/epoch - 471ms/step
Epoch 60/1000
3012/3012 - 1464s - loss: 4.8984 - r1: 0.2131 - r5: 0.3742 - r10: 0.4485 - p5: 0.0749 - p10: 0.0449 - val_loss: 4.9071 - val_r1: 0.2513 - val_r5: 0.4170 - val_r10: 0.4916 - val_p5: 0.0834 - val_p10: 0.0492 - lr: 9.4060e-06 - 1464s/epoch - 486ms/step
Epoch 61/1000
3012/3012 - 1446s - loss: 4.8891 - r1: 0.2142 - r5: 0.3753 - r10: 0.4497 - p5: 0.0751 - p10: 0.0450 - val_loss: 4.9845 - val_r1: 0.2381 - val_r5: 0.4035 - val_r10: 0.4781 - val_p5: 0.0807 - val_p10: 0.0478 - lr: 9.3961e-06 - 1446s/epoch - 480ms/step
Epoch 62/1000
3012/3012 - 1440s - loss: 4.8800 - r1: 0.2157 - r5: 0.3768 - r10: 0.4512 - p5: 0.0754 - p10: 0.0451 - val_loss: 4.9815 - val_r1: 0.2384 - val_r5: 0.4031 - val_r10: 0.4780 - val_p5: 0.0806 - val_p10: 0.0478 - lr: 9.3862e-06 - 1440s/epoch - 478ms/step
Epoch 63/1000
3012/3012 - 1424s - loss: 4.8720 - r1: 0.2163 - r5: 0.3779 - r10: 0.4523 - p5: 0.0756 - p10: 0.0452 - val_loss: 4.9771 - val_r1: 0.2400 - val_r5: 0.4048 - val_r10: 0.4793 - val_p5: 0.0809 - val_p10: 0.0479 - lr: 9.3763e-06 - 1424s/epoch - 473ms/step
Epoch 64/1000
3012/3012 - 1453s - loss: 4.8662 - r1: 0.2169 - r5: 0.3788 - r10: 0.4532 - p5: 0.0758 - p10: 0.0453 - val_loss: 4.9949 - val_r1: 0.2359 - val_r5: 0.4006 - val_r10: 0.4749 - val_p5: 0.0801 - val_p10: 0.0475 - lr: 9.3664e-06 - 1453s/epoch - 483ms/step
Epoch 65/1000
3012/3012 - 1458s - loss: 4.8602 - r1: 0.2174 - r5: 0.3798 - r10: 0.4541 - p5: 0.0760 - p10: 0.0454 - val_loss: 4.9607 - val_r1: 0.2417 - val_r5: 0.4060 - val_r10: 0.4801 - val_p5: 0.0812 - val_p10: 0.0480 - lr: 9.3565e-06 - 1458s/epoch - 484ms/step
Epoch 66/1000
3012/3012 - 1468s - loss: 4.8518 - r1: 0.2186 - r5: 0.3808 - r10: 0.4557 - p5: 0.0762 - p10: 0.0456 - val_loss: 4.8559 - val_r1: 0.2571 - val_r5: 0.4238 - val_r10: 0.4984 - val_p5: 0.0848 - val_p10: 0.0498 - lr: 9.3466e-06 - 1468s/epoch - 487ms/step
Epoch 67/1000
[93m[WARNING] Model folder already exists...[0m
Model: "ATT2ITM_0"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 232)]        0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 4882)]       0           []                               
                                                                                                  
 embedding (Embedding)          (None, 232, 384)     7757952     ['input_1[0][0]']                
                                                                                                  
 in_rsts (Embedding)            (None, 4882, 384)    1874688     ['input_2[0][0]']                
                                                                                                  
 dense (Dense)                  (None, 232, 256)     98560       ['embedding[0][0]']              
                                                                                                  
 dense_2 (Dense)                (None, 4882, 256)    98560       ['in_rsts[0][0]']                
                                                                                                  
 tf.math.not_equal (TFOpLambda)  (None, 232)         0           ['input_1[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 232, 128)     32896       ['dense[0][0]']                  
                                                                                                  
 dense_3 (Dense)                (None, 4882, 128)    32896       ['dense_2[0][0]']                
                                                                                                  
 tf.cast (TFOpLambda)           (None, 232)          0           ['tf.math.not_equal[0][0]']      
                                                                                                  
 word_emb (Lambda)              (None, 232, 128)     0           ['dense_1[0][0]']                
                                                                                                  
 rest_emb (Lambda)              (None, 4882, 128)    0           ['dense_3[0][0]']                
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 232, 1)       0           ['tf.cast[0][0]']                
                                                                                                  
 lambda (Lambda)                (None, 232, 4882)    0           ['word_emb[0][0]',               
                                                                  'rest_emb[0][0]']               
                                                                                                  
 tf.tile (TFOpLambda)           (None, 232, 4882)    0           ['tf.expand_dims[0][0]']         
                                                                                                  
 lambda_1 (Lambda)              (None, 232, 4882)    0           ['lambda[0][0]',                 
                                                                  'tf.tile[0][0]']                
                                                                                                  
 dotprod (Activation)           (None, 232, 4882)    0           ['lambda_1[0][0]']               
                                                                                                  
 dropout (Dropout)              (None, 232, 4882)    0           ['dotprod[0][0]']                
                                                                                                  
 sum (Lambda)                   (None, 4882)         0           ['dropout[0][0]']                
                                                                                                  
 out (Activation)               (None, 4882)         0           ['sum[0][0]']                    
                                                                                                  
==================================================================================================
Total params: 9,895,552
Trainable params: 9,895,552
Non-trainable params: 0
__________________________________________________________________________________________________
None
[92m[INFO] Model already trained. Loading weights...[0m
