Using TensorFlow backend
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 padding_mask (InputLayer)   [(None, None)]               0         []                            
                                                                                                  
 segment_ids (InputLayer)    [(None, None)]               0         []                            
                                                                                                  
 token_ids (InputLayer)      [(None, None)]               0         []                            
                                                                                                  
 bert_backbone (BertBackbon  {'sequence_output': (None,   4385920   ['padding_mask[0][0]',        
 e)                           None, 128),                            'segment_ids[0][0]',         
                              'pooled_output': (None, 1              'token_ids[0][0]']           
                             28)}                                                                 
                                                                                                  
 dropout (Dropout)           (None, None, 128)            0         ['bert_backbone[0][1]']       
                                                                                                  
 tf.__operators__.getitem_1  (None, 128)                  0         ['dropout[0][0]']             
  (SlicingOpLambda)                                                                               
                                                                                                  
 out (Dense)                 (None, 86)                   11094     ['tf.__operators__.getitem_1[0
                                                                    ][0]']                        
                                                                                                  
==================================================================================================
Total params: 4397014 (16.77 MB)
Trainable params: 4397014 (16.77 MB)
Non-trainable params: 0 (0.00 Byte)
__________________________________________________________________________________________________
None
Epoch 1/1000
92/92 - 41s - loss: 3.6695 - NDCG@10: 0.4206 - MAE: 0.4691 - RC@5: 0.4861 - RC@10: 0.5910 - val_loss: 1.7221 - val_NDCG@10: 0.7314 - val_MAE: 0.4405 - val_RC@5: 0.8148 - val_RC@10: 0.8734 - lr: 9.9901e-04 - e_time: 40.8611 - 41s/epoch - 451ms/step
Epoch 2/1000
92/92 - 36s - loss: 1.9063 - NDCG@10: 0.7134 - MAE: 0.4552 - RC@5: 0.7920 - RC@10: 0.8520 - val_loss: 1.2531 - val_NDCG@10: 0.8102 - val_MAE: 0.4346 - val_RC@5: 0.8911 - val_RC@10: 0.9368 - lr: 9.9802e-04 - e_time: 35.8643 - 36s/epoch - 397ms/step
Epoch 3/1000
92/92 - 37s - loss: 1.5096 - NDCG@10: 0.7760 - MAE: 0.4477 - RC@5: 0.8524 - RC@10: 0.9031 - val_loss: 1.1325 - val_NDCG@10: 0.8268 - val_MAE: 0.4159 - val_RC@5: 0.9061 - val_RC@10: 0.9486 - lr: 9.9703e-04 - e_time: 36.0108 - 37s/epoch - 399ms/step
Epoch 4/1000
92/92 - 37s - loss: 1.3149 - NDCG@10: 0.8064 - MAE: 0.4419 - RC@5: 0.8815 - RC@10: 0.9269 - val_loss: 1.0816 - val_NDCG@10: 0.8409 - val_MAE: 0.4109 - val_RC@5: 0.9186 - val_RC@10: 0.9571 - lr: 9.9604e-04 - e_time: 35.9874 - 37s/epoch - 398ms/step
Epoch 5/1000
92/92 - 37s - loss: 1.1983 - NDCG@10: 0.8262 - MAE: 0.4358 - RC@5: 0.8991 - RC@10: 0.9401 - val_loss: 1.0199 - val_NDCG@10: 0.8496 - val_MAE: 0.4055 - val_RC@5: 0.9263 - val_RC@10: 0.9602 - lr: 9.9505e-04 - e_time: 36.0129 - 37s/epoch - 399ms/step
Epoch 6/1000
92/92 - 37s - loss: 1.1024 - NDCG@10: 0.8413 - MAE: 0.4315 - RC@5: 0.9120 - RC@10: 0.9503 - val_loss: 1.0145 - val_NDCG@10: 0.8508 - val_MAE: 0.4056 - val_RC@5: 0.9259 - val_RC@10: 0.9593 - lr: 9.9406e-04 - e_time: 36.0184 - 37s/epoch - 398ms/step
Epoch 7/1000
92/92 - 37s - loss: 1.0324 - NDCG@10: 0.8526 - MAE: 0.4291 - RC@5: 0.9226 - RC@10: 0.9560 - val_loss: 0.9977 - val_NDCG@10: 0.8546 - val_MAE: 0.3956 - val_RC@5: 0.9281 - val_RC@10: 0.9619 - lr: 9.9307e-04 - e_time: 36.0251 - 37s/epoch - 399ms/step
Epoch 8/1000
92/92 - 36s - loss: 0.9667 - NDCG@10: 0.8628 - MAE: 0.4256 - RC@5: 0.9292 - RC@10: 0.9618 - val_loss: 1.0054 - val_NDCG@10: 0.8544 - val_MAE: 0.3939 - val_RC@5: 0.9299 - val_RC@10: 0.9620 - lr: 9.9208e-04 - e_time: 36.0228 - 36s/epoch - 392ms/step
Epoch 9/1000
92/92 - 36s - loss: 0.9248 - NDCG@10: 0.8695 - MAE: 0.4237 - RC@5: 0.9356 - RC@10: 0.9651 - val_loss: 1.0000 - val_NDCG@10: 0.8551 - val_MAE: 0.3902 - val_RC@5: 0.9303 - val_RC@10: 0.9601 - lr: 9.9109e-04 - e_time: 36.0158 - 36s/epoch - 391ms/step
Epoch 10/1000
92/92 - 36s - loss: 0.8847 - NDCG@10: 0.8758 - MAE: 0.4206 - RC@5: 0.9403 - RC@10: 0.9682 - val_loss: 1.0302 - val_NDCG@10: 0.8541 - val_MAE: 0.3870 - val_RC@5: 0.9283 - val_RC@10: 0.9599 - lr: 9.9010e-04 - e_time: 36.0311 - 36s/epoch - 392ms/step
Epoch 11/1000
92/92 - 36s - loss: 0.8496 - NDCG@10: 0.8816 - MAE: 0.4195 - RC@5: 0.9431 - RC@10: 0.9701 - val_loss: 1.0274 - val_NDCG@10: 0.8538 - val_MAE: 0.3815 - val_RC@5: 0.9274 - val_RC@10: 0.9603 - lr: 9.8911e-04 - e_time: 36.0319 - 36s/epoch - 392ms/step
Epoch 12/1000
92/92 - 36s - loss: 0.8089 - NDCG@10: 0.8876 - MAE: 0.4168 - RC@5: 0.9479 - RC@10: 0.9721 - val_loss: 1.0503 - val_NDCG@10: 0.8543 - val_MAE: 0.3752 - val_RC@5: 0.9278 - val_RC@10: 0.9609 - lr: 9.8812e-04 - e_time: 36.0186 - 36s/epoch - 392ms/step
Epoch 13/1000
92/92 - 36s - loss: 0.7795 - NDCG@10: 0.8917 - MAE: 0.4160 - RC@5: 0.9506 - RC@10: 0.9739 - val_loss: 1.0712 - val_NDCG@10: 0.8535 - val_MAE: 0.3726 - val_RC@5: 0.9263 - val_RC@10: 0.9594 - lr: 9.8713e-04 - e_time: 36.0267 - 36s/epoch - 392ms/step
Epoch 14/1000
92/92 - 36s - loss: 0.7482 - NDCG@10: 0.8963 - MAE: 0.4159 - RC@5: 0.9531 - RC@10: 0.9752 - val_loss: 1.1113 - val_NDCG@10: 0.8496 - val_MAE: 0.3725 - val_RC@5: 0.9229 - val_RC@10: 0.9580 - lr: 9.8614e-04 - e_time: 35.9883 - 36s/epoch - 391ms/step
Epoch 15/1000
92/92 - 36s - loss: 0.7253 - NDCG@10: 0.9000 - MAE: 0.4145 - RC@5: 0.9568 - RC@10: 0.9772 - val_loss: 1.1231 - val_NDCG@10: 0.8497 - val_MAE: 0.3671 - val_RC@5: 0.9233 - val_RC@10: 0.9587 - lr: 9.8515e-04 - e_time: 35.9978 - 36s/epoch - 392ms/step
Epoch 16/1000
92/92 - 36s - loss: 0.7036 - NDCG@10: 0.9029 - MAE: 0.4121 - RC@5: 0.9587 - RC@10: 0.9781 - val_loss: 1.1613 - val_NDCG@10: 0.8499 - val_MAE: 0.3683 - val_RC@5: 0.9219 - val_RC@10: 0.9563 - lr: 9.8416e-04 - e_time: 36.0252 - 36s/epoch - 392ms/step
Epoch 17/1000
92/92 - 36s - loss: 0.6854 - NDCG@10: 0.9052 - MAE: 0.4111 - RC@5: 0.9594 - RC@10: 0.9790 - val_loss: 1.1429 - val_NDCG@10: 0.8523 - val_MAE: 0.3670 - val_RC@5: 0.9245 - val_RC@10: 0.9572 - lr: 9.8317e-04 - e_time: 36.0023 - 36s/epoch - 391ms/step
Epoch 18/1000
92/92 - 36s - loss: 0.6644 - NDCG@10: 0.9085 - MAE: 0.4101 - RC@5: 0.9612 - RC@10: 0.9797 - val_loss: 1.1703 - val_NDCG@10: 0.8529 - val_MAE: 0.3616 - val_RC@5: 0.9222 - val_RC@10: 0.9568 - lr: 9.8218e-04 - e_time: 36.0067 - 36s/epoch - 391ms/step
Epoch 19/1000
92/92 - 36s - loss: 0.6513 - NDCG@10: 0.9104 - MAE: 0.4095 - RC@5: 0.9626 - RC@10: 0.9807 - val_loss: 1.1905 - val_NDCG@10: 0.8538 - val_MAE: 0.3601 - val_RC@5: 0.9229 - val_RC@10: 0.9574 - lr: 9.8119e-04 - e_time: 36.0244 - 36s/epoch - 392ms/step
Epoch 20/1000
92/92 - 36s - loss: 0.6349 - NDCG@10: 0.9130 - MAE: 0.4076 - RC@5: 0.9643 - RC@10: 0.9816 - val_loss: 1.2209 - val_NDCG@10: 0.8503 - val_MAE: 0.3591 - val_RC@5: 0.9210 - val_RC@10: 0.9560 - lr: 9.8020e-04 - e_time: 36.0131 - 36s/epoch - 391ms/step
Epoch 21/1000
92/92 - 36s - loss: 0.6136 - NDCG@10: 0.9164 - MAE: 0.4074 - RC@5: 0.9662 - RC@10: 0.9826 - val_loss: 1.2140 - val_NDCG@10: 0.8519 - val_MAE: 0.3625 - val_RC@5: 0.9206 - val_RC@10: 0.9552 - lr: 9.7921e-04 - e_time: 36.0263 - 36s/epoch - 392ms/step
Epoch 22/1000
92/92 - 36s - loss: 0.5966 - NDCG@10: 0.9181 - MAE: 0.4081 - RC@5: 0.9671 - RC@10: 0.9825 - val_loss: 1.2275 - val_NDCG@10: 0.8495 - val_MAE: 0.3606 - val_RC@5: 0.9227 - val_RC@10: 0.9565 - lr: 9.7822e-04 - e_time: 36.0151 - 36s/epoch - 391ms/step
Epoch 23/1000
92/92 - 36s - loss: 0.5834 - NDCG@10: 0.9202 - MAE: 0.4065 - RC@5: 0.9684 - RC@10: 0.9840 - val_loss: 1.2943 - val_NDCG@10: 0.8466 - val_MAE: 0.3605 - val_RC@5: 0.9191 - val_RC@10: 0.9544 - lr: 9.7723e-04 - e_time: 36.0346 - 36s/epoch - 392ms/step
Epoch 24/1000
92/92 - 36s - loss: 0.5670 - NDCG@10: 0.9222 - MAE: 0.4054 - RC@5: 0.9694 - RC@10: 0.9840 - val_loss: 1.2529 - val_NDCG@10: 0.8477 - val_MAE: 0.3587 - val_RC@5: 0.9210 - val_RC@10: 0.9559 - lr: 9.7624e-04 - e_time: 36.0132 - 36s/epoch - 391ms/step
Epoch 25/1000
92/92 - 36s - loss: 0.5580 - NDCG@10: 0.9232 - MAE: 0.4042 - RC@5: 0.9703 - RC@10: 0.9849 - val_loss: 1.2703 - val_NDCG@10: 0.8485 - val_MAE: 0.3551 - val_RC@5: 0.9216 - val_RC@10: 0.9560 - lr: 9.7525e-04 - e_time: 35.9984 - 36s/epoch - 391ms/step
Epoch 26/1000
92/92 - 36s - loss: 0.5511 - NDCG@10: 0.9239 - MAE: 0.4043 - RC@5: 0.9710 - RC@10: 0.9852 - val_loss: 1.3074 - val_NDCG@10: 0.8459 - val_MAE: 0.3530 - val_RC@5: 0.9182 - val_RC@10: 0.9548 - lr: 9.7426e-04 - e_time: 36.0129 - 36s/epoch - 391ms/step
Epoch 27/1000
92/92 - 36s - loss: 0.5390 - NDCG@10: 0.9256 - MAE: 0.4033 - RC@5: 0.9717 - RC@10: 0.9854 - val_loss: 1.3784 - val_NDCG@10: 0.8450 - val_MAE: 0.3501 - val_RC@5: 0.9158 - val_RC@10: 0.9530 - lr: 9.7327e-04 - e_time: 36.0066 - 36s/epoch - 391ms/step
Epoch 28/1000
92/92 - 36s - loss: 0.5302 - NDCG@10: 0.9269 - MAE: 0.4027 - RC@5: 0.9718 - RC@10: 0.9854 - val_loss: 1.3620 - val_NDCG@10: 0.8437 - val_MAE: 0.3512 - val_RC@5: 0.9171 - val_RC@10: 0.9512 - lr: 9.7228e-04 - e_time: 36.0298 - 36s/epoch - 392ms/step
Epoch 29/1000
92/92 - 36s - loss: 0.5199 - NDCG@10: 0.9285 - MAE: 0.4022 - RC@5: 0.9726 - RC@10: 0.9863 - val_loss: 1.3796 - val_NDCG@10: 0.8458 - val_MAE: 0.3524 - val_RC@5: 0.9169 - val_RC@10: 0.9514 - lr: 9.7129e-04 - e_time: 36.0303 - 36s/epoch - 392ms/step
Epoch 30/1000
92/92 - 36s - loss: 0.5179 - NDCG@10: 0.9284 - MAE: 0.4009 - RC@5: 0.9736 - RC@10: 0.9861 - val_loss: 1.3760 - val_NDCG@10: 0.8487 - val_MAE: 0.3477 - val_RC@5: 0.9202 - val_RC@10: 0.9539 - lr: 9.7030e-04 - e_time: 36.0113 - 36s/epoch - 391ms/step
Epoch 31/1000
92/92 - 36s - loss: 0.4981 - NDCG@10: 0.9305 - MAE: 0.4009 - RC@5: 0.9746 - RC@10: 0.9868 - val_loss: 1.3977 - val_NDCG@10: 0.8507 - val_MAE: 0.3450 - val_RC@5: 0.9199 - val_RC@10: 0.9551 - lr: 9.6931e-04 - e_time: 36.0217 - 36s/epoch - 392ms/step
Epoch 32/1000
92/92 - 36s - loss: 0.4829 - NDCG@10: 0.9333 - MAE: 0.3999 - RC@5: 0.9756 - RC@10: 0.9874 - val_loss: 1.3849 - val_NDCG@10: 0.8500 - val_MAE: 0.3458 - val_RC@5: 0.9209 - val_RC@10: 0.9540 - lr: 9.6832e-04 - e_time: 36.0351 - 36s/epoch - 392ms/step
Epoch 33/1000
92/92 - 36s - loss: 0.4674 - NDCG@10: 0.9352 - MAE: 0.3986 - RC@5: 0.9770 - RC@10: 0.9882 - val_loss: 1.4224 - val_NDCG@10: 0.8473 - val_MAE: 0.3479 - val_RC@5: 0.9186 - val_RC@10: 0.9521 - lr: 9.6733e-04 - e_time: 36.0137 - 36s/epoch - 391ms/step
Epoch 34/1000
92/92 - 36s - loss: 0.4657 - NDCG@10: 0.9350 - MAE: 0.3992 - RC@5: 0.9769 - RC@10: 0.9880 - val_loss: 1.4654 - val_NDCG@10: 0.8448 - val_MAE: 0.3459 - val_RC@5: 0.9151 - val_RC@10: 0.9521 - lr: 9.6634e-04 - e_time: 36.0076 - 36s/epoch - 391ms/step
Epoch 35/1000
92/92 - 36s - loss: 0.4540 - NDCG@10: 0.9365 - MAE: 0.3987 - RC@5: 0.9784 - RC@10: 0.9887 - val_loss: 1.4973 - val_NDCG@10: 0.8459 - val_MAE: 0.3432 - val_RC@5: 0.9151 - val_RC@10: 0.9523 - lr: 9.6535e-04 - e_time: 36.0128 - 36s/epoch - 391ms/step
Epoch 36/1000
92/92 - 36s - loss: 0.4528 - NDCG@10: 0.9360 - MAE: 0.3979 - RC@5: 0.9780 - RC@10: 0.9882 - val_loss: 1.4857 - val_NDCG@10: 0.8459 - val_MAE: 0.3440 - val_RC@5: 0.9180 - val_RC@10: 0.9529 - lr: 9.6436e-04 - e_time: 36.0193 - 36s/epoch - 392ms/step
Epoch 37/1000
92/92 - 36s - loss: 0.4391 - NDCG@10: 0.9380 - MAE: 0.3988 - RC@5: 0.9790 - RC@10: 0.9892 - val_loss: 1.5309 - val_NDCG@10: 0.8435 - val_MAE: 0.3442 - val_RC@5: 0.9168 - val_RC@10: 0.9513 - lr: 9.6337e-04 - e_time: 36.0032 - 36s/epoch - 391ms/step
Epoch 38/1000
92/92 - 36s - loss: 0.4377 - NDCG@10: 0.9384 - MAE: 0.3978 - RC@5: 0.9788 - RC@10: 0.9888 - val_loss: 1.5153 - val_NDCG@10: 0.8427 - val_MAE: 0.3413 - val_RC@5: 0.9163 - val_RC@10: 0.9505 - lr: 9.6238e-04 - e_time: 36.0154 - 36s/epoch - 391ms/step
Epoch 39/1000
92/92 - 36s - loss: 0.4247 - NDCG@10: 0.9399 - MAE: 0.3979 - RC@5: 0.9801 - RC@10: 0.9895 - val_loss: 1.5816 - val_NDCG@10: 0.8422 - val_MAE: 0.3397 - val_RC@5: 0.9171 - val_RC@10: 0.9512 - lr: 9.6139e-04 - e_time: 36.0183 - 36s/epoch - 392ms/step
Epoch 40/1000
92/92 - 36s - loss: 0.4246 - NDCG@10: 0.9395 - MAE: 0.3966 - RC@5: 0.9798 - RC@10: 0.9899 - val_loss: 1.5782 - val_NDCG@10: 0.8421 - val_MAE: 0.3388 - val_RC@5: 0.9137 - val_RC@10: 0.9502 - lr: 9.6040e-04 - e_time: 36.0066 - 36s/epoch - 391ms/step
Epoch 41/1000
92/92 - 36s - loss: 0.4215 - NDCG@10: 0.9399 - MAE: 0.3962 - RC@5: 0.9803 - RC@10: 0.9902 - val_loss: 1.5517 - val_NDCG@10: 0.8455 - val_MAE: 0.3387 - val_RC@5: 0.9157 - val_RC@10: 0.9520 - lr: 9.5941e-04 - e_time: 36.0241 - 36s/epoch - 392ms/step
Epoch 42/1000
92/92 - 36s - loss: 0.4070 - NDCG@10: 0.9415 - MAE: 0.3954 - RC@5: 0.9818 - RC@10: 0.9905 - val_loss: 1.5920 - val_NDCG@10: 0.8428 - val_MAE: 0.3383 - val_RC@5: 0.9145 - val_RC@10: 0.9504 - lr: 9.5842e-04 - e_time: 36.0219 - 36s/epoch - 392ms/step
Epoch 43/1000
92/92 - 36s - loss: 0.4043 - NDCG@10: 0.9418 - MAE: 0.3949 - RC@5: 0.9813 - RC@10: 0.9900 - val_loss: 1.6201 - val_NDCG@10: 0.8432 - val_MAE: 0.3366 - val_RC@5: 0.9130 - val_RC@10: 0.9486 - lr: 9.5743e-04 - e_time: 36.0136 - 36s/epoch - 391ms/step
Epoch 44/1000
92/92 - 36s - loss: 0.3982 - NDCG@10: 0.9427 - MAE: 0.3947 - RC@5: 0.9820 - RC@10: 0.9908 - val_loss: 1.6171 - val_NDCG@10: 0.8427 - val_MAE: 0.3363 - val_RC@5: 0.9149 - val_RC@10: 0.9512 - lr: 9.5644e-04 - e_time: 36.0149 - 36s/epoch - 391ms/step
Epoch 45/1000
92/92 - 36s - loss: 0.3918 - NDCG@10: 0.9436 - MAE: 0.3948 - RC@5: 0.9822 - RC@10: 0.9905 - val_loss: 1.6329 - val_NDCG@10: 0.8413 - val_MAE: 0.3366 - val_RC@5: 0.9124 - val_RC@10: 0.9479 - lr: 9.5545e-04 - e_time: 36.0084 - 36s/epoch - 391ms/step
Epoch 46/1000
92/92 - 36s - loss: 0.3800 - NDCG@10: 0.9443 - MAE: 0.3950 - RC@5: 0.9822 - RC@10: 0.9903 - val_loss: 1.6553 - val_NDCG@10: 0.8415 - val_MAE: 0.3366 - val_RC@5: 0.9140 - val_RC@10: 0.9509 - lr: 9.5446e-04 - e_time: 36.0188 - 36s/epoch - 392ms/step
Epoch 47/1000
92/92 - 36s - loss: 0.3828 - NDCG@10: 0.9442 - MAE: 0.3944 - RC@5: 0.9826 - RC@10: 0.9909 - val_loss: 1.6863 - val_NDCG@10: 0.8422 - val_MAE: 0.3316 - val_RC@5: 0.9151 - val_RC@10: 0.9497 - lr: 9.5347e-04 - e_time: 36.0240 - 36s/epoch - 392ms/step
Epoch 48/1000
92/92 - 36s - loss: 0.3739 - NDCG@10: 0.9449 - MAE: 0.3940 - RC@5: 0.9834 - RC@10: 0.9913 - val_loss: 1.6412 - val_NDCG@10: 0.8436 - val_MAE: 0.3323 - val_RC@5: 0.9167 - val_RC@10: 0.9509 - lr: 9.5248e-04 - e_time: 36.0154 - 36s/epoch - 391ms/step
Epoch 49/1000
92/92 - 36s - loss: 0.3682 - NDCG@10: 0.9450 - MAE: 0.3934 - RC@5: 0.9829 - RC@10: 0.9911 - val_loss: 1.7123 - val_NDCG@10: 0.8405 - val_MAE: 0.3329 - val_RC@5: 0.9121 - val_RC@10: 0.9478 - lr: 9.5149e-04 - e_time: 36.0391 - 36s/epoch - 392ms/step
Epoch 50/1000
92/92 - 36s - loss: 0.3694 - NDCG@10: 0.9456 - MAE: 0.3926 - RC@5: 0.9835 - RC@10: 0.9911 - val_loss: 1.7067 - val_NDCG@10: 0.8406 - val_MAE: 0.3322 - val_RC@5: 0.9110 - val_RC@10: 0.9488 - lr: 9.5050e-04 - e_time: 36.0260 - 36s/epoch - 392ms/step
Epoch 51/1000
92/92 - 36s - loss: 0.3579 - NDCG@10: 0.9463 - MAE: 0.3920 - RC@5: 0.9843 - RC@10: 0.9915 - val_loss: 1.7235 - val_NDCG@10: 0.8401 - val_MAE: 0.3334 - val_RC@5: 0.9128 - val_RC@10: 0.9491 - lr: 9.4951e-04 - e_time: 36.0236 - 36s/epoch - 392ms/step
Epoch 52/1000
92/92 - 36s - loss: 0.3547 - NDCG@10: 0.9472 - MAE: 0.3916 - RC@5: 0.9843 - RC@10: 0.9923 - val_loss: 1.7262 - val_NDCG@10: 0.8419 - val_MAE: 0.3305 - val_RC@5: 0.9147 - val_RC@10: 0.9516 - lr: 9.4852e-04 - e_time: 36.0253 - 36s/epoch - 392ms/step
Epoch 53/1000
92/92 - 36s - loss: 0.3496 - NDCG@10: 0.9476 - MAE: 0.3918 - RC@5: 0.9844 - RC@10: 0.9916 - val_loss: 1.7323 - val_NDCG@10: 0.8415 - val_MAE: 0.3303 - val_RC@5: 0.9145 - val_RC@10: 0.9493 - lr: 9.4753e-04 - e_time: 36.0067 - 36s/epoch - 391ms/step
Epoch 54/1000
92/92 - 36s - loss: 0.3461 - NDCG@10: 0.9480 - MAE: 0.3912 - RC@5: 0.9848 - RC@10: 0.9921 - val_loss: 1.7692 - val_NDCG@10: 0.8388 - val_MAE: 0.3285 - val_RC@5: 0.9122 - val_RC@10: 0.9481 - lr: 9.4654e-04 - e_time: 36.0250 - 36s/epoch - 392ms/step
Epoch 55/1000
92/92 - 36s - loss: 0.3421 - NDCG@10: 0.9484 - MAE: 0.3910 - RC@5: 0.9851 - RC@10: 0.9921 - val_loss: 1.7512 - val_NDCG@10: 0.8373 - val_MAE: 0.3312 - val_RC@5: 0.9105 - val_RC@10: 0.9480 - lr: 9.4555e-04 - e_time: 36.0108 - 36s/epoch - 391ms/step
Epoch 56/1000
92/92 - 36s - loss: 0.3359 - NDCG@10: 0.9491 - MAE: 0.3900 - RC@5: 0.9854 - RC@10: 0.9928 - val_loss: 1.8155 - val_NDCG@10: 0.8400 - val_MAE: 0.3274 - val_RC@5: 0.9122 - val_RC@10: 0.9486 - lr: 9.4456e-04 - e_time: 36.0090 - 36s/epoch - 391ms/step
Epoch 57/1000
92/92 - 36s - loss: 0.3319 - NDCG@10: 0.9495 - MAE: 0.3898 - RC@5: 0.9856 - RC@10: 0.9924 - val_loss: 1.7572 - val_NDCG@10: 0.8391 - val_MAE: 0.3287 - val_RC@5: 0.9115 - val_RC@10: 0.9486 - lr: 9.4357e-04 - e_time: 36.0293 - 36s/epoch - 392ms/step
Epoch 57: early stopping
[92m[INFO] Loading best model...[0m
Using TensorFlow backend
[93m[WARNING] Model folder already exists...[0m
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 padding_mask (InputLayer)   [(None, None)]               0         []                            
                                                                                                  
 segment_ids (InputLayer)    [(None, None)]               0         []                            
                                                                                                  
 token_ids (InputLayer)      [(None, None)]               0         []                            
                                                                                                  
 bert_backbone (BertBackbon  {'sequence_output': (None,   4385920   ['padding_mask[0][0]',        
 e)                           None, 128),                            'segment_ids[0][0]',         
                              'pooled_output': (None, 1              'token_ids[0][0]']           
                             28)}                                                                 
                                                                                                  
 dropout (Dropout)           (None, None, 128)            0         ['bert_backbone[0][1]']       
                                                                                                  
 tf.__operators__.getitem_1  (None, 128)                  0         ['dropout[0][0]']             
  (SlicingOpLambda)                                                                               
                                                                                                  
 out (Dense)                 (None, 86)                   11094     ['tf.__operators__.getitem_1[0
                                                                    ][0]']                        
                                                                                                  
==================================================================================================
Total params: 4397014 (16.77 MB)
Trainable params: 4397014 (16.77 MB)
Non-trainable params: 0 (0.00 Byte)
__________________________________________________________________________________________________
None
[92m[INFO] Model already trained. Loading weights...[0m
Using TensorFlow backend
[93m[WARNING] Model folder already exists...[0m
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 padding_mask (InputLayer)   [(None, None)]               0         []                            
                                                                                                  
 segment_ids (InputLayer)    [(None, None)]               0         []                            
                                                                                                  
 token_ids (InputLayer)      [(None, None)]               0         []                            
                                                                                                  
 bert_backbone (BertBackbon  {'sequence_output': (None,   4385920   ['padding_mask[0][0]',        
 e)                           None, 128),                            'segment_ids[0][0]',         
                              'pooled_output': (None, 1              'token_ids[0][0]']           
                             28)}                                                                 
                                                                                                  
 dropout (Dropout)           (None, None, 128)            0         ['bert_backbone[0][1]']       
                                                                                                  
 tf.__operators__.getitem_1  (None, 128)                  0         ['dropout[0][0]']             
  (SlicingOpLambda)                                                                               
                                                                                                  
 out (Dense)                 (None, 86)                   11094     ['tf.__operators__.getitem_1[0
                                                                    ][0]']                        
                                                                                                  
==================================================================================================
Total params: 4397014 (16.77 MB)
Trainable params: 4397014 (16.77 MB)
Non-trainable params: 0 (0.00 Byte)
__________________________________________________________________________________________________
None
[92m[INFO] Model already trained. Loading weights...[0m
Using TensorFlow backend
[93m[WARNING] Model folder already exists...[0m
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 padding_mask (InputLayer)   [(None, None)]               0         []                            
                                                                                                  
 segment_ids (InputLayer)    [(None, None)]               0         []                            
                                                                                                  
 token_ids (InputLayer)      [(None, None)]               0         []                            
                                                                                                  
 bert_backbone (BertBackbon  {'sequence_output': (None,   4385920   ['padding_mask[0][0]',        
 e)                           None, 128),                            'segment_ids[0][0]',         
                              'pooled_output': (None, 1              'token_ids[0][0]']           
                             28)}                                                                 
                                                                                                  
 dropout (Dropout)           (None, None, 128)            0         ['bert_backbone[0][1]']       
                                                                                                  
 tf.__operators__.getitem_1  (None, 128)                  0         ['dropout[0][0]']             
  (SlicingOpLambda)                                                                               
                                                                                                  
 out (Dense)                 (None, 86)                   11094     ['tf.__operators__.getitem_1[0
                                                                    ][0]']                        
                                                                                                  
==================================================================================================
Total params: 4397014 (16.77 MB)
Trainable params: 4397014 (16.77 MB)
Non-trainable params: 0 (0.00 Byte)
__________________________________________________________________________________________________
None
[92m[INFO] Model already trained. Loading weights...[0m
