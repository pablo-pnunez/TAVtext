Using TensorFlow backend
[94mLoading best USEM2ITM model: 4a75205e3811c42a98be9cb8602c2f65[0m
[93m[WARNING] Model folder already exists...[0m
[93m[WARNING] Model weights are not loaded![0m
[92m[INFO] Best epoch number: 10[0m
[92m[INFO] Not saving the model...[0m
Epoch 1/10
104/104 - 20s - loss: 3.5212 - r1: 0.4596 - r5: 0.6849 - r10: 0.7602 - p5: 0.1370 - p10: 0.0760 - lr: 4.9951e-04 - CO2(gr): 0.6067 - 20s/epoch - 194ms/step
Epoch 2/10
104/104 - 13s - loss: 2.5366 - r1: 0.6682 - r5: 0.8427 - r10: 0.8906 - p5: 0.1685 - p10: 0.0891 - lr: 4.9901e-04 - CO2(gr): 1.0568 - 13s/epoch - 127ms/step
Epoch 3/10
104/104 - 13s - loss: 1.9181 - r1: 0.7234 - r5: 0.8892 - r10: 0.9309 - p5: 0.1778 - p10: 0.0931 - lr: 4.9852e-04 - CO2(gr): 1.5316 - 13s/epoch - 128ms/step
Epoch 4/10
104/104 - 13s - loss: 1.5123 - r1: 0.7609 - r5: 0.9166 - r10: 0.9508 - p5: 0.1833 - p10: 0.0951 - lr: 4.9802e-04 - CO2(gr): 2.0098 - 13s/epoch - 127ms/step
Epoch 5/10
104/104 - 13s - loss: 1.2445 - r1: 0.7919 - r5: 0.9339 - r10: 0.9625 - p5: 0.1868 - p10: 0.0963 - lr: 4.9753e-04 - CO2(gr): 2.4891 - 13s/epoch - 127ms/step
Epoch 6/10
104/104 - 13s - loss: 1.0642 - r1: 0.8138 - r5: 0.9459 - r10: 0.9706 - p5: 0.1892 - p10: 0.0971 - lr: 4.9703e-04 - CO2(gr): 2.9701 - 13s/epoch - 127ms/step
Epoch 7/10
104/104 - 13s - loss: 0.9131 - r1: 0.8372 - r5: 0.9552 - r10: 0.9764 - p5: 0.1910 - p10: 0.0976 - lr: 4.9654e-04 - CO2(gr): 3.4440 - 13s/epoch - 127ms/step
Epoch 8/10
104/104 - 13s - loss: 0.8014 - r1: 0.8549 - r5: 0.9616 - r10: 0.9807 - p5: 0.1923 - p10: 0.0981 - lr: 4.9604e-04 - CO2(gr): 3.9212 - 13s/epoch - 127ms/step
Epoch 9/10
104/104 - 13s - loss: 0.7033 - r1: 0.8721 - r5: 0.9680 - r10: 0.9841 - p5: 0.1936 - p10: 0.0984 - lr: 4.9555e-04 - CO2(gr): 4.3918 - 13s/epoch - 127ms/step
Epoch 10/10
104/104 - 13s - loss: 0.6281 - r1: 0.8845 - r5: 0.9729 - r10: 0.9867 - p5: 0.1946 - p10: 0.0987 - lr: 4.9505e-04 - CO2(gr): 4.8661 - 13s/epoch - 127ms/step
2'19" of training time
4.868g of CO2
22.389Wh of electricity
[92m[INFO] There are 11702 evaluation examples.[0m
[92m       loss    NDCG@1   NDCG@10  ...      F1@1      F1@5     F1@10
0  1.157365  0.745343  0.852358  ...  0.745343  0.306928  0.173304

[1 rows x 20 columns][0m
