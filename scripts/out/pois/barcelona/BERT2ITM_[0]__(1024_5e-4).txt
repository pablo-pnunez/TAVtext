Using TensorFlow backend
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 padding_mask (InputLayer)   [(None, None)]               0         []                            
                                                                                                  
 segment_ids (InputLayer)    [(None, None)]               0         []                            
                                                                                                  
 token_ids (InputLayer)      [(None, None)]               0         []                            
                                                                                                  
 bert_backbone (BertBackbon  {'sequence_output': (None,   4385920   ['padding_mask[0][0]',        
 e)                           None, 128),                            'segment_ids[0][0]',         
                              'pooled_output': (None, 1              'token_ids[0][0]']           
                             28)}                                                                 
                                                                                                  
 dropout (Dropout)           (None, None, 128)            0         ['bert_backbone[0][1]']       
                                                                                                  
 tf.__operators__.getitem_1  (None, 128)                  0         ['dropout[0][0]']             
  (SlicingOpLambda)                                                                               
                                                                                                  
 out (Dense)                 (None, 86)                   11094     ['tf.__operators__.getitem_1[0
                                                                    ][0]']                        
                                                                                                  
==================================================================================================
Total params: 4397014 (16.77 MB)
Trainable params: 4397014 (16.77 MB)
Non-trainable params: 0 (0.00 Byte)
__________________________________________________________________________________________________
None
Epoch 1/1000
92/92 - 41s - loss: 4.2201 - NDCG@10: 0.3316 - MAE: 0.4811 - RC@5: 0.3899 - RC@10: 0.5059 - val_loss: 2.1493 - val_NDCG@10: 0.6616 - val_MAE: 0.4550 - val_RC@5: 0.7500 - val_RC@10: 0.8148 - lr: 4.9951e-04 - e_time: 40.8022 - 41s/epoch - 450ms/step
Epoch 2/1000
92/92 - 37s - loss: 2.3680 - NDCG@10: 0.6418 - MAE: 0.4671 - RC@5: 0.7177 - RC@10: 0.7870 - val_loss: 1.4877 - val_NDCG@10: 0.7745 - val_MAE: 0.4466 - val_RC@5: 0.8560 - val_RC@10: 0.9097 - lr: 4.9901e-04 - e_time: 35.9201 - 37s/epoch - 398ms/step
Epoch 3/1000
92/92 - 37s - loss: 1.8471 - NDCG@10: 0.7249 - MAE: 0.4607 - RC@5: 0.8008 - RC@10: 0.8572 - val_loss: 1.2913 - val_NDCG@10: 0.8036 - val_MAE: 0.4378 - val_RC@5: 0.8844 - val_RC@10: 0.9304 - lr: 4.9852e-04 - e_time: 35.9567 - 37s/epoch - 398ms/step
Epoch 4/1000
92/92 - 37s - loss: 1.5987 - NDCG@10: 0.7637 - MAE: 0.4580 - RC@5: 0.8385 - RC@10: 0.8903 - val_loss: 1.1743 - val_NDCG@10: 0.8239 - val_MAE: 0.4381 - val_RC@5: 0.9038 - val_RC@10: 0.9442 - lr: 4.9802e-04 - e_time: 35.9948 - 37s/epoch - 399ms/step
Epoch 5/1000
92/92 - 37s - loss: 1.4413 - NDCG@10: 0.7879 - MAE: 0.4529 - RC@5: 0.8623 - RC@10: 0.9103 - val_loss: 1.0939 - val_NDCG@10: 0.8346 - val_MAE: 0.4310 - val_RC@5: 0.9139 - val_RC@10: 0.9514 - lr: 4.9753e-04 - e_time: 35.9957 - 37s/epoch - 398ms/step
Epoch 6/1000
92/92 - 37s - loss: 1.3270 - NDCG@10: 0.8057 - MAE: 0.4491 - RC@5: 0.8793 - RC@10: 0.9244 - val_loss: 1.0666 - val_NDCG@10: 0.8409 - val_MAE: 0.4213 - val_RC@5: 0.9187 - val_RC@10: 0.9553 - lr: 4.9703e-04 - e_time: 36.0169 - 37s/epoch - 399ms/step
Epoch 7/1000
92/92 - 37s - loss: 1.2442 - NDCG@10: 0.8196 - MAE: 0.4457 - RC@5: 0.8921 - RC@10: 0.9347 - val_loss: 1.0358 - val_NDCG@10: 0.8460 - val_MAE: 0.4162 - val_RC@5: 0.9231 - val_RC@10: 0.9576 - lr: 4.9654e-04 - e_time: 36.0214 - 37s/epoch - 399ms/step
Epoch 8/1000
92/92 - 37s - loss: 1.1640 - NDCG@10: 0.8314 - MAE: 0.4420 - RC@5: 0.9028 - RC@10: 0.9422 - val_loss: 1.0101 - val_NDCG@10: 0.8515 - val_MAE: 0.4147 - val_RC@5: 0.9269 - val_RC@10: 0.9588 - lr: 4.9604e-04 - e_time: 36.0293 - 37s/epoch - 399ms/step
Epoch 9/1000
92/92 - 37s - loss: 1.1160 - NDCG@10: 0.8394 - MAE: 0.4402 - RC@5: 0.9113 - RC@10: 0.9478 - val_loss: 1.0023 - val_NDCG@10: 0.8519 - val_MAE: 0.4137 - val_RC@5: 0.9263 - val_RC@10: 0.9603 - lr: 4.9555e-04 - e_time: 36.0242 - 37s/epoch - 399ms/step
Epoch 10/1000
92/92 - 37s - loss: 1.0602 - NDCG@10: 0.8485 - MAE: 0.4363 - RC@5: 0.9176 - RC@10: 0.9537 - val_loss: 0.9988 - val_NDCG@10: 0.8531 - val_MAE: 0.4059 - val_RC@5: 0.9282 - val_RC@10: 0.9612 - lr: 4.9505e-04 - e_time: 36.0299 - 37s/epoch - 399ms/step
Epoch 11/1000
92/92 - 36s - loss: 1.0139 - NDCG@10: 0.8559 - MAE: 0.4350 - RC@5: 0.9229 - RC@10: 0.9573 - val_loss: 1.0012 - val_NDCG@10: 0.8539 - val_MAE: 0.4043 - val_RC@5: 0.9274 - val_RC@10: 0.9599 - lr: 4.9456e-04 - e_time: 36.0092 - 36s/epoch - 391ms/step
Epoch 12/1000
92/92 - 36s - loss: 0.9719 - NDCG@10: 0.8622 - MAE: 0.4326 - RC@5: 0.9293 - RC@10: 0.9606 - val_loss: 1.0107 - val_NDCG@10: 0.8552 - val_MAE: 0.3959 - val_RC@5: 0.9279 - val_RC@10: 0.9617 - lr: 4.9406e-04 - e_time: 36.0362 - 36s/epoch - 392ms/step
Epoch 13/1000
92/92 - 36s - loss: 0.9432 - NDCG@10: 0.8668 - MAE: 0.4309 - RC@5: 0.9319 - RC@10: 0.9628 - val_loss: 1.0112 - val_NDCG@10: 0.8552 - val_MAE: 0.3948 - val_RC@5: 0.9276 - val_RC@10: 0.9616 - lr: 4.9357e-04 - e_time: 36.0337 - 36s/epoch - 392ms/step
Epoch 14/1000
92/92 - 36s - loss: 0.9082 - NDCG@10: 0.8726 - MAE: 0.4297 - RC@5: 0.9365 - RC@10: 0.9651 - val_loss: 1.0132 - val_NDCG@10: 0.8544 - val_MAE: 0.3940 - val_RC@5: 0.9278 - val_RC@10: 0.9608 - lr: 4.9307e-04 - e_time: 36.0343 - 36s/epoch - 392ms/step
Epoch 15/1000
92/92 - 36s - loss: 0.8826 - NDCG@10: 0.8761 - MAE: 0.4282 - RC@5: 0.9400 - RC@10: 0.9681 - val_loss: 1.0143 - val_NDCG@10: 0.8550 - val_MAE: 0.3881 - val_RC@5: 0.9279 - val_RC@10: 0.9604 - lr: 4.9258e-04 - e_time: 36.0388 - 36s/epoch - 392ms/step
Epoch 16/1000
92/92 - 36s - loss: 0.8524 - NDCG@10: 0.8816 - MAE: 0.4269 - RC@5: 0.9430 - RC@10: 0.9691 - val_loss: 1.0126 - val_NDCG@10: 0.8567 - val_MAE: 0.3898 - val_RC@5: 0.9308 - val_RC@10: 0.9611 - lr: 4.9208e-04 - e_time: 36.0448 - 36s/epoch - 392ms/step
Epoch 17/1000
92/92 - 36s - loss: 0.8280 - NDCG@10: 0.8852 - MAE: 0.4259 - RC@5: 0.9447 - RC@10: 0.9710 - val_loss: 1.0363 - val_NDCG@10: 0.8538 - val_MAE: 0.3900 - val_RC@5: 0.9279 - val_RC@10: 0.9609 - lr: 4.9159e-04 - e_time: 36.0521 - 36s/epoch - 392ms/step
Epoch 18/1000
92/92 - 36s - loss: 0.8019 - NDCG@10: 0.8883 - MAE: 0.4237 - RC@5: 0.9479 - RC@10: 0.9720 - val_loss: 1.0513 - val_NDCG@10: 0.8542 - val_MAE: 0.3812 - val_RC@5: 0.9281 - val_RC@10: 0.9611 - lr: 4.9109e-04 - e_time: 36.0294 - 36s/epoch - 392ms/step
Epoch 19/1000
92/92 - 36s - loss: 0.7844 - NDCG@10: 0.8915 - MAE: 0.4230 - RC@5: 0.9506 - RC@10: 0.9730 - val_loss: 1.0572 - val_NDCG@10: 0.8546 - val_MAE: 0.3846 - val_RC@5: 0.9272 - val_RC@10: 0.9597 - lr: 4.9060e-04 - e_time: 36.0424 - 36s/epoch - 392ms/step
Epoch 20/1000
92/92 - 36s - loss: 0.7631 - NDCG@10: 0.8944 - MAE: 0.4224 - RC@5: 0.9521 - RC@10: 0.9744 - val_loss: 1.0689 - val_NDCG@10: 0.8555 - val_MAE: 0.3822 - val_RC@5: 0.9270 - val_RC@10: 0.9608 - lr: 4.9010e-04 - e_time: 36.0277 - 36s/epoch - 392ms/step
Epoch 21/1000
92/92 - 36s - loss: 0.7424 - NDCG@10: 0.8978 - MAE: 0.4214 - RC@5: 0.9550 - RC@10: 0.9766 - val_loss: 1.0685 - val_NDCG@10: 0.8561 - val_MAE: 0.3827 - val_RC@5: 0.9280 - val_RC@10: 0.9607 - lr: 4.8961e-04 - e_time: 36.0260 - 36s/epoch - 392ms/step
Epoch 22/1000
92/92 - 36s - loss: 0.7232 - NDCG@10: 0.9008 - MAE: 0.4215 - RC@5: 0.9558 - RC@10: 0.9766 - val_loss: 1.0740 - val_NDCG@10: 0.8573 - val_MAE: 0.3803 - val_RC@5: 0.9279 - val_RC@10: 0.9603 - lr: 4.8911e-04 - e_time: 36.0227 - 36s/epoch - 392ms/step
Epoch 23/1000
92/92 - 36s - loss: 0.7056 - NDCG@10: 0.9032 - MAE: 0.4196 - RC@5: 0.9579 - RC@10: 0.9775 - val_loss: 1.1160 - val_NDCG@10: 0.8554 - val_MAE: 0.3751 - val_RC@5: 0.9274 - val_RC@10: 0.9595 - lr: 4.8862e-04 - e_time: 36.0253 - 36s/epoch - 392ms/step
Epoch 24/1000
92/92 - 36s - loss: 0.6932 - NDCG@10: 0.9054 - MAE: 0.4194 - RC@5: 0.9599 - RC@10: 0.9787 - val_loss: 1.1208 - val_NDCG@10: 0.8558 - val_MAE: 0.3740 - val_RC@5: 0.9275 - val_RC@10: 0.9609 - lr: 4.8812e-04 - e_time: 36.0306 - 36s/epoch - 392ms/step
Epoch 25/1000
92/92 - 36s - loss: 0.6760 - NDCG@10: 0.9082 - MAE: 0.4187 - RC@5: 0.9610 - RC@10: 0.9797 - val_loss: 1.1575 - val_NDCG@10: 0.8555 - val_MAE: 0.3696 - val_RC@5: 0.9260 - val_RC@10: 0.9604 - lr: 4.8763e-04 - e_time: 36.0340 - 36s/epoch - 392ms/step
Epoch 26/1000
92/92 - 36s - loss: 0.6579 - NDCG@10: 0.9096 - MAE: 0.4179 - RC@5: 0.9615 - RC@10: 0.9803 - val_loss: 1.1449 - val_NDCG@10: 0.8558 - val_MAE: 0.3723 - val_RC@5: 0.9269 - val_RC@10: 0.9600 - lr: 4.8713e-04 - e_time: 36.0329 - 36s/epoch - 392ms/step
Epoch 27/1000
92/92 - 36s - loss: 0.6458 - NDCG@10: 0.9116 - MAE: 0.4173 - RC@5: 0.9627 - RC@10: 0.9812 - val_loss: 1.1507 - val_NDCG@10: 0.8552 - val_MAE: 0.3709 - val_RC@5: 0.9274 - val_RC@10: 0.9592 - lr: 4.8664e-04 - e_time: 36.0241 - 36s/epoch - 392ms/step
Epoch 28/1000
92/92 - 36s - loss: 0.6305 - NDCG@10: 0.9140 - MAE: 0.4166 - RC@5: 0.9639 - RC@10: 0.9814 - val_loss: 1.1691 - val_NDCG@10: 0.8544 - val_MAE: 0.3670 - val_RC@5: 0.9248 - val_RC@10: 0.9575 - lr: 4.8614e-04 - e_time: 36.0261 - 36s/epoch - 392ms/step
Epoch 29/1000
92/92 - 36s - loss: 0.6156 - NDCG@10: 0.9158 - MAE: 0.4158 - RC@5: 0.9657 - RC@10: 0.9824 - val_loss: 1.1839 - val_NDCG@10: 0.8534 - val_MAE: 0.3721 - val_RC@5: 0.9224 - val_RC@10: 0.9580 - lr: 4.8565e-04 - e_time: 36.0176 - 36s/epoch - 392ms/step
Epoch 30/1000
92/92 - 36s - loss: 0.6055 - NDCG@10: 0.9178 - MAE: 0.4153 - RC@5: 0.9663 - RC@10: 0.9830 - val_loss: 1.2025 - val_NDCG@10: 0.8533 - val_MAE: 0.3666 - val_RC@5: 0.9248 - val_RC@10: 0.9562 - lr: 4.8515e-04 - e_time: 36.0285 - 36s/epoch - 392ms/step
Epoch 31/1000
92/92 - 36s - loss: 0.5940 - NDCG@10: 0.9191 - MAE: 0.4152 - RC@5: 0.9676 - RC@10: 0.9832 - val_loss: 1.2295 - val_NDCG@10: 0.8526 - val_MAE: 0.3643 - val_RC@5: 0.9226 - val_RC@10: 0.9574 - lr: 4.8466e-04 - e_time: 36.0011 - 36s/epoch - 391ms/step
Epoch 32/1000
92/92 - 36s - loss: 0.5819 - NDCG@10: 0.9209 - MAE: 0.4143 - RC@5: 0.9687 - RC@10: 0.9841 - val_loss: 1.2162 - val_NDCG@10: 0.8512 - val_MAE: 0.3659 - val_RC@5: 0.9227 - val_RC@10: 0.9573 - lr: 4.8416e-04 - e_time: 36.0089 - 36s/epoch - 391ms/step
Epoch 33/1000
92/92 - 36s - loss: 0.5712 - NDCG@10: 0.9220 - MAE: 0.4137 - RC@5: 0.9691 - RC@10: 0.9838 - val_loss: 1.2385 - val_NDCG@10: 0.8532 - val_MAE: 0.3655 - val_RC@5: 0.9245 - val_RC@10: 0.9570 - lr: 4.8367e-04 - e_time: 36.0135 - 36s/epoch - 391ms/step
Epoch 34/1000
92/92 - 36s - loss: 0.5603 - NDCG@10: 0.9241 - MAE: 0.4144 - RC@5: 0.9704 - RC@10: 0.9849 - val_loss: 1.2334 - val_NDCG@10: 0.8522 - val_MAE: 0.3672 - val_RC@5: 0.9216 - val_RC@10: 0.9570 - lr: 4.8317e-04 - e_time: 36.0340 - 36s/epoch - 392ms/step
Epoch 35/1000
92/92 - 36s - loss: 0.5517 - NDCG@10: 0.9249 - MAE: 0.4142 - RC@5: 0.9712 - RC@10: 0.9852 - val_loss: 1.2782 - val_NDCG@10: 0.8504 - val_MAE: 0.3651 - val_RC@5: 0.9199 - val_RC@10: 0.9545 - lr: 4.8268e-04 - e_time: 36.0138 - 36s/epoch - 391ms/step
Epoch 36/1000
92/92 - 36s - loss: 0.5369 - NDCG@10: 0.9265 - MAE: 0.4129 - RC@5: 0.9721 - RC@10: 0.9858 - val_loss: 1.3041 - val_NDCG@10: 0.8494 - val_MAE: 0.3633 - val_RC@5: 0.9207 - val_RC@10: 0.9539 - lr: 4.8218e-04 - e_time: 36.0164 - 36s/epoch - 391ms/step
Epoch 37/1000
92/92 - 36s - loss: 0.5306 - NDCG@10: 0.9279 - MAE: 0.4124 - RC@5: 0.9733 - RC@10: 0.9864 - val_loss: 1.2973 - val_NDCG@10: 0.8501 - val_MAE: 0.3638 - val_RC@5: 0.9214 - val_RC@10: 0.9551 - lr: 4.8169e-04 - e_time: 36.0155 - 36s/epoch - 391ms/step
Epoch 38/1000
92/92 - 36s - loss: 0.5271 - NDCG@10: 0.9283 - MAE: 0.4128 - RC@5: 0.9730 - RC@10: 0.9862 - val_loss: 1.2746 - val_NDCG@10: 0.8512 - val_MAE: 0.3626 - val_RC@5: 0.9212 - val_RC@10: 0.9559 - lr: 4.8119e-04 - e_time: 36.0345 - 36s/epoch - 392ms/step
Epoch 39/1000
92/92 - 36s - loss: 0.5149 - NDCG@10: 0.9296 - MAE: 0.4130 - RC@5: 0.9739 - RC@10: 0.9867 - val_loss: 1.3143 - val_NDCG@10: 0.8495 - val_MAE: 0.3634 - val_RC@5: 0.9194 - val_RC@10: 0.9548 - lr: 4.8070e-04 - e_time: 36.0246 - 36s/epoch - 392ms/step
Epoch 40/1000
92/92 - 36s - loss: 0.5049 - NDCG@10: 0.9306 - MAE: 0.4117 - RC@5: 0.9742 - RC@10: 0.9866 - val_loss: 1.3117 - val_NDCG@10: 0.8507 - val_MAE: 0.3614 - val_RC@5: 0.9214 - val_RC@10: 0.9553 - lr: 4.8020e-04 - e_time: 36.0329 - 36s/epoch - 392ms/step
Epoch 41/1000
92/92 - 36s - loss: 0.4962 - NDCG@10: 0.9319 - MAE: 0.4107 - RC@5: 0.9760 - RC@10: 0.9875 - val_loss: 1.3753 - val_NDCG@10: 0.8474 - val_MAE: 0.3634 - val_RC@5: 0.9191 - val_RC@10: 0.9526 - lr: 4.7971e-04 - e_time: 36.0345 - 36s/epoch - 392ms/step
Epoch 42/1000
92/92 - 36s - loss: 0.4889 - NDCG@10: 0.9332 - MAE: 0.4106 - RC@5: 0.9756 - RC@10: 0.9877 - val_loss: 1.3638 - val_NDCG@10: 0.8469 - val_MAE: 0.3597 - val_RC@5: 0.9183 - val_RC@10: 0.9531 - lr: 4.7921e-04 - e_time: 36.0229 - 36s/epoch - 392ms/step
Epoch 43/1000
92/92 - 36s - loss: 0.4824 - NDCG@10: 0.9344 - MAE: 0.4100 - RC@5: 0.9764 - RC@10: 0.9875 - val_loss: 1.3741 - val_NDCG@10: 0.8484 - val_MAE: 0.3582 - val_RC@5: 0.9186 - val_RC@10: 0.9541 - lr: 4.7872e-04 - e_time: 36.0480 - 36s/epoch - 392ms/step
Epoch 44/1000
92/92 - 36s - loss: 0.4749 - NDCG@10: 0.9348 - MAE: 0.4100 - RC@5: 0.9768 - RC@10: 0.9883 - val_loss: 1.3737 - val_NDCG@10: 0.8475 - val_MAE: 0.3581 - val_RC@5: 0.9218 - val_RC@10: 0.9530 - lr: 4.7822e-04 - e_time: 36.0544 - 36s/epoch - 392ms/step
Epoch 45/1000
92/92 - 36s - loss: 0.4676 - NDCG@10: 0.9361 - MAE: 0.4098 - RC@5: 0.9768 - RC@10: 0.9883 - val_loss: 1.4101 - val_NDCG@10: 0.8454 - val_MAE: 0.3582 - val_RC@5: 0.9180 - val_RC@10: 0.9506 - lr: 4.7773e-04 - e_time: 36.0401 - 36s/epoch - 392ms/step
Epoch 46/1000
92/92 - 36s - loss: 0.4596 - NDCG@10: 0.9363 - MAE: 0.4094 - RC@5: 0.9774 - RC@10: 0.9883 - val_loss: 1.4194 - val_NDCG@10: 0.8434 - val_MAE: 0.3582 - val_RC@5: 0.9168 - val_RC@10: 0.9509 - lr: 4.7723e-04 - e_time: 36.0375 - 36s/epoch - 392ms/step
Epoch 47/1000
92/92 - 36s - loss: 0.4569 - NDCG@10: 0.9372 - MAE: 0.4086 - RC@5: 0.9783 - RC@10: 0.9886 - val_loss: 1.4011 - val_NDCG@10: 0.8490 - val_MAE: 0.3559 - val_RC@5: 0.9197 - val_RC@10: 0.9539 - lr: 4.7674e-04 - e_time: 36.0245 - 36s/epoch - 392ms/step
Epoch 48/1000
92/92 - 36s - loss: 0.4459 - NDCG@10: 0.9387 - MAE: 0.4095 - RC@5: 0.9796 - RC@10: 0.9895 - val_loss: 1.4375 - val_NDCG@10: 0.8450 - val_MAE: 0.3585 - val_RC@5: 0.9167 - val_RC@10: 0.9509 - lr: 4.7624e-04 - e_time: 36.0280 - 36s/epoch - 392ms/step
Epoch 49/1000
92/92 - 36s - loss: 0.4420 - NDCG@10: 0.9385 - MAE: 0.4094 - RC@5: 0.9788 - RC@10: 0.9895 - val_loss: 1.4747 - val_NDCG@10: 0.8448 - val_MAE: 0.3564 - val_RC@5: 0.9165 - val_RC@10: 0.9507 - lr: 4.7575e-04 - e_time: 36.0259 - 36s/epoch - 392ms/step
Epoch 50/1000
92/92 - 36s - loss: 0.4353 - NDCG@10: 0.9397 - MAE: 0.4087 - RC@5: 0.9799 - RC@10: 0.9899 - val_loss: 1.4640 - val_NDCG@10: 0.8425 - val_MAE: 0.3568 - val_RC@5: 0.9155 - val_RC@10: 0.9498 - lr: 4.7525e-04 - e_time: 36.0494 - 36s/epoch - 392ms/step
Epoch 51/1000
92/92 - 36s - loss: 0.4281 - NDCG@10: 0.9401 - MAE: 0.4079 - RC@5: 0.9801 - RC@10: 0.9896 - val_loss: 1.4652 - val_NDCG@10: 0.8421 - val_MAE: 0.3579 - val_RC@5: 0.9151 - val_RC@10: 0.9515 - lr: 4.7476e-04 - e_time: 36.0266 - 36s/epoch - 392ms/step
Epoch 52/1000
92/92 - 36s - loss: 0.4255 - NDCG@10: 0.9406 - MAE: 0.4077 - RC@5: 0.9807 - RC@10: 0.9901 - val_loss: 1.4869 - val_NDCG@10: 0.8405 - val_MAE: 0.3575 - val_RC@5: 0.9141 - val_RC@10: 0.9499 - lr: 4.7426e-04 - e_time: 36.0448 - 36s/epoch - 392ms/step
Epoch 53/1000
92/92 - 36s - loss: 0.4238 - NDCG@10: 0.9408 - MAE: 0.4075 - RC@5: 0.9801 - RC@10: 0.9897 - val_loss: 1.5011 - val_NDCG@10: 0.8430 - val_MAE: 0.3512 - val_RC@5: 0.9176 - val_RC@10: 0.9513 - lr: 4.7377e-04 - e_time: 36.0319 - 36s/epoch - 392ms/step
Epoch 54/1000
92/92 - 36s - loss: 0.4132 - NDCG@10: 0.9421 - MAE: 0.4071 - RC@5: 0.9813 - RC@10: 0.9908 - val_loss: 1.5001 - val_NDCG@10: 0.8468 - val_MAE: 0.3521 - val_RC@5: 0.9164 - val_RC@10: 0.9539 - lr: 4.7327e-04 - e_time: 36.0148 - 36s/epoch - 391ms/step
Epoch 55/1000
92/92 - 36s - loss: 0.4132 - NDCG@10: 0.9418 - MAE: 0.4078 - RC@5: 0.9810 - RC@10: 0.9906 - val_loss: 1.4711 - val_NDCG@10: 0.8480 - val_MAE: 0.3533 - val_RC@5: 0.9191 - val_RC@10: 0.9548 - lr: 4.7278e-04 - e_time: 36.0118 - 36s/epoch - 391ms/step
Epoch 56/1000
92/92 - 36s - loss: 0.4000 - NDCG@10: 0.9438 - MAE: 0.4072 - RC@5: 0.9819 - RC@10: 0.9906 - val_loss: 1.5048 - val_NDCG@10: 0.8464 - val_MAE: 0.3517 - val_RC@5: 0.9181 - val_RC@10: 0.9522 - lr: 4.7228e-04 - e_time: 36.0300 - 36s/epoch - 392ms/step
Epoch 57/1000
92/92 - 36s - loss: 0.3938 - NDCG@10: 0.9446 - MAE: 0.4061 - RC@5: 0.9824 - RC@10: 0.9912 - val_loss: 1.5128 - val_NDCG@10: 0.8451 - val_MAE: 0.3499 - val_RC@5: 0.9199 - val_RC@10: 0.9527 - lr: 4.7179e-04 - e_time: 36.0351 - 36s/epoch - 392ms/step
Epoch 58/1000
92/92 - 36s - loss: 0.3859 - NDCG@10: 0.9448 - MAE: 0.4068 - RC@5: 0.9831 - RC@10: 0.9916 - val_loss: 1.5515 - val_NDCG@10: 0.8458 - val_MAE: 0.3496 - val_RC@5: 0.9180 - val_RC@10: 0.9517 - lr: 4.7129e-04 - e_time: 36.0353 - 36s/epoch - 392ms/step
Epoch 59/1000
92/92 - 36s - loss: 0.3874 - NDCG@10: 0.9448 - MAE: 0.4061 - RC@5: 0.9829 - RC@10: 0.9913 - val_loss: 1.5289 - val_NDCG@10: 0.8473 - val_MAE: 0.3503 - val_RC@5: 0.9179 - val_RC@10: 0.9522 - lr: 4.7080e-04 - e_time: 36.0466 - 36s/epoch - 392ms/step
Epoch 60/1000
92/92 - 36s - loss: 0.3802 - NDCG@10: 0.9459 - MAE: 0.4066 - RC@5: 0.9828 - RC@10: 0.9913 - val_loss: 1.5628 - val_NDCG@10: 0.8461 - val_MAE: 0.3479 - val_RC@5: 0.9174 - val_RC@10: 0.9527 - lr: 4.7030e-04 - e_time: 36.0383 - 36s/epoch - 392ms/step
Epoch 60: early stopping
[92m[INFO] Loading best model...[0m
Using TensorFlow backend
[93m[WARNING] Model folder already exists...[0m
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 padding_mask (InputLayer)   [(None, None)]               0         []                            
                                                                                                  
 segment_ids (InputLayer)    [(None, None)]               0         []                            
                                                                                                  
 token_ids (InputLayer)      [(None, None)]               0         []                            
                                                                                                  
 bert_backbone (BertBackbon  {'sequence_output': (None,   4385920   ['padding_mask[0][0]',        
 e)                           None, 128),                            'segment_ids[0][0]',         
                              'pooled_output': (None, 1              'token_ids[0][0]']           
                             28)}                                                                 
                                                                                                  
 dropout (Dropout)           (None, None, 128)            0         ['bert_backbone[0][1]']       
                                                                                                  
 tf.__operators__.getitem_1  (None, 128)                  0         ['dropout[0][0]']             
  (SlicingOpLambda)                                                                               
                                                                                                  
 out (Dense)                 (None, 86)                   11094     ['tf.__operators__.getitem_1[0
                                                                    ][0]']                        
                                                                                                  
==================================================================================================
Total params: 4397014 (16.77 MB)
Trainable params: 4397014 (16.77 MB)
Non-trainable params: 0 (0.00 Byte)
__________________________________________________________________________________________________
None
[92m[INFO] Model already trained. Loading weights...[0m
Using TensorFlow backend
[93m[WARNING] Model folder already exists...[0m
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 padding_mask (InputLayer)   [(None, None)]               0         []                            
                                                                                                  
 segment_ids (InputLayer)    [(None, None)]               0         []                            
                                                                                                  
 token_ids (InputLayer)      [(None, None)]               0         []                            
                                                                                                  
 bert_backbone (BertBackbon  {'sequence_output': (None,   4385920   ['padding_mask[0][0]',        
 e)                           None, 128),                            'segment_ids[0][0]',         
                              'pooled_output': (None, 1              'token_ids[0][0]']           
                             28)}                                                                 
                                                                                                  
 dropout (Dropout)           (None, None, 128)            0         ['bert_backbone[0][1]']       
                                                                                                  
 tf.__operators__.getitem_1  (None, 128)                  0         ['dropout[0][0]']             
  (SlicingOpLambda)                                                                               
                                                                                                  
 out (Dense)                 (None, 86)                   11094     ['tf.__operators__.getitem_1[0
                                                                    ][0]']                        
                                                                                                  
==================================================================================================
Total params: 4397014 (16.77 MB)
Trainable params: 4397014 (16.77 MB)
Non-trainable params: 0 (0.00 Byte)
__________________________________________________________________________________________________
None
[92m[INFO] Model already trained. Loading weights...[0m
Using TensorFlow backend
[93m[WARNING] Model folder already exists...[0m
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 padding_mask (InputLayer)   [(None, None)]               0         []                            
                                                                                                  
 segment_ids (InputLayer)    [(None, None)]               0         []                            
                                                                                                  
 token_ids (InputLayer)      [(None, None)]               0         []                            
                                                                                                  
 bert_backbone (BertBackbon  {'sequence_output': (None,   4385920   ['padding_mask[0][0]',        
 e)                           None, 128),                            'segment_ids[0][0]',         
                              'pooled_output': (None, 1              'token_ids[0][0]']           
                             28)}                                                                 
                                                                                                  
 dropout (Dropout)           (None, None, 128)            0         ['bert_backbone[0][1]']       
                                                                                                  
 tf.__operators__.getitem_1  (None, 128)                  0         ['dropout[0][0]']             
  (SlicingOpLambda)                                                                               
                                                                                                  
 out (Dense)                 (None, 86)                   11094     ['tf.__operators__.getitem_1[0
                                                                    ][0]']                        
                                                                                                  
==================================================================================================
Total params: 4397014 (16.77 MB)
Trainable params: 4397014 (16.77 MB)
Non-trainable params: 0 (0.00 Byte)
__________________________________________________________________________________________________
None
[92m[INFO] Model already trained. Loading weights...[0m
Using TensorFlow backend
[93m[WARNING] Model folder already exists...[0m
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 padding_mask (InputLayer)   [(None, None)]               0         []                            
                                                                                                  
 segment_ids (InputLayer)    [(None, None)]               0         []                            
                                                                                                  
 token_ids (InputLayer)      [(None, None)]               0         []                            
                                                                                                  
 bert_backbone (BertBackbon  {'sequence_output': (None,   4385920   ['padding_mask[0][0]',        
 e)                           None, 128),                            'segment_ids[0][0]',         
                              'pooled_output': (None, 1              'token_ids[0][0]']           
                             28)}                                                                 
                                                                                                  
 dropout (Dropout)           (None, None, 128)            0         ['bert_backbone[0][1]']       
                                                                                                  
 tf.__operators__.getitem_1  (None, 128)                  0         ['dropout[0][0]']             
  (SlicingOpLambda)                                                                               
                                                                                                  
 out (Dense)                 (None, 86)                   11094     ['tf.__operators__.getitem_1[0
                                                                    ][0]']                        
                                                                                                  
==================================================================================================
Total params: 4397014 (16.77 MB)
Trainable params: 4397014 (16.77 MB)
Non-trainable params: 0 (0.00 Byte)
__________________________________________________________________________________________________
None
[92m[INFO] Model already trained. Loading weights...[0m
