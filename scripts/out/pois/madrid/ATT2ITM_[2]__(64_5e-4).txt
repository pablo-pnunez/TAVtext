Model: "ATT2ITM_2"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 112)]        0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 134)]        0           []                               
                                                                                                  
 embedding (Embedding)          (None, 112, 45)      217620      ['input_1[0][0]']                
                                                                                                  
 in_rsts (Embedding)            (None, 134, 45)      6030        ['input_2[0][0]']                
                                                                                                  
 tf.math.not_equal (TFOpLambda)  (None, 112)         0           ['input_1[0][0]']                
                                                                                                  
 word_emb (Lambda)              (None, 112, 45)      0           ['embedding[0][0]']              
                                                                                                  
 rest_emb (Lambda)              (None, 134, 45)      0           ['in_rsts[0][0]']                
                                                                                                  
 tf.cast (TFOpLambda)           (None, 112)          0           ['tf.math.not_equal[0][0]']      
                                                                                                  
 dropout (Dropout)              (None, 112, 45)      0           ['word_emb[0][0]']               
                                                                                                  
 dropout_1 (Dropout)            (None, 134, 45)      0           ['rest_emb[0][0]']               
                                                                                                  
 tf.expand_dims (TFOpLambda)    (None, 112, 1)       0           ['tf.cast[0][0]']                
                                                                                                  
 lambda (Lambda)                (None, 112, 134)     0           ['dropout[0][0]',                
                                                                  'dropout_1[0][0]']              
                                                                                                  
 tf.tile (TFOpLambda)           (None, 112, 134)     0           ['tf.expand_dims[0][0]']         
                                                                                                  
 lambda_1 (Lambda)              (None, 112, 134)     0           ['lambda[0][0]',                 
                                                                  'tf.tile[0][0]']                
                                                                                                  
 dotprod (Activation)           (None, 112, 134)     0           ['lambda_1[0][0]']               
                                                                                                  
 sum (Lambda)                   (None, 134)          0           ['dotprod[0][0]']                
                                                                                                  
 normalization (Normalization)  (None, 134)          269         ['sum[0][0]']                    
                                                                                                  
 out (Activation)               (None, 134)          0           ['normalization[0][0]']          
                                                                                                  
==================================================================================================
Total params: 223,919
Trainable params: 223,650
Non-trainable params: 269
__________________________________________________________________________________________________
None
Epoch 1/1000
2068/2068 - 12s - loss: 2.5332 - NDCG10: 0.6341 - AUC: 0.9269 - r1: 0.4878 - p1: 0.4878 - F1: 0.1053 - val_loss: 1.7416 - val_NDCG10: 0.7689 - val_AUC: 0.9648 - val_r1: 0.6248 - val_p1: 0.6247 - val_F1: 0.2029 - lr: 4.9951e-04 - e_time: 11.5640 - 12s/epoch - 6ms/step
Epoch 2/1000
2068/2068 - 9s - loss: 1.5604 - NDCG10: 0.7871 - AUC: 0.9690 - r1: 0.6470 - p1: 0.6470 - F1: 0.2576 - val_loss: 1.4217 - val_NDCG10: 0.8110 - val_AUC: 0.9733 - val_r1: 0.6744 - val_p1: 0.6742 - val_F1: 0.3218 - lr: 4.9901e-04 - e_time: 8.8572 - 9s/epoch - 4ms/step
Epoch 3/1000
2068/2068 - 9s - loss: 1.3270 - NDCG10: 0.8198 - AUC: 0.9755 - r1: 0.6878 - p1: 0.6876 - F1: 0.3510 - val_loss: 1.2814 - val_NDCG10: 0.8285 - val_AUC: 0.9780 - val_r1: 0.6987 - val_p1: 0.6983 - val_F1: 0.3777 - lr: 4.9852e-04 - e_time: 8.8561 - 9s/epoch - 4ms/step
Epoch 4/1000
2068/2068 - 9s - loss: 1.1892 - NDCG10: 0.8390 - AUC: 0.9798 - r1: 0.7153 - p1: 0.7152 - F1: 0.4221 - val_loss: 1.1944 - val_NDCG10: 0.8386 - val_AUC: 0.9813 - val_r1: 0.7132 - val_p1: 0.7135 - val_F1: 0.4260 - lr: 4.9802e-04 - e_time: 8.7774 - 9s/epoch - 4ms/step
Epoch 5/1000
2068/2068 - 9s - loss: 1.0965 - NDCG10: 0.8517 - AUC: 0.9825 - r1: 0.7333 - p1: 0.7332 - F1: 0.4676 - val_loss: 1.1408 - val_NDCG10: 0.8450 - val_AUC: 0.9830 - val_r1: 0.7226 - val_p1: 0.7228 - val_F1: 0.4621 - lr: 4.9753e-04 - e_time: 8.7302 - 9s/epoch - 4ms/step
Epoch 6/1000
2068/2068 - 9s - loss: 1.0309 - NDCG10: 0.8606 - AUC: 0.9844 - r1: 0.7459 - p1: 0.7458 - F1: 0.5051 - val_loss: 1.1095 - val_NDCG10: 0.8475 - val_AUC: 0.9839 - val_r1: 0.7261 - val_p1: 0.7262 - val_F1: 0.4812 - lr: 4.9703e-04 - e_time: 8.7406 - 9s/epoch - 4ms/step
Epoch 7/1000
2068/2068 - 9s - loss: 0.9835 - NDCG10: 0.8665 - AUC: 0.9855 - r1: 0.7547 - p1: 0.7548 - F1: 0.5346 - val_loss: 1.0903 - val_NDCG10: 0.8497 - val_AUC: 0.9847 - val_r1: 0.7279 - val_p1: 0.7282 - val_F1: 0.4961 - lr: 4.9654e-04 - e_time: 8.7557 - 9s/epoch - 4ms/step
Epoch 8/1000
2068/2068 - 9s - loss: 0.9446 - NDCG10: 0.8723 - AUC: 0.9865 - r1: 0.7636 - p1: 0.7635 - F1: 0.5620 - val_loss: 1.0789 - val_NDCG10: 0.8501 - val_AUC: 0.9850 - val_r1: 0.7289 - val_p1: 0.7291 - val_F1: 0.5077 - lr: 4.9604e-04 - e_time: 8.7298 - 9s/epoch - 4ms/step
Epoch 9/1000
2068/2068 - 9s - loss: 0.9158 - NDCG10: 0.8763 - AUC: 0.9872 - r1: 0.7694 - p1: 0.7694 - F1: 0.5814 - val_loss: 1.0709 - val_NDCG10: 0.8508 - val_AUC: 0.9853 - val_r1: 0.7309 - val_p1: 0.7305 - val_F1: 0.5181 - lr: 4.9555e-04 - e_time: 8.8898 - 9s/epoch - 4ms/step
Epoch 10/1000
2068/2068 - 9s - loss: 0.8947 - NDCG10: 0.8791 - AUC: 0.9878 - r1: 0.7734 - p1: 0.7734 - F1: 0.5957 - val_loss: 1.0651 - val_NDCG10: 0.8508 - val_AUC: 0.9853 - val_r1: 0.7308 - val_p1: 0.7307 - val_F1: 0.5227 - lr: 4.9505e-04 - e_time: 8.8360 - 9s/epoch - 4ms/step
Epoch 11/1000
2068/2068 - 9s - loss: 0.8744 - NDCG10: 0.8819 - AUC: 0.9881 - r1: 0.7771 - p1: 0.7772 - F1: 0.6090 - val_loss: 1.0656 - val_NDCG10: 0.8504 - val_AUC: 0.9854 - val_r1: 0.7304 - val_p1: 0.7305 - val_F1: 0.5284 - lr: 4.9456e-04 - e_time: 8.8401 - 9s/epoch - 4ms/step
Epoch 12/1000
2068/2068 - 9s - loss: 0.8572 - NDCG10: 0.8841 - AUC: 0.9884 - r1: 0.7805 - p1: 0.7806 - F1: 0.6206 - val_loss: 1.0675 - val_NDCG10: 0.8505 - val_AUC: 0.9856 - val_r1: 0.7297 - val_p1: 0.7296 - val_F1: 0.5322 - lr: 4.9406e-04 - e_time: 8.8803 - 9s/epoch - 4ms/step
Epoch 13/1000
2068/2068 - 9s - loss: 0.8419 - NDCG10: 0.8863 - AUC: 0.9888 - r1: 0.7837 - p1: 0.7837 - F1: 0.6302 - val_loss: 1.0669 - val_NDCG10: 0.8496 - val_AUC: 0.9854 - val_r1: 0.7292 - val_p1: 0.7291 - val_F1: 0.5343 - lr: 4.9357e-04 - e_time: 8.8876 - 9s/epoch - 4ms/step
Epoch 14/1000
2068/2068 - 9s - loss: 0.8289 - NDCG10: 0.8882 - AUC: 0.9891 - r1: 0.7868 - p1: 0.7867 - F1: 0.6425 - val_loss: 1.0693 - val_NDCG10: 0.8496 - val_AUC: 0.9856 - val_r1: 0.7292 - val_p1: 0.7291 - val_F1: 0.5376 - lr: 4.9307e-04 - e_time: 8.8454 - 9s/epoch - 4ms/step
Epoch 15/1000
2068/2068 - 9s - loss: 0.8194 - NDCG10: 0.8900 - AUC: 0.9894 - r1: 0.7901 - p1: 0.7902 - F1: 0.6499 - val_loss: 1.0698 - val_NDCG10: 0.8485 - val_AUC: 0.9855 - val_r1: 0.7283 - val_p1: 0.7280 - val_F1: 0.5389 - lr: 4.9258e-04 - e_time: 8.8275 - 9s/epoch - 4ms/step
Epoch 16/1000
2068/2068 - 9s - loss: 0.8075 - NDCG10: 0.8917 - AUC: 0.9896 - r1: 0.7923 - p1: 0.7924 - F1: 0.6595 - val_loss: 1.0719 - val_NDCG10: 0.8490 - val_AUC: 0.9854 - val_r1: 0.7296 - val_p1: 0.7297 - val_F1: 0.5377 - lr: 4.9208e-04 - e_time: 8.8793 - 9s/epoch - 4ms/step
Epoch 17/1000
2068/2068 - 9s - loss: 0.8023 - NDCG10: 0.8922 - AUC: 0.9897 - r1: 0.7928 - p1: 0.7927 - F1: 0.6598 - val_loss: 1.0761 - val_NDCG10: 0.8482 - val_AUC: 0.9853 - val_r1: 0.7280 - val_p1: 0.7282 - val_F1: 0.5410 - lr: 4.9159e-04 - e_time: 8.8818 - 9s/epoch - 4ms/step
Epoch 18/1000
2068/2068 - 9s - loss: 0.7934 - NDCG10: 0.8938 - AUC: 0.9898 - r1: 0.7953 - p1: 0.7953 - F1: 0.6681 - val_loss: 1.0786 - val_NDCG10: 0.8474 - val_AUC: 0.9853 - val_r1: 0.7269 - val_p1: 0.7266 - val_F1: 0.5409 - lr: 4.9109e-04 - e_time: 8.8513 - 9s/epoch - 4ms/step
Epoch 19/1000
2068/2068 - 9s - loss: 0.7875 - NDCG10: 0.8943 - AUC: 0.9901 - r1: 0.7955 - p1: 0.7956 - F1: 0.6726 - val_loss: 1.0802 - val_NDCG10: 0.8466 - val_AUC: 0.9854 - val_r1: 0.7257 - val_p1: 0.7254 - val_F1: 0.5431 - lr: 4.9060e-04 - e_time: 8.8601 - 9s/epoch - 4ms/step
Epoch 20/1000
2068/2068 - 9s - loss: 0.7797 - NDCG10: 0.8954 - AUC: 0.9901 - r1: 0.7970 - p1: 0.7969 - F1: 0.6772 - val_loss: 1.0830 - val_NDCG10: 0.8461 - val_AUC: 0.9853 - val_r1: 0.7252 - val_p1: 0.7253 - val_F1: 0.5399 - lr: 4.9010e-04 - e_time: 8.8619 - 9s/epoch - 4ms/step
Epoch 20: early stopping
[92m[INFO] Loading best model...[0m
