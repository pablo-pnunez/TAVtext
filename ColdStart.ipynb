{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Par√°metros comunes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\"restaurants\":[\"gijon\", \"barcelona\", \"madrid\", \"paris\", \"newyorkcity\"],\n",
    "            \"pois\":[\"barcelona\", \"madrid\", \"paris\", \"newyorkcity\", \"london\"],\n",
    "            \"amazon\":[\"fashion\", \"digital_music\"]}\n",
    "\n",
    "models = [\"ATT2ITM\", \"BOW2ITM\", \"USEM2ITM\", \"BERT2ITM\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluar nuestros modelos solo en los casos de cold-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/nas/pperez/conda/ns3/envs/TAVtext/lib/python3.9/site-packages/keras_nlp/src/models/backbone.py:37: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  return id(getattr(self, attr)) not in self._functional_layer_ids\n",
      "/media/nas/pperez/conda/ns3/envs/TAVtext/lib/python3.9/site-packages/keras_nlp/src/models/backbone.py:37: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  return id(getattr(self, attr)) not in self._functional_layer_ids\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m[INFO] There are 1511 evaluation examples.\u001b[0m\n",
      "\u001b[92m       loss    NDCG@1   NDCG@10   NDCG@50  NDCG@100   NDCG@-1  Precision@-1  \\\n",
      "0  0.885943  0.755791  0.871724  0.878574  0.879011  0.879011      0.041326   \n",
      "\n",
      "   Precision@1  Precision@5  Precision@10  Recall@-1  Recall@1  Recall@5  \\\n",
      "0     0.755791     0.189676      0.096823   0.992058  0.755791  0.948379   \n",
      "\n",
      "   Recall@10  Recall@20  Recall@50     F1@-1      F1@1      F1@5     F1@10  \n",
      "0   0.968233   0.987426   0.997353  0.079346  0.755791  0.316126  0.176042  \u001b[0m\n",
      "\u001b[94mLoading best ATT2ITM model: b1fd2b9a5b758e60a01fad655ae73515\u001b[0m\n",
      "\u001b[93m[WARNING] Model folder already exists...\u001b[0m\n",
      "\u001b[93m[WARNING] Model weights are not loaded!\u001b[0m\n",
      "\u001b[92m[INFO] Best epoch number: 87\u001b[0m\n",
      "\u001b[92m[INFO] Model already trained. Loading weights...\u001b[0m\n",
      "\u001b[92m[INFO] There are 1198 evaluation examples.\u001b[0m\n",
      "\u001b[92m       loss    NDCG@1   NDCG@10   NDCG@50  NDCG@100   NDCG@-1  Precision@-1  \\\n",
      "0  0.008529  0.785476  0.884357  0.890497  0.890636  0.890636       0.85023   \n",
      "\n",
      "   Precision@1  Precision@5  Precision@10  Recall@-1  Recall@1  Recall@5  \\\n",
      "0     0.785476     0.189149      0.097412   0.616027  0.785476  0.945743   \n",
      "\n",
      "   Recall@10  Recall@20  Recall@50     F1@-1      F1@1      F1@5     F1@10  \n",
      "0   0.974124   0.992487   0.999165  0.714424  0.785476  0.315248  0.177113  \u001b[0m\n",
      "\u001b[94mLoading best BOW2ITM model: 58539f1981fab6b86e15924f1a7bf50f\u001b[0m\n",
      "\u001b[93m[WARNING] Model folder already exists...\u001b[0m\n",
      "\u001b[93m[WARNING] Model weights are not loaded!\u001b[0m\n",
      "\u001b[92m[INFO] Best epoch number: 64\u001b[0m\n",
      "\u001b[92m[INFO] Model already trained. Loading weights...\u001b[0m\n",
      "\u001b[92m[INFO] There are 1198 evaluation examples.\u001b[0m\n",
      "\u001b[92m       loss    NDCG@1   NDCG@10   NDCG@50  NDCG@100  NDCG@-1  Precision@-1  \\\n",
      "0  0.998149  0.755426  0.863115  0.871051   0.87119  0.87119      0.053263   \n",
      "\n",
      "   Precision@1  Precision@5  Precision@10  Recall@-1  Recall@1  Recall@5  \\\n",
      "0     0.755426     0.185643      0.096578   0.989983  0.755426  0.928214   \n",
      "\n",
      "   Recall@10  Recall@20  Recall@50     F1@-1      F1@1      F1@5     F1@10  \n",
      "0   0.965776   0.989149   0.999165  0.101087  0.755426  0.309405  0.175596  \u001b[0m\n",
      "\u001b[94mLoading best USEM2ITM model: b7caed7a4d82d3bc054e9ddf4172ff9c\u001b[0m\n",
      "\u001b[93m[WARNING] Model folder already exists...\u001b[0m\n",
      "\u001b[93m[WARNING] Model weights are not loaded!\u001b[0m\n",
      "\u001b[92m[INFO] Best epoch number: 10\u001b[0m\n",
      "\u001b[92m[INFO] Model already trained. Loading weights...\u001b[0m\n",
      "\u001b[92m[INFO] There are 1198 evaluation examples.\u001b[0m\n",
      "\u001b[92m       loss    NDCG@1   NDCG@10   NDCG@50  NDCG@100   NDCG@-1  Precision@-1  \\\n",
      "0  0.942888  0.793823  0.884281  0.890859  0.891708  0.891708      0.066914   \n",
      "\n",
      "   Precision@1  Precision@5  Precision@10  Recall@-1  Recall@1  Recall@5  \\\n",
      "0     0.793823     0.188147      0.096745   0.978297  0.793823  0.940735   \n",
      "\n",
      "   Recall@10  Recall@20  Recall@50     F1@-1      F1@1      F1@5     F1@10  \n",
      "0   0.967446   0.984975   0.994992  0.125261  0.793823  0.313578  0.175899  \u001b[0m\n",
      "\u001b[94mLoading best BERT2ITM model: 41f59df0da79e551ef9243d473bcef0e\u001b[0m\n",
      "\u001b[93m[WARNING] Model folder already exists...\u001b[0m\n",
      "Model: \"model_19\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " padding_mask (InputLayer)   [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " segment_ids (InputLayer)    [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " token_ids (InputLayer)      [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " bert_backbone (BertBackbon  {'sequence_output': (None,   4385920   ['padding_mask[0][0]',        \n",
      " e)                           None, 128),                            'segment_ids[0][0]',         \n",
      "                              'pooled_output': (None, 1              'token_ids[0][0]']           \n",
      "                             28)}                                                                 \n",
      "                                                                                                  \n",
      " dropout_39 (Dropout)        (None, None, 128)            0         ['bert_backbone[0][1]']       \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  (None, 128)                  0         ['dropout_39[0][0]']          \n",
      " 9 (SlicingOpLambda)                                                                              \n",
      "                                                                                                  \n",
      " out (Dense)                 (None, 63)                   8127      ['tf.__operators__.getitem_19[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4394047 (16.76 MB)\n",
      "Trainable params: 4394047 (16.76 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/nas/pperez/conda/ns3/envs/TAVtext/lib/python3.9/site-packages/keras_nlp/src/models/backbone.py:37: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  return id(getattr(self, attr)) not in self._functional_layer_ids\n",
      "/media/nas/pperez/conda/ns3/envs/TAVtext/lib/python3.9/site-packages/keras_nlp/src/models/backbone.py:37: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  return id(getattr(self, attr)) not in self._functional_layer_ids\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\u001b[93m[WARNING] Model weights are not loaded!\u001b[0m\n",
      "\u001b[92m[INFO] Best epoch number: 75\u001b[0m\n",
      "\u001b[92m[INFO] Model already trained. Loading weights...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/nas/pperez/conda/ns3/envs/TAVtext/lib/python3.9/site-packages/keras_nlp/src/models/backbone.py:37: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  return id(getattr(self, attr)) not in self._functional_layer_ids\n",
      "/media/nas/pperez/conda/ns3/envs/TAVtext/lib/python3.9/site-packages/keras_nlp/src/models/backbone.py:37: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  return id(getattr(self, attr)) not in self._functional_layer_ids\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m[INFO] There are 1198 evaluation examples.\u001b[0m\n",
      "\u001b[92m       loss    NDCG@1  NDCG@10   NDCG@50  NDCG@100   NDCG@-1  Precision@-1  \\\n",
      "0  0.844927  0.800501  0.88651  0.894328  0.894764  0.894764      0.042184   \n",
      "\n",
      "   Precision@1  Precision@5  Precision@10  Recall@-1  Recall@1  Recall@5  \\\n",
      "0     0.800501     0.188982      0.096411   0.992487  0.800501  0.944908   \n",
      "\n",
      "   Recall@10  Recall@20  Recall@50     F1@-1      F1@1      F1@5     F1@10  \n",
      "0   0.964107    0.98581   0.997496  0.080928  0.800501  0.314969  0.175292  \u001b[0m\n",
      "\u001b[94mLoading best ATT2ITM model: 35df7659227e1d9871e0be81787f66c6\u001b[0m\n",
      "\u001b[93m[WARNING] Model folder already exists...\u001b[0m\n",
      "\u001b[93m[WARNING] Model weights are not loaded!\u001b[0m\n",
      "\u001b[92m[INFO] Best epoch number: 510\u001b[0m\n",
      "\u001b[92m[INFO] Model already trained. Loading weights...\u001b[0m\n",
      "\u001b[92m[INFO] There are 15448 evaluation examples.\u001b[0m\n",
      "\u001b[92m       loss   NDCG@1   NDCG@10   NDCG@50  NDCG@100   NDCG@-1  Precision@-1  \\\n",
      "0  3.527125  0.33124  0.477773  0.517407  0.528167  0.543129       0.01893   \n",
      "\n",
      "   Precision@1  Precision@5  Precision@10  Recall@-1  Recall@1  Recall@5  \\\n",
      "0      0.33124     0.110629      0.064144   0.773369   0.33124  0.553146   \n",
      "\n",
      "   Recall@10  Recall@20  Recall@50     F1@-1     F1@1      F1@5     F1@10  \n",
      "0   0.641442   0.722035   0.818099  0.036956  0.33124  0.184382  0.116626  \u001b[0m\n",
      "\u001b[94mLoading best BOW2ITM model: 2bf0d3793edf66c690c9d37fa4afa6b2\u001b[0m\n",
      "\u001b[93m[WARNING] Model folder already exists...\u001b[0m\n",
      "\u001b[93m[WARNING] Model weights are not loaded!\u001b[0m\n",
      "\u001b[92m[INFO] Best epoch number: 28\u001b[0m\n",
      "\u001b[92m[INFO] Model already trained. Loading weights...\u001b[0m\n",
      "\u001b[92m[INFO] There are 15448 evaluation examples.\u001b[0m\n",
      "\u001b[92m       loss    NDCG@1   NDCG@10   NDCG@50  NDCG@100   NDCG@-1  Precision@-1  \\\n",
      "0  4.065667  0.265601  0.401084  0.443823  0.455474  0.478213      0.003858   \n",
      "\n",
      "   Precision@1  Precision@5  Precision@10  Recall@-1  Recall@1  Recall@5  \\\n",
      "0     0.265536     0.094109      0.055807   0.916753  0.265536  0.470546   \n",
      "\n",
      "   Recall@10  Recall@20  Recall@50     F1@-1      F1@1      F1@5     F1@10  \n",
      "0   0.558066    0.64565   0.748835  0.007683  0.265536  0.156849  0.101467  \u001b[0m\n",
      "\u001b[94mLoading best USEM2ITM model: b73849c1547e35e73b945f1ac891bf3e\u001b[0m\n",
      "\u001b[93m[WARNING] Model folder already exists...\u001b[0m\n",
      "\u001b[93m[WARNING] Model weights are not loaded!\u001b[0m\n",
      "\u001b[92m[INFO] Best epoch number: 222\u001b[0m\n",
      "\u001b[92m[INFO] Model already trained. Loading weights...\u001b[0m\n",
      "\u001b[92m[INFO] There are 15448 evaluation examples.\u001b[0m\n",
      "\u001b[92m       loss    NDCG@1   NDCG@10   NDCG@50  NDCG@100   NDCG@-1  Precision@-1  \\\n",
      "0  6.280683  0.002784  0.034589  0.077497  0.098309  0.171432      0.003122   \n",
      "\n",
      "   Precision@1  Precision@5  Precision@10  Recall@-1  Recall@1  Recall@5  \\\n",
      "0     0.002784     0.011652      0.007865   0.516313  0.002784   0.05826   \n",
      "\n",
      "   Recall@10  Recall@20  Recall@50     F1@-1      F1@1     F1@5   F1@10  \n",
      "0   0.078651   0.155813   0.275764  0.006207  0.002784  0.01942  0.0143  \u001b[0m\n",
      "\u001b[94mLoading best BERT2ITM model: 7f21293988cf9aa7e9b2b02465f497e3\u001b[0m\n",
      "\u001b[93m[WARNING] Model folder already exists...\u001b[0m\n",
      "Model: \"model_21\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " padding_mask (InputLayer)   [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " segment_ids (InputLayer)    [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " token_ids (InputLayer)      [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " bert_backbone (BertBackbon  {'sequence_output': (None,   4385920   ['padding_mask[0][0]',        \n",
      " e)                           None, 128),                            'segment_ids[0][0]',         \n",
      "                              'pooled_output': (None, 1              'token_ids[0][0]']           \n",
      "                             28)}                                                                 \n",
      "                                                                                                  \n",
      " dropout_43 (Dropout)        (None, None, 128)            0         ['bert_backbone[0][1]']       \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2  (None, 128)                  0         ['dropout_43[0][0]']          \n",
      " 1 (SlicingOpLambda)                                                                              \n",
      "                                                                                                  \n",
      " out (Dense)                 (None, 706)                  91074     ['tf.__operators__.getitem_21[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4476994 (17.08 MB)\n",
      "Trainable params: 4476994 (17.08 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/nas/pperez/conda/ns3/envs/TAVtext/lib/python3.9/site-packages/keras_nlp/src/models/backbone.py:37: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  return id(getattr(self, attr)) not in self._functional_layer_ids\n",
      "/media/nas/pperez/conda/ns3/envs/TAVtext/lib/python3.9/site-packages/keras_nlp/src/models/backbone.py:37: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  return id(getattr(self, attr)) not in self._functional_layer_ids\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\u001b[93m[WARNING] Model weights are not loaded!\u001b[0m\n",
      "\u001b[92m[INFO] Best epoch number: 10\u001b[0m\n",
      "\u001b[92m[INFO] Model already trained. Loading weights...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/nas/pperez/conda/ns3/envs/TAVtext/lib/python3.9/site-packages/keras_nlp/src/models/backbone.py:37: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  return id(getattr(self, attr)) not in self._functional_layer_ids\n",
      "/media/nas/pperez/conda/ns3/envs/TAVtext/lib/python3.9/site-packages/keras_nlp/src/models/backbone.py:37: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  return id(getattr(self, attr)) not in self._functional_layer_ids\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m[INFO] There are 15448 evaluation examples.\u001b[0m\n",
      "\u001b[92m       loss    NDCG@1   NDCG@10   NDCG@50  NDCG@100   NDCG@-1  Precision@-1  \\\n",
      "0  6.287388  0.002784  0.036435  0.076279  0.097074  0.170903      0.003123   \n",
      "\n",
      "   Precision@1  Precision@5  Precision@10  Recall@-1  Recall@1  Recall@5  \\\n",
      "0     0.002784      0.01138      0.008499   0.499612  0.002784  0.056901   \n",
      "\n",
      "   Recall@10  Recall@20  Recall@50     F1@-1      F1@1      F1@5     F1@10  \n",
      "0   0.084995   0.147657   0.270262  0.006207  0.002784  0.018967  0.015454  \u001b[0m\n",
      "\u001b[94mLoading best ATT2ITM model: 83d7299d69e036237427036eafe7886a\u001b[0m\n",
      "\u001b[93m[WARNING] Model folder already exists...\u001b[0m\n",
      "\u001b[93m[WARNING] Model weights are not loaded!\u001b[0m\n",
      "\u001b[92m[INFO] Best epoch number: 480\u001b[0m\n",
      "\u001b[92m[INFO] Model already trained. Loading weights...\u001b[0m\n",
      "\u001b[92m[INFO] There are 14781 evaluation examples.\u001b[0m\n",
      "\u001b[92m       loss    NDCG@1   NDCG@10   NDCG@50  NDCG@100   NDCG@-1  Precision@-1  \\\n",
      "0  3.969818  0.343346  0.452882  0.488525  0.500731  0.524597      0.009668   \n",
      "\n",
      "   Precision@1  Precision@5  Precision@10  Recall@-1  Recall@1  Recall@5  \\\n",
      "0     0.343346     0.101698      0.057276   0.750626  0.343346  0.508491   \n",
      "\n",
      "   Recall@10  Recall@20  Recall@50    F1@-1      F1@1      F1@5     F1@10  \n",
      "0   0.572762   0.637372    0.73493  0.01909  0.343346  0.169497  0.104139  \u001b[0m\n",
      "\u001b[94mLoading best BOW2ITM model: f6437033f3c383c81bafbcd296d11122\u001b[0m\n",
      "\u001b[93m[WARNING] Model folder already exists...\u001b[0m\n",
      "\u001b[93m[WARNING] Model weights are not loaded!\u001b[0m\n",
      "\u001b[92m[INFO] Best epoch number: 62\u001b[0m\n",
      "\u001b[92m[INFO] Model already trained. Loading weights...\u001b[0m\n",
      "\u001b[92m[INFO] There are 14781 evaluation examples.\u001b[0m\n",
      "\u001b[92m       loss    NDCG@1   NDCG@10   NDCG@50  NDCG@100   NDCG@-1  Precision@-1  \\\n",
      "0  4.640017  0.275759  0.373396  0.409514  0.422389  0.456022      0.002166   \n",
      "\n",
      "   Precision@1  Precision@5  Precision@10  Recall@-1  Recall@1  Recall@5  \\\n",
      "0     0.274677        0.084      0.048305   0.909681  0.274677  0.419999   \n",
      "\n",
      "   Recall@10  Recall@20  Recall@50     F1@-1      F1@1  F1@5     F1@10  \n",
      "0   0.483053   0.549422   0.647926  0.004323  0.274677  0.14  0.087828  \u001b[0m\n",
      "\u001b[94mLoading best USEM2ITM model: 79e6447f873f01e909da8f0dca6627ca\u001b[0m\n",
      "\u001b[93m[WARNING] Model folder already exists...\u001b[0m\n",
      "\u001b[93m[WARNING] Model weights are not loaded!\u001b[0m\n",
      "\u001b[92m[INFO] Best epoch number: 196\u001b[0m\n",
      "\u001b[92m[INFO] Model already trained. Loading weights...\u001b[0m\n",
      "\u001b[92m[INFO] There are 14781 evaluation examples.\u001b[0m\n",
      "\u001b[92m       loss    NDCG@1   NDCG@10   NDCG@50  NDCG@100  NDCG@-1  Precision@-1  \\\n",
      "0  6.572861  0.018673  0.052101  0.084622  0.103453  0.17878      0.002194   \n",
      "\n",
      "   Precision@1  Precision@5  Precision@10  Recall@-1  Recall@1  Recall@5  \\\n",
      "0     0.018673     0.013084      0.009593   0.567215  0.018673  0.065422   \n",
      "\n",
      "   Recall@10  Recall@20  Recall@50     F1@-1      F1@1      F1@5     F1@10  \n",
      "0   0.095934   0.145592   0.247953  0.004371  0.018673  0.021807  0.017443  \u001b[0m\n",
      "\u001b[94mLoading best BERT2ITM model: 9eb53ca88e5907c852217107ac3677ee\u001b[0m\n",
      "\u001b[93m[WARNING] Model folder already exists...\u001b[0m\n",
      "Model: \"model_23\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " padding_mask (InputLayer)   [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " segment_ids (InputLayer)    [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " token_ids (InputLayer)      [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " bert_backbone (BertBackbon  {'sequence_output': (None,   4385920   ['padding_mask[0][0]',        \n",
      " e)                           None, 128),                            'segment_ids[0][0]',         \n",
      "                              'pooled_output': (None, 1              'token_ids[0][0]']           \n",
      "                             28)}                                                                 \n",
      "                                                                                                  \n",
      " dropout_47 (Dropout)        (None, None, 128)            0         ['bert_backbone[0][1]']       \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2  (None, 128)                  0         ['dropout_47[0][0]']          \n",
      " 3 (SlicingOpLambda)                                                                              \n",
      "                                                                                                  \n",
      " out (Dense)                 (None, 1028)                 132612    ['tf.__operators__.getitem_23[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4518532 (17.24 MB)\n",
      "Trainable params: 4518532 (17.24 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/nas/pperez/conda/ns3/envs/TAVtext/lib/python3.9/site-packages/keras_nlp/src/models/backbone.py:37: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  return id(getattr(self, attr)) not in self._functional_layer_ids\n",
      "/media/nas/pperez/conda/ns3/envs/TAVtext/lib/python3.9/site-packages/keras_nlp/src/models/backbone.py:37: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  return id(getattr(self, attr)) not in self._functional_layer_ids\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\u001b[93m[WARNING] Model weights are not loaded!\u001b[0m\n",
      "\u001b[92m[INFO] Best epoch number: 87\u001b[0m\n",
      "\u001b[92m[INFO] Model already trained. Loading weights...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/nas/pperez/conda/ns3/envs/TAVtext/lib/python3.9/site-packages/keras_nlp/src/models/backbone.py:37: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  return id(getattr(self, attr)) not in self._functional_layer_ids\n",
      "/media/nas/pperez/conda/ns3/envs/TAVtext/lib/python3.9/site-packages/keras_nlp/src/models/backbone.py:37: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  return id(getattr(self, attr)) not in self._functional_layer_ids\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m[INFO] There are 14781 evaluation examples.\u001b[0m\n",
      "\u001b[92m       loss    NDCG@1   NDCG@10   NDCG@50  NDCG@100   NDCG@-1  Precision@-1  \\\n",
      "0  6.572719  0.018537  0.051918  0.084069  0.102849  0.178579      0.002127   \n",
      "\n",
      "   Precision@1  Precision@5  Precision@10  Recall@-1  Recall@1  Recall@5  \\\n",
      "0     0.018537     0.013125      0.009587    0.57831  0.018537  0.065625   \n",
      "\n",
      "   Recall@10  Recall@20  Recall@50     F1@-1      F1@1      F1@5    F1@10  \n",
      "0   0.095866   0.143833   0.245924  0.004239  0.018537  0.021875  0.01743  \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from src.experiments.Common import load_best_model\n",
    "import pandas as pd\n",
    "\n",
    "cold_start_res = []\n",
    "\n",
    "for dataset, subsets in datasets.items():\n",
    "    for subset in subsets:\n",
    "        for model in models:\n",
    "            # Cargar configuraci√≥n mejor modelo\n",
    "            model_class = load_best_model(model=model, dataset=dataset, subset=subset)\n",
    "            # Cargar el modelo entrenado\n",
    "            model_class.train(dev=False, save_model=True)\n",
    "            # Eliminar usuarios que aparecen en TRAIN\n",
    "            train_dev_users = model_class.DATASET.DATA[\"TRAIN_DEV\"].userId.unique()\n",
    "            # original_test_len = len(model_class.DATASET.DATA[\"TEST\"])\n",
    "            model_class.DATASET.DATA[\"TEST\"] = model_class.DATASET.DATA[\"TEST\"][~model_class.DATASET.DATA[\"TEST\"][\"userId\"].isin(train_dev_users)]\n",
    "            model_class.DATASET.DATA[\"TEST\"] = model_class.DATASET.DATA[\"TEST\"].drop_duplicates(subset=[\"userId\", \"id_item\"], keep='last', inplace=False)\n",
    "            # Evaluar en el conjunto de test\n",
    "            test_ret = model_class.evaluate(test=True)\n",
    "            cold_start_res.append([dataset, subset, model]+test_ret.values.tolist()[0][1:]+[len(model_class.DATASET.DATA[\"TEST\"])])\n",
    "\n",
    "results = pd.DataFrame(cold_start_res, columns=[\"Set\", \"Subset\", \"Model\"] + test_ret.columns.tolist()[1:]+[\"cold_items\"])\n",
    "# cold_start_res.to_excel(\"cold_start_evaluation.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generar tabla Latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = pd.read_excel(\"/media/nas/pperez/code/TAVtext/cold_start_evaluation.xlsx\")\n",
    "# Poner nombres decentes para el art√≠culo\n",
    "results[\"Set\"].replace({\"restaurants\": \"TAV-RSTS\", \"pois\":\"TAV-POIS\", \"amazon\":\"AM\"}, inplace=True)\n",
    "results[\"Subset\"].replace({\"digital_music\": \"Music\", \"fashion\":\"Fashion\", \"gijon\": \"Gij√≥n\", \"barcelona\":\"Barcelona\", \"madrid\": \"Madrid\", \"paris\": \"Paris\", \"newyorkcity\": \"New York\", \"london\": \"London\"}, inplace=True)\n",
    "results[\"Model\"].replace({\"USEM2ITM\":\"USEM\", \"BERT2ITM\":\"BERT\", \"BOW2ITM\":\"TRecX\", \"ATT2ITM\": \"AITRecX\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllrrrr}\n",
      "\\toprule\n",
      "         &       & Model &     TRecX &   AITRecX &      USEM &      BERT \\\\\n",
      "Set & Subset & Metric &           &           &           &           \\\\\n",
      "\\midrule\n",
      "AM & Music & Recall@5 &  0.419999 &  0.508491 &  0.065422 &  0.065625 \\\\\n",
      "         &       & Recall@10 &  0.483053 &  0.572762 &  0.095934 &  0.095866 \\\\\n",
      "         &       & NDCG@10 &  0.373396 &  0.452882 &  0.052101 &  0.051918 \\\\\n",
      "         & Fashion & Recall@5 &  0.470546 &  0.553146 &  0.058260 &  0.056901 \\\\\n",
      "         &       & Recall@10 &  0.558066 &  0.641442 &  0.078651 &  0.084995 \\\\\n",
      "         &       & NDCG@10 &  0.401084 &  0.477773 &  0.034589 &  0.036435 \\\\\n",
      "TAV-POIS & Barcelona & Recall@5 &  0.919263 &  0.935552 &  0.922805 &  0.921034 \\\\\n",
      "         &       & Recall@10 &  0.955737 &  0.966006 &  0.950779 &  0.953612 \\\\\n",
      "         &       & NDCG@10 &  0.847057 &  0.865142 &  0.861960 &  0.858370 \\\\\n",
      "         & Madrid & Recall@5 &  0.912214 &  0.923664 &  0.914838 &  0.923664 \\\\\n",
      "         &       & Recall@10 &  0.953244 &  0.961116 &  0.943225 &  0.952529 \\\\\n",
      "         &       & NDCG@10 &  0.843640 &  0.864532 &  0.863793 &  0.866968 \\\\\n",
      "         & New York & Recall@5 &  0.926539 &  0.939775 &  0.941760 &  0.948379 \\\\\n",
      "         &       & Recall@10 &  0.962277 &  0.971542 &  0.972204 &  0.968233 \\\\\n",
      "         &       & NDCG@10 &  0.841469 &  0.860069 &  0.868840 &  0.871724 \\\\\n",
      "         & Paris & Recall@5 &  0.951311 &  0.960300 &  0.958052 &  0.955805 \\\\\n",
      "         &       & Recall@10 &  0.974532 &  0.979026 &  0.982022 &  0.982022 \\\\\n",
      "         &       & NDCG@10 &  0.883615 &  0.900399 &  0.906813 &  0.900954 \\\\\n",
      "         & London & Recall@5 &  0.928214 &  0.945743 &  0.940735 &  0.944908 \\\\\n",
      "         &       & Recall@10 &  0.965776 &  0.974124 &  0.967446 &  0.964107 \\\\\n",
      "         &       & NDCG@10 &  0.863115 &  0.884357 &  0.884281 &  0.886510 \\\\\n",
      "TAV-RSTS & Gij√≥n & Recall@5 &  0.578484 &  0.635995 &  0.559540 &  0.584574 \\\\\n",
      "         &       & Recall@10 &  0.670501 &  0.739513 &  0.627199 &  0.682003 \\\\\n",
      "         &       & NDCG@10 &  0.506228 &  0.569218 &  0.503350 &  0.524881 \\\\\n",
      "         & Barcelona & Recall@5 &  0.436285 &  0.497216 &  0.446581 &  0.493644 \\\\\n",
      "         &       & Recall@10 &  0.511503 &  0.571804 &  0.512554 &  0.564975 \\\\\n",
      "         &       & NDCG@10 &  0.380988 &  0.437154 &  0.396065 &  0.427811 \\\\\n",
      "         & Madrid & Recall@5 &  0.495591 &  0.535012 &  0.490842 &  0.520238 \\\\\n",
      "         &       & Recall@10 &  0.565539 &  0.607372 &  0.557624 &  0.595387 \\\\\n",
      "         &       & NDCG@10 &  0.434502 &  0.471268 &  0.429668 &  0.433668 \\\\\n",
      "         & New York & Recall@5 &  0.553627 &  0.609571 &  0.590746 &  0.612457 \\\\\n",
      "         &       & Recall@10 &  0.623719 &  0.675964 &  0.657017 &  0.681493 \\\\\n",
      "         &       & NDCG@10 &  0.496689 &  0.547023 &  0.534710 &  0.518266 \\\\\n",
      "         & Paris & Recall@5 &  0.349445 &  0.413720 &  0.363782 &  0.383605 \\\\\n",
      "         &       & Recall@10 &  0.411637 &  0.478996 &  0.426575 &  0.467542 \\\\\n",
      "         &       & NDCG@10 &  0.307114 &  0.364946 &  0.322868 &  0.317050 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3887499/3593426627.py:19: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(result_df[models].to_latex())\n"
     ]
    }
   ],
   "source": [
    "metrics = [\"Recall@5\", \"Recall@10\", \"NDCG@10\"]\n",
    "models = ['TRecX', 'AITRecX', 'USEM', 'BERT']\n",
    "\n",
    "result_df = []\n",
    "\n",
    "for metric in metrics:\n",
    "    mres = results.pivot_table(index=[ \"Set\", \"Subset\"], columns=[\"Model\"])[metric].reset_index()\n",
    "    mres[\"Metric\"] = metric\n",
    "    result_df.extend(mres.values)\n",
    "\n",
    "result_df = pd.DataFrame(result_df, columns=mres.columns)\n",
    "\n",
    "# Especificar el orden de los datos\n",
    "result_df['Set'] = pd.Categorical(result_df['Set'], [\"AM\", \"TAV-POIS\", \"TAV-RSTS\"])\n",
    "result_df['Subset'] = pd.Categorical(result_df['Subset'], [\"Music\", \"Fashion\", \"Gij√≥n\", \"Barcelona\", \"Madrid\", \"New York\", \"Paris\", \"London\"])\n",
    "result_df['Metric'] = pd.Categorical(result_df['Metric'], metrics)\n",
    "\n",
    "result_df = result_df.pivot_table(index=[\"Set\", \"Subset\", \"Metric\"])\n",
    "print(result_df[models].to_latex())\n",
    "result_df.to_excel(\"cold_start_results.xlsx\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gr√°ficas de evoluci√≥n de nuestros modelos y baselines en funci√≥n del usuarios en Train\n",
    "No parece verse mejora clara en los baselines, por tanto no se mostrar√°n gr√°ficas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "top = 5\n",
    "cumulate = True\n",
    "\n",
    "datasets = {\"restaurants\":[\"gijon\", \"barcelona\", \"madrid\", \"paris\", \"newyorkcity\"],\n",
    "            \"pois\":[\"barcelona\", \"madrid\", \"paris\", \"newyorkcity\", \"london\"],\n",
    "            \"amazon\":[\"fashion\", \"digital_music\"]}\n",
    "\n",
    "datasets = {\"restaurants\":[\"barcelona\"]}\n",
    "\n",
    "models = [\"ATT2ITM\", \"BOW2ITM\", \"USEM2ITM\"]\n",
    "\n",
    "best_model = pd.read_csv(\"models/best_models.csv\")\n",
    "\n",
    "for dataset, subsets in datasets.items():\n",
    "    for subset in subsets:\n",
    "        fig, ax = plt.subplots(figsize=(10, 5))\n",
    "        ax2 = ax.twinx()\n",
    "        subset_results = pd.DataFrame(range(top+1), columns=[\"train_dev_items\"])\n",
    "        \n",
    "        baseline_path = f\"models/Baselines/{dataset}/{subset}/user_results.csv\"\n",
    "        if os.path.exists(baseline_path): \n",
    "            baselines = pd.read_csv(baseline_path).rename(columns={\"cold\":\"train_dev_items\"})\n",
    "            baselines_names = baselines.columns.to_list(); baselines_names.remove(\"userId\"); baselines_names.remove(\"train_dev_items\")\n",
    "            baselines = baselines.groupby(\"train_dev_items\")[baselines_names].mean().reset_index()\n",
    "            subset_results = subset_results.merge(baselines, how=\"left\")\n",
    "\n",
    "            for bl in baselines_names: # [\"GridSearch_BPR\", \"GridSearch_EASE·¥ø\", \"MostPop\"]: \n",
    "                if cumulate: subset_results[bl] = subset_results[bl].expanding().mean()\n",
    "                ax.plot(subset_results[\"train_dev_items\"], subset_results[bl], \"--\", label=bl)\n",
    "\n",
    "        else: raise ValueError\n",
    "\n",
    "        for model in models:\n",
    "            md5 = best_model.loc[(best_model.dataset == dataset) & (best_model.subset == subset) & (best_model.model == model)][\"model_md5\"].values[0]\n",
    "            results_path = f\"models/{model}/{dataset}/{subset}/{md5}/final_user_eval.csv\"\n",
    "            if os.path.exists(results_path):\n",
    "                results = pd.read_csv(results_path)\n",
    "                results = results.groupby(\"cold\").agg(mn=(\"NDCG\", \"mean\"), n_samples=(\"NDCG\", \"count\")).reset_index().rename(columns={\"cold\":\"train_dev_items\", \"mn\":model})\n",
    "                if cumulate: results[model] = results[model].expanding().mean()\n",
    "                subset_results = subset_results.merge(results, how=\"left\")\n",
    "                ax.plot(subset_results[\"train_dev_items\"], subset_results[model], \"-\", label=model)\n",
    "            else:\n",
    "                raise ValueError\n",
    "        \n",
    "        subset_results[\"n_samples\"] = subset_results[\"n_samples\"].fillna(0)\n",
    "\n",
    "        ax2.plot(subset_results[\"train_dev_items\"], subset_results[\"n_samples\"], \":\",label=\"\")\n",
    "\n",
    "        ax.set_ylim([0, 1])\n",
    "        ax2.set_ylim([0, subset_results[\"n_samples\"].max()])\n",
    "        ax.set_ylabel('AVG NDCG')\n",
    "        plt.title(f\"{dataset.title()} - {subset.title()}\")\n",
    "        ax.set_xlabel(\"Number of reviews in Train set\")\n",
    "        # ax.set_xticks(range(top+1))\n",
    "        # ax.set_xlim([0, top])\n",
    "        ax2.set_ylabel('Number of Test cases')\n",
    "\n",
    "        ax.legend()\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TAV_text",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
