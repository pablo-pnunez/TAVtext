{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parámetros comunes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\"restaurants\":[\"gijon\", \"barcelona\", \"madrid\", \"paris\", \"newyorkcity\"],\n",
    "            \"pois\":[\"barcelona\", \"madrid\", \"paris\", \"newyorkcity\", \"london\"],\n",
    "            \"amazon\":[\"fashion\", \"digital_music\"]}\n",
    "\n",
    "models = [\"ATT2ITM\", \"BOW2ITM\", \"USEM2ITM\", \"BERT2ITM\"]\n",
    "models = [\"MOSTPOP2ITM\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluar nuestros modelos solo en los casos de cold-start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto es una solución \"temporal\" para poder obtener los resultados del baseline \"MostPopular\" para el cold-start.\n",
    "El problema es que no hay que entrenarlos y no hay un \"best_model\", por tanto el resto del flujo no funciona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.experiments.Common import load_best_model\n",
    "import pandas as pd\n",
    "\n",
    "cold_start_res = []\n",
    "\n",
    "for dataset, subsets in datasets.items():\n",
    "    for subset in subsets:\n",
    "        for model in models:\n",
    "            # Cargar configuración mejor modelo\n",
    "            model_class = load_best_model(model=model, dataset=dataset, subset=subset)\n",
    "            # Cargar el modelo entrenado\n",
    "            model_class.train(dev=False, save_model=True)\n",
    "            # Eliminar usuarios que aparecen en TRAIN\n",
    "            train_dev_users = model_class.DATASET.DATA[\"TRAIN_DEV\"].userId.unique()\n",
    "            # original_test_len = len(model_class.DATASET.DATA[\"TEST\"])\n",
    "            model_class.DATASET.DATA[\"TEST\"] = model_class.DATASET.DATA[\"TEST\"][~model_class.DATASET.DATA[\"TEST\"][\"userId\"].isin(train_dev_users)]\n",
    "            model_class.DATASET.DATA[\"TEST\"] = model_class.DATASET.DATA[\"TEST\"].drop_duplicates(subset=[\"userId\", \"id_item\"], keep='last', inplace=False)\n",
    "            # Evaluar en el conjunto de test\n",
    "            test_ret = model_class.evaluate(test=True)\n",
    "            cold_start_res.append([dataset, subset, model]+test_ret.values.tolist()[0][1:]+[len(model_class.DATASET.DATA[\"TEST\"])])\n",
    "\n",
    "results = pd.DataFrame(cold_start_res, columns=[\"Set\", \"Subset\", \"Model\"] + test_ret.columns.tolist()[1:]+[\"cold_items\"])\n",
    "# cold_start_res.to_excel(\"cold_start_evaluation.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generar tabla Latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = pd.read_excel(\"/media/nas/pperez/code/TAVtext/cold_start_evaluation.xlsx\")\n",
    "# Poner nombres decentes para el artículo\n",
    "results[\"Set\"].replace({\"restaurants\": \"TAV-RSTS\", \"pois\":\"TAV-POIS\", \"amazon\":\"AM\"}, inplace=True)\n",
    "results[\"Subset\"].replace({\"digital_music\": \"Music\", \"fashion\":\"Fashion\", \"gijon\": \"Gijón\", \"barcelona\":\"Barcelona\", \"madrid\": \"Madrid\", \"paris\": \"Paris\", \"newyorkcity\": \"New York\", \"london\": \"London\"}, inplace=True)\n",
    "results[\"Model\"].replace({\"USEM2ITM\":\"USEM\", \"BERT2ITM\":\"BERT\", \"BOW2ITM\":\"TRecX\", \"ATT2ITM\": \"AITRecX\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllrrrr}\n",
      "\\toprule\n",
      "         &       & Model &     TRecX &   AITRecX &      USEM &      BERT \\\\\n",
      "Set & Subset & Metric &           &           &           &           \\\\\n",
      "\\midrule\n",
      "AM & Music & Recall@5 &  0.419999 &  0.508491 &  0.065422 &  0.065625 \\\\\n",
      "         &       & Recall@10 &  0.483053 &  0.572762 &  0.095934 &  0.095866 \\\\\n",
      "         &       & NDCG@10 &  0.373396 &  0.452882 &  0.052101 &  0.051918 \\\\\n",
      "         & Fashion & Recall@5 &  0.470546 &  0.553146 &  0.058260 &  0.056901 \\\\\n",
      "         &       & Recall@10 &  0.558066 &  0.641442 &  0.078651 &  0.084995 \\\\\n",
      "         &       & NDCG@10 &  0.401084 &  0.477773 &  0.034589 &  0.036435 \\\\\n",
      "TAV-POIS & Barcelona & Recall@5 &  0.919263 &  0.935552 &  0.922805 &  0.921034 \\\\\n",
      "         &       & Recall@10 &  0.955737 &  0.966006 &  0.950779 &  0.953612 \\\\\n",
      "         &       & NDCG@10 &  0.847057 &  0.865142 &  0.861960 &  0.858370 \\\\\n",
      "         & Madrid & Recall@5 &  0.912214 &  0.923664 &  0.914838 &  0.923664 \\\\\n",
      "         &       & Recall@10 &  0.953244 &  0.961116 &  0.943225 &  0.952529 \\\\\n",
      "         &       & NDCG@10 &  0.843640 &  0.864532 &  0.863793 &  0.866968 \\\\\n",
      "         & New York & Recall@5 &  0.926539 &  0.939775 &  0.941760 &  0.948379 \\\\\n",
      "         &       & Recall@10 &  0.962277 &  0.971542 &  0.972204 &  0.968233 \\\\\n",
      "         &       & NDCG@10 &  0.841469 &  0.860069 &  0.868840 &  0.871724 \\\\\n",
      "         & Paris & Recall@5 &  0.951311 &  0.960300 &  0.958052 &  0.955805 \\\\\n",
      "         &       & Recall@10 &  0.974532 &  0.979026 &  0.982022 &  0.982022 \\\\\n",
      "         &       & NDCG@10 &  0.883615 &  0.900399 &  0.906813 &  0.900954 \\\\\n",
      "         & London & Recall@5 &  0.928214 &  0.945743 &  0.940735 &  0.944908 \\\\\n",
      "         &       & Recall@10 &  0.965776 &  0.974124 &  0.967446 &  0.964107 \\\\\n",
      "         &       & NDCG@10 &  0.863115 &  0.884357 &  0.884281 &  0.886510 \\\\\n",
      "TAV-RSTS & Gijón & Recall@5 &  0.578484 &  0.635995 &  0.559540 &  0.584574 \\\\\n",
      "         &       & Recall@10 &  0.670501 &  0.739513 &  0.627199 &  0.682003 \\\\\n",
      "         &       & NDCG@10 &  0.506228 &  0.569218 &  0.503350 &  0.524881 \\\\\n",
      "         & Barcelona & Recall@5 &  0.436285 &  0.497216 &  0.446581 &  0.493644 \\\\\n",
      "         &       & Recall@10 &  0.511503 &  0.571804 &  0.512554 &  0.564975 \\\\\n",
      "         &       & NDCG@10 &  0.380988 &  0.437154 &  0.396065 &  0.427811 \\\\\n",
      "         & Madrid & Recall@5 &  0.495591 &  0.535012 &  0.490842 &  0.520238 \\\\\n",
      "         &       & Recall@10 &  0.565539 &  0.607372 &  0.557624 &  0.595387 \\\\\n",
      "         &       & NDCG@10 &  0.434502 &  0.471268 &  0.429668 &  0.433668 \\\\\n",
      "         & New York & Recall@5 &  0.553627 &  0.609571 &  0.590746 &  0.612457 \\\\\n",
      "         &       & Recall@10 &  0.623719 &  0.675964 &  0.657017 &  0.681493 \\\\\n",
      "         &       & NDCG@10 &  0.496689 &  0.547023 &  0.534710 &  0.518266 \\\\\n",
      "         & Paris & Recall@5 &  0.349445 &  0.413720 &  0.363782 &  0.383605 \\\\\n",
      "         &       & Recall@10 &  0.411637 &  0.478996 &  0.426575 &  0.467542 \\\\\n",
      "         &       & NDCG@10 &  0.307114 &  0.364946 &  0.322868 &  0.317050 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3887499/3593426627.py:19: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(result_df[models].to_latex())\n"
     ]
    }
   ],
   "source": [
    "metrics = [\"Recall@5\", \"Recall@10\", \"NDCG@10\"]\n",
    "models = ['TRecX', 'AITRecX', 'USEM', 'BERT']\n",
    "\n",
    "result_df = []\n",
    "\n",
    "for metric in metrics:\n",
    "    mres = results.pivot_table(index=[ \"Set\", \"Subset\"], columns=[\"Model\"])[metric].reset_index()\n",
    "    mres[\"Metric\"] = metric\n",
    "    result_df.extend(mres.values)\n",
    "\n",
    "result_df = pd.DataFrame(result_df, columns=mres.columns)\n",
    "\n",
    "# Especificar el orden de los datos\n",
    "result_df['Set'] = pd.Categorical(result_df['Set'], [\"AM\", \"TAV-POIS\", \"TAV-RSTS\"])\n",
    "result_df['Subset'] = pd.Categorical(result_df['Subset'], [\"Music\", \"Fashion\", \"Gijón\", \"Barcelona\", \"Madrid\", \"New York\", \"Paris\", \"London\"])\n",
    "result_df['Metric'] = pd.Categorical(result_df['Metric'], metrics)\n",
    "\n",
    "result_df = result_df.pivot_table(index=[\"Set\", \"Subset\", \"Metric\"])\n",
    "print(result_df[models].to_latex())\n",
    "result_df.to_excel(\"cold_start_results.xlsx\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráficas de evolución de nuestros modelos y baselines en función del usuarios en Train\n",
    "No parece verse mejora clara en los baselines, por tanto no se mostrarán gráficas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "top = 5\n",
    "cumulate = True\n",
    "\n",
    "datasets = {\"restaurants\":[\"gijon\", \"barcelona\", \"madrid\", \"paris\", \"newyorkcity\"],\n",
    "            \"pois\":[\"barcelona\", \"madrid\", \"paris\", \"newyorkcity\", \"london\"],\n",
    "            \"amazon\":[\"fashion\", \"digital_music\"]}\n",
    "\n",
    "datasets = {\"restaurants\":[\"barcelona\"]}\n",
    "\n",
    "models = [\"ATT2ITM\", \"BOW2ITM\", \"USEM2ITM\"]\n",
    "\n",
    "best_model = pd.read_csv(\"models/best_models.csv\")\n",
    "\n",
    "for dataset, subsets in datasets.items():\n",
    "    for subset in subsets:\n",
    "        fig, ax = plt.subplots(figsize=(10, 5))\n",
    "        ax2 = ax.twinx()\n",
    "        subset_results = pd.DataFrame(range(top+1), columns=[\"train_dev_items\"])\n",
    "        \n",
    "        baseline_path = f\"models/Baselines/{dataset}/{subset}/user_results.csv\"\n",
    "        if os.path.exists(baseline_path): \n",
    "            baselines = pd.read_csv(baseline_path).rename(columns={\"cold\":\"train_dev_items\"})\n",
    "            baselines_names = baselines.columns.to_list(); baselines_names.remove(\"userId\"); baselines_names.remove(\"train_dev_items\")\n",
    "            baselines = baselines.groupby(\"train_dev_items\")[baselines_names].mean().reset_index()\n",
    "            subset_results = subset_results.merge(baselines, how=\"left\")\n",
    "\n",
    "            for bl in baselines_names: # [\"GridSearch_BPR\", \"GridSearch_EASEᴿ\", \"MostPop\"]: \n",
    "                if cumulate: subset_results[bl] = subset_results[bl].expanding().mean()\n",
    "                ax.plot(subset_results[\"train_dev_items\"], subset_results[bl], \"--\", label=bl)\n",
    "\n",
    "        else: raise ValueError\n",
    "\n",
    "        for model in models:\n",
    "            md5 = best_model.loc[(best_model.dataset == dataset) & (best_model.subset == subset) & (best_model.model == model)][\"model_md5\"].values[0]\n",
    "            results_path = f\"models/{model}/{dataset}/{subset}/{md5}/final_user_eval.csv\"\n",
    "            if os.path.exists(results_path):\n",
    "                results = pd.read_csv(results_path)\n",
    "                results = results.groupby(\"cold\").agg(mn=(\"NDCG\", \"mean\"), n_samples=(\"NDCG\", \"count\")).reset_index().rename(columns={\"cold\":\"train_dev_items\", \"mn\":model})\n",
    "                if cumulate: results[model] = results[model].expanding().mean()\n",
    "                subset_results = subset_results.merge(results, how=\"left\")\n",
    "                ax.plot(subset_results[\"train_dev_items\"], subset_results[model], \"-\", label=model)\n",
    "            else:\n",
    "                raise ValueError\n",
    "        \n",
    "        subset_results[\"n_samples\"] = subset_results[\"n_samples\"].fillna(0)\n",
    "\n",
    "        ax2.plot(subset_results[\"train_dev_items\"], subset_results[\"n_samples\"], \":\",label=\"\")\n",
    "\n",
    "        ax.set_ylim([0, 1])\n",
    "        ax2.set_ylim([0, subset_results[\"n_samples\"].max()])\n",
    "        ax.set_ylabel('AVG NDCG')\n",
    "        plt.title(f\"{dataset.title()} - {subset.title()}\")\n",
    "        ax.set_xlabel(\"Number of reviews in Train set\")\n",
    "        # ax.set_xticks(range(top+1))\n",
    "        # ax.set_xlim([0, top])\n",
    "        ax2.set_ylabel('Number of Test cases')\n",
    "\n",
    "        ax.legend()\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TAV_text",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
