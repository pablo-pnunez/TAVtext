{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0) # only difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross attention is an attention mechanism that mixes two different embedding sequences.\n",
    "\n",
    "Note that:\n",
    " - The two sequences must have the same dimension.\n",
    " - The two sequences can be of different modalities (e.g. text, image, sound).\n",
    " - One of the sequences defines the output length as it plays a role of a query input.\n",
    " - The other sequence then produces key and value input.\n",
    " \n",
    "![selfatt](https://i.imgur.com/ikt6Lfi.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_a:(1, 6), seq_b:(5, 3)\n",
      "Wq:(6, 2), Wk:(3, 2), Wv:(3, 2)\n",
      "q:(1, 2), k:(5, 2), v:(5, 2)\n"
     ]
    }
   ],
   "source": [
    "# https://vaclavkosar.com/ml/cross-attention-in-transformer-architecture\n",
    "# https://colab.research.google.com/github/mrm8488/shared_colab_notebooks/blob/master/basic_self_attention_.ipynb\n",
    "\n",
    "restaurant = np.array([[1,2,1,3,4,4]]) # 1x6\n",
    "review = np.array([[1,2,1],[2,2,2],[2,0,2],[0,2,0],[2,1,1]]) # 5x3\n",
    "\n",
    "restaurant = tf.convert_to_tensor(restaurant, dtype=tf.float32)\n",
    "review = tf.convert_to_tensor(review, dtype=tf.float32)\n",
    "\n",
    "# La nueva dimensión tiene que ser la misma (q y k, no v)\n",
    "Wq = np.array([[1, 0], [1, 1], [0, 1], [1, 1], [1, 1], [0, 1]]) # 4x2\n",
    "Wk = np.array([[1, 0], [0, 1], [1, 0]]) # 3x2\n",
    "Wv = np.array([[1, 1], [1, 1], [1, 1]]) # 3x2\n",
    "\n",
    "Wq = tf.convert_to_tensor(Wq, dtype=tf.float32)\n",
    "Wk = tf.convert_to_tensor(Wk, dtype=tf.float32)\n",
    "Wv = tf.convert_to_tensor(Wv, dtype=tf.float32)\n",
    "\n",
    "# Proyección\n",
    "q = tf.matmul(restaurant, Wq)\n",
    "k = tf.matmul(review, Wk)\n",
    "v = tf.matmul(review, Wv)\n",
    "\n",
    "print(f\"seq_a:{restaurant.shape}, seq_b:{review.shape}\")\n",
    "print(f\"Wq:{Wq.shape}, Wk:{Wk.shape}, Wv:{Wv.shape}\")\n",
    "print(f\"q:{q.shape}, k:{k.shape}, v:{v.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "att_shape:(1, 5), out_shape:(1, 2)\n"
     ]
    }
   ],
   "source": [
    "att_w = tf.matmul(q, k, transpose_b=True)\n",
    "att_w = tf.nn.softmax(att_w, axis=-1)\n",
    "\n",
    "weighted_values = v[:,None] * tf.transpose(att_w)[:,:,None]\n",
    "out = tf.reduce_sum(weighted_values, axis=0)  # 6\n",
    "\n",
    "print(f\"att_shape:{att_w.shape}, out_shape:{out.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```OJO: PARECE QUE KERAS PROYECTA SALIDA AL TAMAÑO DE LA ENTRADA DE QUERY SI NO SE LE DICE NADA```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "att_shape:(1, 1, 1, 5), out_shape:(1, 1, 6)\n"
     ]
    }
   ],
   "source": [
    "layer = tf.keras.layers.MultiHeadAttention(num_heads=1, key_dim=2, value_dim=2, output_shape=None)\n",
    "output_tensor, weights = layer(query=tf.expand_dims(restaurant,0), key=tf.expand_dims(review,0), value=tf.expand_dims(review,0), return_attention_scores=True)\n",
    "out = output_tensor.numpy()\n",
    "att_w =  weights.numpy()\n",
    "\n",
    "# Output: \n",
    "# if output_shape is None, the output shape is (B, T, E), where T is for target sequence shapes and E is the query input last dimension.\n",
    "# Otherwise, the multi-head outputs are project to the shape specified by output_shape.\n",
    "print(f\"att_shape:{att_w.shape}, out_shape:{out.shape}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "59c3167cb05e6f7e97c99e9a79591d7e7581f0ddda224877569af6fd2f440cfc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('TAV_text')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
