{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"models/Baselines\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar pandas\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "datasets = {\"restaurants\":[\"gijon\", \"barcelona\", \"madrid\", \"paris\", \"newyorkcity\"],\n",
    "            \"pois\":[\"barcelona\", \"madrid\", \"paris\", \"newyorkcity\", \"london\"],\n",
    "            \"amazon\":[\"fashion\", \"digital_music\"]}\n",
    "\n",
    "column_names = None\n",
    "all_data = []\n",
    "\n",
    "for dataset, subsets in datasets.items():\n",
    "    for subset in subsets:\n",
    "        # Definir el nombre del fichero\n",
    "        path = f\"/media/nas/pperez/code/TAVtext/{base_path}/{dataset}/{subset}/\"\n",
    "        # path+=[f for f in os.listdir(path) if \".log\" in f][0]\n",
    "        # Leer el fichero con pandas, saltando las primeras dos l√≠neas y usando el separador |\n",
    "        #df = pd.read_csv(path, skiprows=2, sep=\"|\", comment=\"-\", header=1)\n",
    "        path+=\"results.csv\"\n",
    "        df = pd.read_csv(path)\n",
    "        df = df.sort_values(\"F1@1\", ascending=False).reset_index(drop=True)\n",
    "        df.insert(0, \"Position\", df.index+1)\n",
    "        df[\"Set\"] = dataset\n",
    "        df[\"Subset\"] = subset\n",
    "\n",
    "        if column_names is None: column_names = df.columns # [\"Model\"] + [c.strip() for c in df.columns[1:]]\n",
    "        \n",
    "        all_data.extend(df.to_records(index=False).tolist())\n",
    "\n",
    "all_data = pd.DataFrame(all_data, columns=column_names)\n",
    "all_data.to_excel(f\"/media/nas/pperez/code/TAVtext/{base_path}/all_results.xlsx\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.Common import print_b, print_e\n",
    "from src.datasets.text_datasets.RestaurantDataset import RestaurantDataset\n",
    "from src.datasets.text_datasets.AmazonDataset import AmazonDataset\n",
    "from src.datasets.text_datasets.POIDataset import POIDataset\n",
    "\n",
    "from cornac.eval_methods import BaseMethod\n",
    "from cornac.data.text import BaseTokenizer\n",
    "from cornac.data import ReviewModality\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nvgpu\n",
    "import json\n",
    "\n",
    "gpu = int(np.argmin(list(map(lambda x: x[\"mem_used_percent\"], nvgpu.gpu_info())))) \n",
    "\n",
    "def load_set(dataset, subset, model = \"ATT2ITM\"):\n",
    "    best_model = pd.read_csv(\"models/best_models.csv\")\n",
    "    best_model = best_model.loc[(best_model.dataset == dataset) & (best_model.subset == subset) & (best_model.model == model)][\"model_md5\"].values[0]\n",
    "    model_path = f\"models/{model}/{dataset}/{subset}/{best_model}\"\n",
    "    with open(f'{model_path}/cfg.json') as f: model_config = json.load(f)\n",
    "    dts_cfg = model_config[\"dataset_config\"]\n",
    "    with open(f'{model_path}/cfg.json') as f: model_config = json.load(f)\n",
    "    mdl_cfg = {\"model\": model_config[\"model\"], \"session\": {\"gpu\": gpu, \"mixed_precision\": False, \"in_md5\": False}}\n",
    "\n",
    "    print_b(f\"Loading best model: {best_model}\")\n",
    "\n",
    "    if dataset == \"restaurants\":\n",
    "        # text_dataset = RestaurantDataset(dts_cfg, load=[\"TRAIN_DEV\", \"TEXT_TOKENIZER\", \"TEXT_SEQUENCES\", \"WORD_INDEX\", \"VOCAB_SIZE\", \"MAX_LEN_PADDING\", \"N_ITEMS\", \"FEATURES_NAME\", \"BOW_SEQUENCES\"])\n",
    "        text_dataset = RestaurantDataset(dts_cfg)\n",
    "    elif dataset == \"pois\":\n",
    "        text_dataset = POIDataset(dts_cfg)\n",
    "    elif dataset == \"amazon\":\n",
    "        text_dataset = AmazonDataset(dts_cfg)\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "\n",
    "    all_data = pd.read_pickle(f\"{text_dataset.DATASET_PATH}ALL_DATA\")\n",
    "    all_data[\"rating\"]/=10\n",
    "    all_data=all_data[[\"userId\", \"id_item\", \"rating\", \"dev\", \"test\", \"text\"]]\n",
    "\n",
    "    # Eliminar usuarios desconocidos y dividir en 3 subconjuntos\n",
    "    train_data = all_data[(all_data[\"dev\"] == 0) & (all_data[\"test\"] == 0)]\n",
    "    train_users = train_data[\"userId\"].unique()\n",
    "    id_user, userId = pd.factorize(train_data[\"userId\"])\n",
    "    user_map = pd.DataFrame(zip(userId, id_user), columns=[\"userId\", \"id_user\"])\n",
    "    val_data = all_data[(all_data[\"dev\"] == 1) & (all_data[\"userId\"].isin(train_users))]\n",
    "    test_data = all_data[(all_data[\"test\"] == 1) & (all_data[\"userId\"].isin(train_users))]\n",
    "\n",
    "    train_data = train_data.merge(user_map)[[\"id_user\", \"id_item\", \"rating\"]]\n",
    "    val_data = val_data.merge(user_map)[[\"id_user\", \"id_item\", \"rating\"]].drop_duplicates(subset=[\"id_user\", \"id_item\"], keep='last', inplace=False)\n",
    "    test_data = test_data.merge(user_map)[[\"id_user\", \"id_item\", \"rating\"]].drop_duplicates(subset=[\"id_user\", \"id_item\"], keep='last', inplace=False)\n",
    "\n",
    "    # Instantiate a Base evaluation method using the provided train and test sets\n",
    "    eval_method = BaseMethod.from_splits(train_data=train_data.to_records(index=False), val_data=val_data.to_records(index=False), test_data=test_data.to_records(index=False),  verbose=False, rating_threshold=3)\n",
    "    # Ojo, lo anterior elimina las repeticiones de USUARIO, ITEM\n",
    "\n",
    "    # max_vocab = 3000\n",
    "    # max_doc_freq = 0.5\n",
    "    # tokenizer = BaseTokenizer()\n",
    "    # reviews = all_data.drop_duplicates(subset=[\"userId\", \"id_item\"], keep='last', inplace=False).merge(user_map)[[\"id_user\", \"id_item\", \"text\"]].to_records(index=False).tolist()\n",
    "    # eval_method = BaseMethod.from_splits(train_data=train_data.to_records(index=False), review_text=rm, val_data=val_data.to_records(index=False), test_data=test_data.to_records(index=False),  verbose=True, rating_threshold=3)\n",
    "\n",
    "    return text_dataset, eval_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cornac.metrics import Recall, Precision, FMeasure\n",
    "from cornac.experiment import Experiment\n",
    "import cornac\n",
    "\n",
    "seed = 2048\n",
    "\n",
    "metrics = [\n",
    "    FMeasure(k=1), FMeasure(k=5), FMeasure(k=10),\n",
    "    Recall(k=1), Recall(k=5), Recall(k=10),\n",
    "    Precision(k=1), Precision(k=5), Precision(k=10)\n",
    "    ]\n",
    "\n",
    "models = [\n",
    "    cornac.models.MostPop(),\n",
    "    cornac.models.BPR(seed=seed),\n",
    "    cornac.models.EASE(seed=seed)\n",
    "]\n",
    "\n",
    "model = \"ATT2ITM\"\n",
    "datasets = {\"restaurants\":[\"gijon\", \"barcelona\"]}\n",
    "\n",
    "for dataset, subsets in datasets.items():\n",
    "    for subset in subsets:\n",
    "        text_dataset, eval_method = load_set(dataset, subset)\n",
    "        test_result = Experiment(\n",
    "            eval_method=eval_method,\n",
    "            show_validation=False,\n",
    "            models=models,\n",
    "            metrics=metrics,\n",
    "            save_dir=f\"{base_path}/{dataset}/{subset}\", \n",
    "            verbose=True\n",
    "        ).run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from cornac.metrics import Recall, Precision, FMeasure\n",
    "from cornac.hyperopt import GridSearch, Discrete\n",
    "from cornac.experiment import Experiment\n",
    "import cornac\n",
    "\n",
    "seed = 2048\n",
    "\n",
    "dataset = \"restaurants\"\n",
    "subset = \"barcelona\"\n",
    "\n",
    "metrics = [\n",
    "    FMeasure(k=1), FMeasure(k=5), FMeasure(k=10),\n",
    "    Recall(k=1), Recall(k=5), Recall(k=10),\n",
    "    Precision(k=1), Precision(k=5), Precision(k=10)\n",
    "    ]\n",
    "\n",
    "_, eval_method = load_set(dataset, subset)\n",
    "\n",
    "md_bpr = cornac.models.BPR(seed=seed, verbose=True) #  k=50, max_iter=200, learning_rate=0.001, lambda_reg=0.001, verbose=True\n",
    "md_ease = cornac.models.EASE(seed=seed, verbose=True) \n",
    "\n",
    "models = [\n",
    "    GridSearch(\n",
    "        model=md_bpr, space=[ \n",
    "            Discrete(\"k\", [25, 50, 75]), \n",
    "            Discrete(\"max_iter\", [50, 100, 200]), \n",
    "            Discrete(\"learning_rate\", [1e-4, 5e-4, 1e-3]), \n",
    "        ], metric=FMeasure(k=1), eval_method=eval_method),\n",
    "    GridSearch(\n",
    "        model=md_ease, space=[\n",
    "            Discrete(\"posB\", [True, False]),\n",
    "        ], metric=FMeasure(k=1), eval_method=eval_method),\n",
    "    ]\n",
    "\n",
    "# Put everything together into an experiment and run it\n",
    "test_result = Experiment(\n",
    "    eval_method=eval_method,\n",
    "    models=models,\n",
    "    metrics=metrics,\n",
    "    user_based=False,\n",
    "    save_dir=f\"{base_path}/{dataset}/{subset}\", \n",
    "    verbose=True\n",
    ").run()\n",
    "\n",
    "print(test_result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba con RatioSplit\n",
    "Para ver si aprende mejor que con nuestros datos ya divididos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from locale import setlocale, LC_TIME\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cornac\n",
    "import os\n",
    "\n",
    "city = \"madrid\"\n",
    "\n",
    "setlocale(LC_TIME, 'es_ES.UTF-8')\n",
    "\n",
    "seed=2032\n",
    "data_path = f\"/media/nas/datasets/tripadvisor/restaurants/{city}/reviews.pkl\"\n",
    "data = pd.read_pickle(data_path)\n",
    "# Ordenar por fecha (- a +) y quedarse con la √∫ltima (si hay repeticiones)\n",
    "data[\"date\"] =  pd.to_datetime(data[\"date\"] , format='%d de %B de %Y')\n",
    "data[\"timestamp\"] = data[\"date\"].values.astype(np.int64) // 10 ** 9\n",
    "data = data.sort_values(\"date\").reset_index(drop=True)\n",
    "data = data.drop_duplicates(subset=[\"userId\", \"restaurantId\"], keep='last', inplace=False)\n",
    "\n",
    "feedback = list(zip(data[\"userId\"], data[\"restaurantId\"], data[\"rating\"]/10))\n",
    "reviews = list(zip(data[\"userId\"], data[\"restaurantId\"], data[\"text\"].values.tolist()))\n",
    "\n",
    "cold_start = False\n",
    "eval_method = cornac.eval_methods.RatioSplit(data=feedback, test_size=0.1, val_size=0.1, exclude_unknowns=not cold_start, verbose=False, seed=123, rating_threshold=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST:\n",
      "...\n",
      "        |   F1@1 |  F1@10 |   F1@5 | NDCG@-1 | NDCG@1 | NDCG@10 | Precision@1 | Precision@10 | Precision@5 | Recall@1 | Recall@10 | Recall@5 | Train (s) | Test (s)\n",
      "------- + ------ + ------ + ------ + ------- + ------ + ------- + ----------- + ------------ + ----------- + -------- + --------- + -------- + --------- + --------\n",
      "MostPop | 0.0135 | 0.0128 | 0.0147 |  0.1552 | 0.0159 |  0.0334 |      0.0159 |       0.0074 |      0.0096 |   0.0127 |    0.0578 |   0.0378 |    0.0003 |  31.7415\n",
      "BPR     | 0.0135 | 0.0128 | 0.0147 |  0.1553 | 0.0159 |  0.0334 |      0.0159 |       0.0074 |      0.0096 |   0.0127 |    0.0578 |   0.0378 |    2.2495 |  39.6140\n",
      "EASE·¥ø   | 0.0220 | 0.0168 | 0.0204 |  0.1658 | 0.0248 |  0.0472 |      0.0248 |       0.0097 |      0.0132 |   0.0209 |    0.0768 |   0.0531 |    4.1852 |  39.0607\n",
      "MF      | 0.0001 | 0.0002 | 0.0001 |  0.0987 | 0.0001 |  0.0003 |      0.0001 |       0.0001 |      0.0001 |   0.0001 |    0.0007 |   0.0003 |    0.1750 |  41.5808\n",
      "WBPR    | 0.0080 | 0.0022 | 0.0035 |  0.1105 | 0.0095 |  0.0091 |      0.0095 |       0.0013 |      0.0023 |   0.0075 |    0.0098 |   0.0088 |    4.1824 |  41.6347\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from cornac.metrics import Recall, Precision, FMeasure, NDCG, RMSE, MSE\n",
    "from cornac.hyperopt import GridSearch, Discrete\n",
    "from cornac.experiment import Experiment\n",
    "\n",
    "metrics = [\n",
    "    FMeasure(k=1), FMeasure(k=5), FMeasure(k=10),\n",
    "    Recall(k=1), Recall(k=5), Recall(k=10),\n",
    "    Precision(k=1), Precision(k=5), Precision(k=10),\n",
    "    NDCG(), NDCG(k=1), NDCG(k=10),\n",
    "    ]\n",
    "\n",
    "md_bpr = cornac.models.BPR(seed=seed, verbose=True)\n",
    "md_ease = cornac.models.EASE(seed=seed, verbose=True)\n",
    "\n",
    "models = [\n",
    "    cornac.models.MostPop(),\n",
    "    # GridSearch( model=md_bpr, space=[ Discrete(\"k\", [25, 50]), Discrete(\"max_iter\", [50, 100]), Discrete(\"learning_rate\", [1e-4, 5e-4, 1e-3]), ], metric=NDCG(), eval_method=eval_method),\n",
    "    # GridSearch( model=md_ease, space=[ Discrete(\"posB\", [True, False]), ], metric=NDCG(), eval_method=eval_method),\n",
    "    cornac.models.BPR(seed=seed, k=25, learning_rate=0.0005, max_iter=50),  # Best parameter settings: {'k': 25, 'learning_rate': 0.0005, 'max_iter': 50}\n",
    "    cornac.models.EASE(seed=seed, posB=True),\n",
    "    cornac.models.MF(seed=seed),  # Best parameter settings: {'k': 30, 'learning_rate': 5e-06, 'max_iter': 10}\n",
    "    cornac.models.WBPR(seed=seed),\n",
    "    #cornac.models.MMMF(seed=seed),  # Best parameter settings: {'k': 5, 'learning_rate': 0.001, 'max_iter': 50}\n",
    "    #cornac.models.NeuMF(seed=seed),\n",
    "    ## cornac.models.WBPR(seed=seed),\n",
    "    #cornac.models.FM(seed=seed),\n",
    "    #cornac.models.HPF(seed=seed),\n",
    "    #cornac.models.NMF(seed=seed),\n",
    "    #cornac.models.PMF(seed=seed),\n",
    "    #cornac.models.SKMeans(seed=seed),\n",
    "    #cornac.models.SVD(seed=seed),\n",
    "    #cornac.models.WMF(seed=seed),\n",
    "]\n",
    "\n",
    "experiment = Experiment(\n",
    "    eval_method=eval_method,\n",
    "    show_validation=False,\n",
    "    models=models,\n",
    "    metrics=metrics,\n",
    "    verbose=True,\n",
    "    user_based=False,\n",
    ")\n",
    "\n",
    "experiment.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "user, times = np.unique(eval_method.train_set.uir_tuple[0], return_counts=True)\n",
    "user_train_items = pd.DataFrame(zip(user, times), columns=[\"user\", \"train_rvws\"])\n",
    "\n",
    "for result in experiment.result:\n",
    "    result_model = result.model_name\n",
    "    result_data = result.metric_user_results\n",
    "    result_metrics = list(result_data.keys())\n",
    "    \n",
    "    model_user_results = pd.DataFrame(result_data).reset_index().rename(columns={\"index\":\"user\"}).merge(user_train_items, how=\"left\")\n",
    "    model_user_results = model_user_results.groupby(\"train_rvws\")[result_metrics].mean().reset_index()\n",
    "    model_user_results.to_excel(f\"{result_model}.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_user_results[result_metrics].expanding().mean().to_excel(f\"{result_model}.xlsx\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TAV_text",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
